{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5d576399-5f2e-44ba-bfdb-c7ae1a7ed5f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "all_datasets = \"\"\"BirdSoundDetection_Warblrb10k\n",
    "ChordClassification_AcousticGuitarAndPiano\n",
    "EnvironmentalSoundClassification_AnimalsESC50\n",
    "EnvironmentalSoundClassification_ExteriorAndUrbanNoisesESC50\n",
    "EnvironmentalSoundClassification_HumanAndNonSpeechSoundsESC50\n",
    "EnvironmentalSoundClassification_InteriorAndDomesticSoundsESC50\n",
    "EnvironmentalSoundClassification_NaturalSoundscapesAndWaterSoundsESC50\n",
    "SpeechDetection_LJSpeech\n",
    "SpeechDetection_LibriSpeechTestClean\n",
    "SpeechDetection_LibriSpeechTestOther\n",
    "SpeechTextMatching_LJSpeech\n",
    "SpeechTextMatching_LibriSpeechTestClean\n",
    "SpeechTextMatching_LibriSpeechTestOther\n",
    "SpokenTermDetection_LJSpeech\n",
    "SpokenTermDetection_LibriSpeechTestClean\n",
    "SpokenTermDetection_LibriSpeechTestOther\n",
    "SpeechCommandRecognition_GoogleSpeechCommandsV1\n",
    "EnhancementDetection_LibrittsTestCleanWham\n",
    "NoiseDetectiongaussian_LJSpeechMusan\n",
    "NoiseDetectiongaussian_VCTKMusan\n",
    "NoiseDetectionmusic_LJSpeechMusan\n",
    "NoiseDetectionmusic_VCTKMusan\n",
    "NoiseDetectionnoise_LJSpeechMusan\n",
    "NoiseDetectionnoise_VCTKMusan\n",
    "NoiseDetectionspeech_LJSpeechMusan\n",
    "NoiseDetectionspeech_VCTKMusan\n",
    "NoiseSNRLevelPredictiongaussian_VCTKMusan\n",
    "NoiseSNRLevelPredictionmusic_VCTKMusan\n",
    "NoiseSNRLevelPredictionnoise_VCTKMusan\n",
    "NoiseSNRLevelPredictionspeech_VCTKMusan\n",
    "ReverberationDetectionlargeroom_LJSpeechRirsNoises\n",
    "ReverberationDetectionlargeroom_VCTKRirsNoises\n",
    "ReverberationDetectionmediumroom_LJSpeechRirsNoises\n",
    "ReverberationDetectionmediumroom_VCTKRirsNoises\n",
    "ReverberationDetectionsmallroom_LJSpeechRirsNoises\n",
    "ReverberationDetectionsmallroom_VCTKRirsNoises\n",
    "AccentClassification_AccentdbExtended\n",
    "DialogueEmotionClassification_DailyTalk\n",
    "EmotionRecognition_MultimodalEmotionlinesDataset\n",
    "HowFarAreYou_3DSpeaker\n",
    "StressDetection_MIRSD\n",
    "SpoofDetection_ASVspoof2015\n",
    "SpoofDetection_ASVspoof2017\n",
    "DialogueActClassification_DailyTalk\n",
    "Intent_Classification_FluentSpeechCommands_Action\n",
    "Intent_Classification_FluentSpeechCommands_Location\n",
    "Intent_Classification_FluentSpeechCommands_Object\n",
    "SarcasmDetection_Mustard\n",
    "SpeakerCounting_LibriTTSTestClean\"\"\".split(\"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "76428646-ea6d-4f19-b127-4233496e25d8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BirdSoundDetection_Warblrb10k;0.2707;;0.2707\n",
      "ChordClassification_AcousticGuitarAndPiano;0.4901;;0.4901\n",
      "EnvironmentalSoundClassification_AnimalsESC50;0.1525;;0.1525\n",
      "EnvironmentalSoundClassification_ExteriorAndUrbanNoisesESC50;0.2475;;0.2475\n",
      "EnvironmentalSoundClassification_HumanAndNonSpeechSoundsESC50;0.0850;;0.0850\n",
      "EnvironmentalSoundClassification_InteriorAndDomesticSoundsESC50;0.0400;;0.0400\n",
      "EnvironmentalSoundClassification_NaturalSoundscapesAndWaterSoundsESC50;0.2475;;0.2475\n",
      "SpeechDetection_LJSpeech;0.9556;0.9570;0.9527\n",
      "SpeechDetection_LibriSpeechTestClean;0.8958;0.9021;0.8815\n",
      "SpeechDetection_LibriSpeechTestOther;0.8459;0.8541;0.8270\n",
      "SpeechTextMatching_LJSpeech;0.5060;0.5035;0.5118\n",
      "SpeechTextMatching_LibriSpeechTestClean;0.5183;0.5205;0.5131\n",
      "SpeechTextMatching_LibriSpeechTestOther;0.5043;0.4973;0.5207\n",
      "SpokenTermDetection_LJSpeech;0.5953;0.5992;0.5860\n",
      "SpokenTermDetection_LibriSpeechTestClean;0.4511;0.4460;0.4634\n",
      "SpokenTermDetection_LibriSpeechTestOther;0.4621;0.4538;0.4831\n",
      "SpeechCommandRecognition_GoogleSpeechCommandsV1;0.0450;;0.0450\n",
      "EnhancementDetection_LibrittsTestCleanWham;0.8133;0.8179;0.8025\n",
      "NoiseDetectiongaussian_LJSpeechMusan;0.9825;0.9825;\n",
      "NoiseDetectiongaussian_VCTKMusan;0.9421;0.9421;\n",
      "NoiseDetectionmusic_LJSpeechMusan;0.4838;;0.4838\n",
      "NoiseDetectionmusic_VCTKMusan;0.4541;;0.4541\n",
      "NoiseDetectionnoise_LJSpeechMusan;0.5528;;0.5528\n",
      "NoiseDetectionnoise_VCTKMusan;0.5831;;0.5831\n",
      "NoiseDetectionspeech_LJSpeechMusan;0.4805;;0.4805\n",
      "NoiseDetectionspeech_VCTKMusan;0.4669;;0.4669\n",
      "NoiseSNRLevelPredictiongaussian_VCTKMusan;0.4906;0.4887;0.4950\n",
      "NoiseSNRLevelPredictionmusic_VCTKMusan;0.1608;;0.1608\n",
      "NoiseSNRLevelPredictionnoise_VCTKMusan;0.2016;;0.2016\n",
      "NoiseSNRLevelPredictionspeech_VCTKMusan;0.1603;;0.1603\n",
      "ReverberationDetectionlargeroom_LJSpeechRirsNoises;0.4842;;0.4842\n",
      "ReverberationDetectionlargeroom_VCTKRirsNoises;0.5994;;0.5994\n",
      "ReverberationDetectionmediumroom_LJSpeechRirsNoises;0.6013;;0.6013\n",
      "ReverberationDetectionmediumroom_VCTKRirsNoises;0.6518;;0.6518\n",
      "ReverberationDetectionsmallroom_LJSpeechRirsNoises;0.7470;0.7470;\n",
      "ReverberationDetectionsmallroom_VCTKRirsNoises;0.7299;0.7299;\n",
      "AccentClassification_AccentdbExtended;0.2610;;0.2610\n",
      "DialogueEmotionClassification_DailyTalk;0.7909;;0.7909\n",
      "EmotionRecognition_MultimodalEmotionlinesDataset;0.1068;;0.1068\n",
      "HowFarAreYou_3DSpeaker;;;\n",
      "StressDetection_MIRSD;0.3747;;0.3747\n",
      "SpoofDetection_ASVspoof2015;0.9245;0.9271;0.9185\n",
      "SpoofDetection_ASVspoof2017;0.5164;;0.5164\n",
      "DialogueActClassification_DailyTalk;0.4563;;0.4563\n",
      "Intent_Classification_FluentSpeechCommands_Action;;;\n",
      "Intent_Classification_FluentSpeechCommands_Location;;;\n",
      "Intent_Classification_FluentSpeechCommands_Object;;;\n",
      "SarcasmDetection_Mustard;0.5217;;0.5217\n",
      "SpeakerCounting_LibriTTSTestClean;0.2795;0.2794;0.2798\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "\n",
    "def cal_accuracy(predictions, training_instructions=None):\n",
    "    total_count = 0\n",
    "    unseen_count = 0\n",
    "    total_correct = 0\n",
    "    unseen_correct = 0\n",
    "    for pred in predictions:\n",
    "        total_count += 1\n",
    "        if pred[\"label\"] == pred[\"pred\"]:\n",
    "            total_correct += 1\n",
    "            \n",
    "        if training_instructions is not None:\n",
    "            if \"The answer\" in pred[\"instruction\"]:\n",
    "                ins = pred[\"instruction\"].split(\"The answer\")[0].strip()\n",
    "            else:\n",
    "                ins = pred[\"instruction\"]\n",
    "            \n",
    "            if not ins in training_instructions:\n",
    "                unseen_count += 1\n",
    "                if pred[\"label\"] == pred[\"pred\"]:\n",
    "                    unseen_correct += 1\n",
    "    \n",
    "                \n",
    "    acc = {\n",
    "        \"total_count\": total_count,\n",
    "        \"total_correct\": total_correct,\n",
    "        \"unseen_count\": unseen_count,\n",
    "        \"unseen_correct\": unseen_correct,\n",
    "        \"accuracy\": total_correct / total_count,\n",
    "        \"unseen_accuracy\": unseen_correct / unseen_count if unseen_count != 0 else None,\n",
    "        \"seen_accuracy\": (total_correct - unseen_correct) / (total_count - unseen_count) if (total_count - unseen_count) !=0 else None,\n",
    "        \"unseen_ratio\": unseen_count / total_count\n",
    "    }\n",
    "    acc = {k: f\"{v:.4f}\" if v is not None else \"\" for k,v in acc.items()}\n",
    "    return acc\n",
    "\n",
    "exp_path = Path(\"/home/u8915687/lab/big-superb/LLaMA-Adapter/imagebind_LLM/exp/new_train2/results/full\")\n",
    "train_data_path = Path(\"/work/u8915687/big-superb/big-superb-train-data\")\n",
    "task2path = {}\n",
    "for d in train_data_path.iterdir():\n",
    "    task2path[d.stem.split(\"_\")[0].lower()] = d\n",
    "    \n",
    "for dataset_name in all_datasets:\n",
    "    task_data_name = dataset_name\n",
    "    task_name = task_data_name.split(\"_\")[0].lower()\n",
    "\n",
    "    row = [task_data_name]\n",
    "    result_file = (exp_path/f\"{task_data_name}.json\")\n",
    "    if (result_file.exists() and\n",
    "        not task_name.startswith(\"how\")\n",
    "       ):\n",
    "        results = json.load(result_file.open())\n",
    "        if task2path.get(task_name):\n",
    "            metadata_file = task2path.get(task_name) / \"train/metadata.json\"\n",
    "            metadata = json.load(metadata_file.open())\n",
    "            training_instructions = set([v[\"instruction\"].split(\"The answer\")[0].strip() for v in metadata.values()])\n",
    "            # check\n",
    "\n",
    "            acc = cal_accuracy(results[\"predictions\"], training_instructions)\n",
    "            # row += [acc[\"accuracy\"], acc[\"seen_accuracy\"], acc[\"unseen_accuracy\"], acc[\"unseen_ratio\"], str(results[\"label_count\"])]\n",
    "            row += [acc[\"accuracy\"], acc[\"seen_accuracy\"], acc[\"unseen_accuracy\"]]\n",
    "        else:\n",
    "            acc = cal_accuracy(results[\"predictions\"])\n",
    "            row += [acc[\"accuracy\"], \"\", acc[\"accuracy\"]]\n",
    "        \n",
    "    else:\n",
    "        row += [\"\", \"\", \"\"]\n",
    "    # print(row)\n",
    "    print(\";\".join(row))\n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c4d3b756-085a-4bc3-b880-3b38a46d9b78",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BirdSoundDetection_Warblrb10k;;8000.0000\n",
      "ChordClassification_AcousticGuitarAndPiano;;859.0000\n",
      "EnvironmentalSoundClassification_AnimalsESC50;;400.0000\n",
      "EnvironmentalSoundClassification_ExteriorAndUrbanNoisesESC50;;400.0000\n",
      "EnvironmentalSoundClassification_HumanAndNonSpeechSoundsESC50;;400.0000\n",
      "EnvironmentalSoundClassification_InteriorAndDomesticSoundsESC50;;400.0000\n",
      "EnvironmentalSoundClassification_NaturalSoundscapesAndWaterSoundsESC50;;400.0000\n",
      "SpeechDetection_LJSpeech;9108.0000;3992.0000\n",
      "SpeechDetection_LibriSpeechTestClean;1818.0000;802.0000\n",
      "SpeechDetection_LibriSpeechTestOther;2043.0000;896.0000\n",
      "SpeechTextMatching_LJSpeech;9202.0000;3898.0000\n",
      "SpeechTextMatching_LibriSpeechTestClean;1854.0000;766.0000\n",
      "SpeechTextMatching_LibriSpeechTestOther;2069.0000;870.0000\n",
      "SpokenTermDetection_LJSpeech;9255.0000;3845.0000\n",
      "SpokenTermDetection_LibriSpeechTestClean;1841.0000;779.0000\n",
      "SpokenTermDetection_LibriSpeechTestOther;2109.0000;830.0000\n",
      "SpeechCommandRecognition_GoogleSpeechCommandsV1;;60973.0000\n",
      "EnhancementDetection_LibrittsTestCleanWham;3404.0000;1433.0000\n",
      "NoiseDetectiongaussian_LJSpeechMusan;26200.0000;0.0000\n",
      "NoiseDetectiongaussian_VCTKMusan;26865.0000;0.0000\n",
      "NoiseDetectionmusic_LJSpeechMusan;;26200.0000\n",
      "NoiseDetectionmusic_VCTKMusan;;26865.0000\n",
      "NoiseDetectionnoise_LJSpeechMusan;;26200.0000\n",
      "NoiseDetectionnoise_VCTKMusan;;26865.0000\n",
      "NoiseDetectionspeech_LJSpeechMusan;;26200.0000\n",
      "NoiseDetectionspeech_VCTKMusan;;26865.0000\n",
      "NoiseSNRLevelPredictiongaussian_VCTKMusan;18859.0000;8006.0000\n",
      "NoiseSNRLevelPredictionmusic_VCTKMusan;;26865.0000\n",
      "NoiseSNRLevelPredictionnoise_VCTKMusan;;26865.0000\n",
      "NoiseSNRLevelPredictionspeech_VCTKMusan;;26865.0000\n",
      "ReverberationDetectionlargeroom_LJSpeechRirsNoises;;26200.0000\n",
      "ReverberationDetectionlargeroom_VCTKRirsNoises;;20000.0000\n",
      "ReverberationDetectionmediumroom_LJSpeechRirsNoises;;26200.0000\n",
      "ReverberationDetectionmediumroom_VCTKRirsNoises;;20000.0000\n",
      "ReverberationDetectionsmallroom_LJSpeechRirsNoises;26200.0000;0.0000\n",
      "ReverberationDetectionsmallroom_VCTKRirsNoises;20000.0000;0.0000\n",
      "AccentClassification_AccentdbExtended;;17313.0000\n",
      "DialogueEmotionClassification_DailyTalk;0.0000;4758.0000\n",
      "EmotionRecognition_MultimodalEmotionlinesDataset;;3426.0000\n",
      "HowFarAreYou_3DSpeaker;;;\n",
      "StressDetection_MIRSD;;4492.0000\n",
      "SpoofDetection_ASVspoof2015;23938.0000;10239.0000\n",
      "SpoofDetection_ASVspoof2017;0.0000;13306.0000\n",
      "DialogueActClassification_DailyTalk;0.0000;4758.0000\n",
      "Intent_Classification_FluentSpeechCommands_Action;;;\n",
      "Intent_Classification_FluentSpeechCommands_Location;;;\n",
      "Intent_Classification_FluentSpeechCommands_Object;;;\n",
      "SarcasmDetection_Mustard;;690.0000\n",
      "SpeakerCounting_LibriTTSTestClean;1396.0000;604.0000\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import json\n",
    "\n",
    "\n",
    "def cal_accuracy(predictions, training_instructions=None):\n",
    "    seen_count = 0\n",
    "    unseen_count = 0\n",
    "    seen_correct = 0\n",
    "    unseen_correct = 0\n",
    "    for pred in predictions:\n",
    "        if \"The answer\" in pred[\"instruction\"]:\n",
    "            ins = pred[\"instruction\"].split(\"The answer\")[0].strip()\n",
    "        else:\n",
    "            ins = pred[\"instruction\"]\n",
    "\n",
    "        if training_instructions is not None:\n",
    "            if ins in training_instructions:\n",
    "                seen_count += 1\n",
    "                if pred[\"label\"] == pred[\"pred\"]:\n",
    "                    seen_correct += 1\n",
    "            else:\n",
    "                unseen_count += 1\n",
    "                if pred[\"label\"] == pred[\"pred\"]:\n",
    "                    unseen_correct += 1\n",
    "        else:\n",
    "            unseen_count += 1\n",
    "            if pred[\"label\"] == pred[\"pred\"]:\n",
    "                unseen_correct += 1\n",
    "    total_count = (seen_count + unseen_count)\n",
    "    total_correct = (seen_correct + unseen_correct)\n",
    "    acc = {\n",
    "        \"seen_accuracy\": seen_correct / seen_count if seen_count != 0 else None,\n",
    "        \"unseen_accuracy\": unseen_correct / unseen_count if unseen_count != 0 else None,\n",
    "        \"total_accuracy\":  total_correct / total_count,\n",
    "\n",
    "        \"total_count\": total_count,\n",
    "        \"seen_count\": seen_count,\n",
    "        \"unseen_count\": unseen_count,\n",
    "\n",
    "        \"total_correct\": total_correct,\n",
    "        \"seen_correct\": seen_correct,\n",
    "        \"unseen_correct\": unseen_correct,\n",
    "\n",
    "        \"unseen_ratio\": unseen_count / total_count\n",
    "    }\n",
    "    acc = {k: f\"{v:.4f}\" if v is not None else \"\" for k,v in acc.items()}\n",
    "    return acc\n",
    "\n",
    "exp_path = Path(\"/home/u8915687/lab/big-superb/LLaMA-Adapter/imagebind_LLM/exp/new_train2/results/full\")\n",
    "train_data_path = Path(\"/work/u8915687/big-superb/big-superb-train-data\")\n",
    "task2path = {}\n",
    "for d in train_data_path.iterdir():\n",
    "    task2path[d.stem.split(\"_\")[0].lower()] = d\n",
    "    \n",
    "for dataset_name in all_datasets:\n",
    "    task_data_name = dataset_name\n",
    "    task_name = task_data_name.split(\"_\")[0].lower()\n",
    "\n",
    "    row = [task_data_name]\n",
    "    result_file = (exp_path/f\"{task_data_name}.json\")\n",
    "    if (result_file.exists() and\n",
    "        not task_name.startswith(\"how\")\n",
    "       ):\n",
    "        results = json.load(result_file.open())\n",
    "        if task2path.get(task_name):\n",
    "            metadata_file = task2path.get(task_name) / \"train/metadata.json\"\n",
    "            metadata = json.load(metadata_file.open())\n",
    "            training_instructions = set([v[\"instruction\"].split(\"The answer\")[0].strip() for v in metadata.values()])\n",
    "            # check\n",
    "\n",
    "            acc = cal_accuracy(results[\"predictions\"], training_instructions)\n",
    "            # row += [acc[\"accuracy\"], acc[\"seen_accuracy\"], acc[\"unseen_accuracy\"], acc[\"unseen_ratio\"], str(results[\"label_count\"])]\n",
    "            # row += [acc[\"total_accuracy\"], acc[\"seen_accuracy\"], acc[\"unseen_accuracy\"]]\n",
    "            row += [acc[\"seen_count\"], acc[\"unseen_count\"]]\n",
    "        else:\n",
    "            acc = cal_accuracy(results[\"predictions\"])\n",
    "            # row += [acc[\"total_accuracy\"], \"\", acc[\"unseen_accuracy\"]]\n",
    "            row += [\"\", acc[\"unseen_count\"]]\n",
    "        \n",
    "    else:\n",
    "        row += [\"\", \"\", \"\"]\n",
    "    # print(row)\n",
    "    print(\";\".join(row))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98269959-7189-4a0d-8b49-509d84be0dc9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc8d7586-4da9-4887-a10c-c3ad2a2a5752",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc8ff2a-92bd-4a06-95ff-11a79daced8c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "14d701c7-5073-4d17-be53-4182359987dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = json.load(Path(\"/work/u8915687/big-superb/big-superb-test-data-renamed/SarcasmDetection_Mustard/test/metadata.json\").open())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "845248a7-eebd-47de-a2b7-51e5af70873e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "\n",
    "for k, v in a.items():\n",
    "    v[\"label\"] = str(v[\"label\"]).lower()\n",
    "    a[k] = v"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8476709b-2bda-4ab2-8c12-77f7d23d2fac",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "json.dump(a, Path(\"/work/u8915687/big-superb/big-superb-test-data-renamed/SarcasmDetection_Mustard/test/metadata.json\").open(\"w\"), ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04b00573-65d5-48e3-a911-e9edf04364da",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "33e0a173-c512-4d5c-9211-940bbbc3bcef",
   "metadata": {},
   "outputs": [],
   "source": [
    "a = json.load(open(\"/home/u8915687/lab/big-superb/LLaMA-Adapter/imagebind_LLM/exp/new_train2/results/full/SarcasmDetection_Mustard.json\"))\n",
    "json.dump(a, open(\"/home/u8915687/lab/big-superb/LLaMA-Adapter/imagebind_LLM/exp/new_train2/results/full/SarcasmDetection_Mustard.json\", \"w\"), ensure_ascii=False, indent=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59ae69c8-5f4a-40bb-957f-c2335f258938",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "imagebind_LLM",
   "language": "python",
   "name": "imagebind_llm"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.17"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
