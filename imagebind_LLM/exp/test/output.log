/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
Start
GPU:: 0
| distributed init (rank 0): env://, gpu 0
[1692807814.789237] [mozgsxctr1692792176642-sllj8:6217 :f]        vfs_fuse.c:281  UCX  ERROR inotify_add_watch(/tmp) failed: No space left on device
[00:23:34.831736] job dir: /home/u8915687/lab/big-superb/LLaMA-Adapter/imagebind_LLM
[00:23:34.831861] Namespace(batch_size=8,
epochs=5,
accum_iter=4,
llama_type='7B',
llama_path='/home/u8915687/lab/big-superb/Macaw-LLM2/weights/llama/',
pretrained_path='/home/u8915687/lab/big-superb/LLaMA-Adapter/imagebind_LLM/ckpts/7B.pth',
max_words=512,
weight_decay=0.02,
lr=None,
blr=0.0005,
min_lr=0.0,
warmup_epochs=1,
data_config='/home/u8915687/lab/big-superb/LLaMA-Adapter/imagebind_LLM/exps/config.yaml',
num_workers=10,
pin_mem=True,
output_dir='exp/test',
log_dir='./output',
device='cuda',
seed=0,
start_epoch=0,
world_size=1,
local_rank=-1,
dist_on_itp=False,
dist_url='env://',
rank=0,
gpu=0,
distributed=True,
dist_backend='nccl')
WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 6217 closing signal SIGINT

Traceback (most recent call last):
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 850, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 6153 got signal: 2
/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torchvision/transforms/_functional_video.py:6: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms.functional' module instead.
  warnings.warn(
/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torchvision/transforms/_transforms_video.py:22: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in the future. Please use the 'torchvision.transforms' module instead.
  warnings.warn(
Start
GPU:: 0
| distributed init (rank 0): env://, gpu 0
[1692807857.932041] [mozgsxctr1692792176642-sllj8:6952 :f]        vfs_fuse.c:281  UCX  ERROR inotify_add_watch(/tmp) failed: No space left on device
[00:24:17.972992] job dir: /home/u8915687/lab/big-superb/LLaMA-Adapter/imagebind_LLM
[00:24:17.973102] Namespace(batch_size=8,
epochs=5,
accum_iter=4,
llama_type='7B',
llama_path='/home/u8915687/lab/big-superb/Macaw-LLM2/weights/llama/',
pretrained_path='/home/u8915687/lab/big-superb/LLaMA-Adapter/imagebind_LLM/ckpts/7B.pth',
max_words=512,
weight_decay=0.02,
lr=None,
blr=0.0005,
min_lr=0.0,
warmup_epochs=1,
data_config='/home/u8915687/lab/big-superb/LLaMA-Adapter/imagebind_LLM/exps/config.yaml',
num_workers=10,
pin_mem=True,
output_dir='exp/test',
log_dir='./output',
device='cuda',
seed=0,
start_epoch=0,
world_size=1,
local_rank=-1,
dist_on_itp=False,
dist_url='env://',
rank=0,
gpu=0,
distributed=True,
dist_backend='nccl')
[00:24:47.738452] model args: ModelArgs(dim=4096, n_layers=32, n_heads=32, vocab_size=-1, multiple_of=256, norm_eps=1e-06, max_batch_size=1, max_seq_len=512, w_bias=True, w_lora=True, lora_rank=16)
[00:25:10.664163] Model = LLaMA_adapter(
  (image_bind): ImageBindModel(
    (modality_preprocessors): ModuleDict(
      (vision): RGBDTPreprocessor(
        (cls_token): tensor((1, 1, 1280), requires_grad=False)
        
        (rgbt_stem): PatchEmbedGeneric(
          (proj): Sequential(
            (0): PadIm2Video()
            (1): Conv3d(3, 1280, kernel_size=(2, 14, 14), stride=(2, 14, 14), bias=False)
          )
        )
        (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(
          (pos_embed): tensor((1, 257, 1280), requires_grad=False)
          
        )
      )
      (text): TextPreprocessor(
        (pos_embed): tensor((1, 77, 1024), requires_grad=False)
        (mask): tensor((77, 77), requires_grad=False)
        
        (token_embedding): Embedding(49408, 1024)
      )
      (audio): AudioPreprocessor(
        (cls_token): tensor((1, 1, 768), requires_grad=False)
        
        (rgbt_stem): PatchEmbedGeneric(
          (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(10, 10), bias=False)
          (norm_layer): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(
          (pos_embed): tensor((1, 229, 768), requires_grad=False)
          
        )
      )
      (depth): RGBDTPreprocessor(
        (cls_token): tensor((1, 1, 384), requires_grad=False)
        
        (depth_stem): PatchEmbedGeneric(
          (proj): Conv2d(1, 384, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (norm_layer): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
        )
        (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(
          (pos_embed): tensor((1, 197, 384), requires_grad=False)
          
        )
      )
      (thermal): ThermalPreprocessor(
        (cls_token): tensor((1, 1, 768), requires_grad=False)
        
        (rgbt_stem): PatchEmbedGeneric(
          (proj): Conv2d(1, 768, kernel_size=(16, 16), stride=(16, 16), bias=False)
          (norm_layer): LayerNorm((768,), eps=1e-05, elementwise_affine=True)
        )
        (pos_embedding_helper): SpatioTemporalPosEmbeddingHelper(
          (pos_embed): tensor((1, 197, 768), requires_grad=False)
          
        )
      )
      (imu): IMUPreprocessor(
        (pos_embed): tensor((1, 251, 512), requires_grad=False)
        (cls_token): tensor((1, 1, 512), requires_grad=False)
        
        (imu_stem): PatchEmbedGeneric(
          (proj): Linear(in_features=48, out_features=512, bias=False)
          (norm_layer): LayerNorm((512,), eps=1e-05, elementwise_affine=True)
        )
      )
    )
    (modality_trunks): ModuleDict(
      (vision): SimpleTransformer(
        (pre_transformer_layer): Sequential(
          (0): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          (1): EinOpsRearrange()
        )
        (blocks): Sequential(
          (0): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (1): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (2): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (3): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (4): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (5): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (6): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (7): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (8): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (9): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (10): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (11): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (12): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (13): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (14): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (15): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (16): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (17): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (18): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (19): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (20): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (21): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (22): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (23): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (24): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (25): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (26): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (27): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (28): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (29): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (30): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
          (31): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1280, out_features=1280, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1280, out_features=5120, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=5120, out_features=1280, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
          )
        )
        (post_transformer_layer): EinOpsRearrange()
      )
      (text): SimpleTransformer(
        (pre_transformer_layer): Sequential(
          (0): Identity()
          (1): EinOpsRearrange()
        )
        (blocks): Sequential(
          (0): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (1): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (2): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (3): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (4): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (5): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (6): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (7): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (8): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (9): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (10): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (11): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (12): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (13): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (14): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (15): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (16): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (17): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (18): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (19): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (20): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (21): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (22): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
          (23): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=1024, out_features=1024, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=1024, out_features=4096, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=4096, out_features=1024, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          )
        )
        (post_transformer_layer): EinOpsRearrange()
      )
      (audio): SimpleTransformer(
        (pre_transformer_layer): Sequential(
          (0): Identity()
          (1): EinOpsRearrange()
        )
        (blocks): Sequential(
          (0): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (1): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): DropPath(drop_prob=0.009)
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (2): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): DropPath(drop_prob=0.018)
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (3): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): DropPath(drop_prob=0.027)
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (4): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): DropPath(drop_prob=0.036)
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (5): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): DropPath(drop_prob=0.045)
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (6): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): DropPath(drop_prob=0.055)
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (7): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): DropPath(drop_prob=0.064)
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (8): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): DropPath(drop_prob=0.073)
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (9): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): DropPath(drop_prob=0.082)
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (10): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): DropPath(drop_prob=0.091)
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (11): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): DropPath(drop_prob=0.100)
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
        )
        (post_transformer_layer): EinOpsRearrange()
      )
      (depth): SimpleTransformer(
        (pre_transformer_layer): Sequential(
          (0): Identity()
          (1): EinOpsRearrange()
        )
        (blocks): Sequential(
          (0): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          )
          (1): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          )
          (2): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          )
          (3): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          )
          (4): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          )
          (5): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          )
          (6): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          )
          (7): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          )
          (8): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          )
          (9): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          )
          (10): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          )
          (11): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=384, out_features=384, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=384, out_features=1536, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=1536, out_features=384, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
          )
        )
        (post_transformer_layer): EinOpsRearrange()
      )
      (thermal): SimpleTransformer(
        (pre_transformer_layer): Sequential(
          (0): Identity()
          (1): EinOpsRearrange()
        )
        (blocks): Sequential(
          (0): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (1): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (2): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (3): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (4): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (5): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (6): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (7): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (8): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (9): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (10): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
          (11): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=768, out_features=3072, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=3072, out_features=768, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
          )
        )
        (post_transformer_layer): EinOpsRearrange()
      )
      (imu): SimpleTransformer(
        (pre_transformer_layer): Sequential(
          (0): Identity()
          (1): EinOpsRearrange()
        )
        (blocks): Sequential(
          (0): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (drop_path): Identity()
            (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          )
          (1): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (drop_path): DropPath(drop_prob=0.140)
            (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          )
          (2): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (drop_path): DropPath(drop_prob=0.280)
            (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          )
          (3): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (drop_path): DropPath(drop_prob=0.420)
            (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          )
          (4): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (drop_path): DropPath(drop_prob=0.560)
            (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          )
          (5): BlockWithMasking(
            (attn): MultiheadAttention(
              (out_proj): NonDynamicallyQuantizableLinear(in_features=512, out_features=512, bias=True)
            )
            (drop_path): DropPath(drop_prob=0.700)
            (norm_1): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
            (mlp): Mlp(
              (fc1): Linear(in_features=512, out_features=2048, bias=True)
              (act): GELU(approximate='none')
              (fc2): Linear(in_features=2048, out_features=512, bias=True)
              (drop): Dropout(p=0.0, inplace=False)
            )
            (norm_2): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
          )
        )
        (post_transformer_layer): EinOpsRearrange()
      )
    )
    (modality_heads): ModuleDict(
      (vision): Sequential(
        (0): LayerNorm((1280,), eps=1e-06, elementwise_affine=True)
        (1): SelectElement()
        (2): Linear(in_features=1280, out_features=1024, bias=False)
      )
      (text): SelectEOSAndProject(
        (proj): Sequential(
          (0): LayerNorm((1024,), eps=1e-06, elementwise_affine=True)
          (1): Linear(in_features=1024, out_features=1024, bias=False)
        )
      )
      (audio): Sequential(
        (0): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (1): SelectElement()
        (2): Linear(in_features=768, out_features=1024, bias=False)
      )
      (depth): Sequential(
        (0): LayerNorm((384,), eps=1e-06, elementwise_affine=True)
        (1): SelectElement()
        (2): Linear(in_features=384, out_features=1024, bias=False)
      )
      (thermal): Sequential(
        (0): LayerNorm((768,), eps=1e-06, elementwise_affine=True)
        (1): SelectElement()
        (2): Linear(in_features=768, out_features=1024, bias=False)
      )
      (imu): Sequential(
        (0): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (1): SelectElement()
        (2): Dropout(p=0.5, inplace=False)
        (3): Linear(in_features=512, out_features=1024, bias=False)
      )
      (point): Sequential(
        (0): LayerNorm((512,), eps=1e-06, elementwise_affine=True)
        (1): Dropout(p=0.5, inplace=False)
        (2): Linear(in_features=512, out_features=1024, bias=False)
      )
    )
    (modality_postprocessors): ModuleDict(
      (vision): Normalize()
      (text): Sequential(
        (0): Normalize()
        (1): LearnableLogitScaling(logit_scale_init=14.285714285714285,learnable=True, max_logit_scale=100)
      )
      (audio): Sequential(
        (0): Normalize()
        (1): LearnableLogitScaling(logit_scale_init=20.0,learnable=False, max_logit_scale=100)
      )
      (depth): Sequential(
        (0): Normalize()
        (1): LearnableLogitScaling(logit_scale_init=5.0,learnable=False, max_logit_scale=100)
      )
      (thermal): Sequential(
        (0): Normalize()
        (1): LearnableLogitScaling(logit_scale_init=10.0,learnable=False, max_logit_scale=100)
      )
      (imu): Sequential(
        (0): Normalize()
        (1): LearnableLogitScaling(logit_scale_init=5.0,learnable=False, max_logit_scale=100)
      )
      (point): Sequential(
        (0): Normalize()
        (1): LearnableLogitScaling(logit_scale_init=1.0,learnable=False, max_logit_scale=100)
      )
    )
    (point_trunk): PointTransformerBind(
      (point_encoder): PointTransformer(
        (group_divider): Group()
        (encoder): Encoder(
          (first_conv): Sequential(
            (0): Conv1d(3, 128, kernel_size=(1,), stride=(1,))
            (1): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv1d(128, 256, kernel_size=(1,), stride=(1,))
          )
          (second_conv): Sequential(
            (0): Conv1d(512, 512, kernel_size=(1,), stride=(1,))
            (1): BatchNorm1d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)
            (2): ReLU(inplace=True)
            (3): Conv1d(512, 256, kernel_size=(1,), stride=(1,))
          )
        )
        (reduce_dim): Linear(in_features=256, out_features=384, bias=True)
        (pos_embed): Sequential(
          (0): Linear(in_features=3, out_features=128, bias=True)
          (1): GELU(approximate='none')
          (2): Linear(in_features=128, out_features=384, bias=True)
        )
        (blocks): TransformerEncoder(
          (blocks): ModuleList(
            (0): Block(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (drop_path): Identity()
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (attn): Attention(
                (qkv): Linear(in_features=384, out_features=1152, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (1): Block(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (drop_path): DropPath(drop_prob=0.009)
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (attn): Attention(
                (qkv): Linear(in_features=384, out_features=1152, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (2): Block(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (drop_path): DropPath(drop_prob=0.018)
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (attn): Attention(
                (qkv): Linear(in_features=384, out_features=1152, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (3): Block(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (drop_path): DropPath(drop_prob=0.027)
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (attn): Attention(
                (qkv): Linear(in_features=384, out_features=1152, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (4): Block(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (drop_path): DropPath(drop_prob=0.036)
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (attn): Attention(
                (qkv): Linear(in_features=384, out_features=1152, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (5): Block(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (drop_path): DropPath(drop_prob=0.045)
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (attn): Attention(
                (qkv): Linear(in_features=384, out_features=1152, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (6): Block(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (drop_path): DropPath(drop_prob=0.055)
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (attn): Attention(
                (qkv): Linear(in_features=384, out_features=1152, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (7): Block(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (drop_path): DropPath(drop_prob=0.064)
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (attn): Attention(
                (qkv): Linear(in_features=384, out_features=1152, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (8): Block(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (drop_path): DropPath(drop_prob=0.073)
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (attn): Attention(
                (qkv): Linear(in_features=384, out_features=1152, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (9): Block(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (drop_path): DropPath(drop_prob=0.082)
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (attn): Attention(
                (qkv): Linear(in_features=384, out_features=1152, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (10): Block(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (drop_path): DropPath(drop_prob=0.091)
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (attn): Attention(
                (qkv): Linear(in_features=384, out_features=1152, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
            )
            (11): Block(
              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (drop_path): DropPath(drop_prob=0.100)
              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
              (mlp): Mlp(
                (fc1): Linear(in_features=384, out_features=1536, bias=True)
                (act): GELU(approximate='none')
                (fc2): Linear(in_features=1536, out_features=384, bias=True)
                (drop): Dropout(p=0.0, inplace=False)
              )
              (attn): Attention(
                (qkv): Linear(in_features=384, out_features=1152, bias=False)
                (attn_drop): Dropout(p=0.0, inplace=False)
                (proj): Linear(in_features=384, out_features=384, bias=True)
                (proj_drop): Dropout(p=0.0, inplace=False)
              )
            )
          )
        )
        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)
      )
    )
  )
  (image_bind_proj): Linear(in_features=1024, out_features=4096, bias=True)
  (image_bind_norm_1): RMSNorm()
  (image_bind_f1_1): Linear(in_features=4096, out_features=16384, bias=False)
  (image_bind_f2_1): Linear(in_features=16384, out_features=4096, bias=False)
  (image_bind_f3_1): Linear(in_features=4096, out_features=16384, bias=False)
  (image_bind_norm_2): RMSNorm()
  (image_bind_f1_2): Linear(in_features=4096, out_features=16384, bias=False)
  (image_bind_f2_2): Linear(in_features=16384, out_features=4096, bias=False)
  (image_bind_f3_2): Linear(in_features=4096, out_features=16384, bias=False)
  (image_bind_norm_3): RMSNorm()
  (image_bind_f1_3): Linear(in_features=4096, out_features=16384, bias=False)
  (image_bind_f2_3): Linear(in_features=16384, out_features=4096, bias=False)
  (image_bind_f3_3): Linear(in_features=4096, out_features=16384, bias=False)
  (llama): Transformer(
    (tok_embeddings): Embedding(32000, 4096)
    (layers): ModuleList(
      (0): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (1): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (2): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (3): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (4): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (5): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (6): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (7): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (8): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (9): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (10): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (11): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (12): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (13): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (14): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (15): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (16): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (17): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (18): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (19): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (20): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (21): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (22): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (23): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (24): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (25): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (26): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (27): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (28): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (29): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (30): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
      (31): TransformerBlock(
        (attention): Attention(
          (wq): Linear(in_features=4096, out_features=4096, bias=True)
          (wk): Linear(in_features=4096, out_features=4096, bias=False)
          (wv): Linear(in_features=4096, out_features=4096, bias=False)
          (wo): Linear(in_features=4096, out_features=4096, bias=True)
          (lora_wq_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wq_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wk_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wk_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wv_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wv_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_wo_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_wo_l2): Linear(in_features=16, out_features=4096, bias=False)
        )
        (feed_forward): FeedForward(
          (w1): Linear(in_features=4096, out_features=11008, bias=True)
          (w2): Linear(in_features=11008, out_features=4096, bias=True)
          (w3): Linear(in_features=4096, out_features=11008, bias=True)
          (lora_w1_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w1_l2): Linear(in_features=16, out_features=11008, bias=False)
          (lora_w2_l1): Linear(in_features=11008, out_features=16, bias=False)
          (lora_w2_l2): Linear(in_features=16, out_features=4096, bias=False)
          (lora_w3_l1): Linear(in_features=4096, out_features=16, bias=False)
          (lora_w3_l2): Linear(in_features=16, out_features=11008, bias=False)
        )
        (attention_norm): RMSNorm()
        (ffn_norm): RMSNorm()
      )
    )
    (norm): RMSNorm()
    (output): Linear(in_features=4096, out_features=32000, bias=False)
  )
  (prefix_query): Embedding(32, 4096)
  (criterion): CrossEntropyLoss()
)
[00:25:10.669435] Total Params: 8212.44 M
[00:25:10.673949] Trainable Params:: 39.43 M
[00:25:10.673993] image_bind.modality_preprocessors.vision.cls_token torch.Size([1, 1, 1280]) False
[00:25:10.674040] image_bind.modality_preprocessors.vision.rgbt_stem.proj.1.weight torch.Size([1280, 3, 2, 14, 14]) False
[00:25:10.674074] image_bind.modality_preprocessors.vision.pos_embedding_helper.pos_embed torch.Size([1, 257, 1280]) False
[00:25:10.674107] image_bind.modality_preprocessors.text.pos_embed torch.Size([1, 77, 1024]) False
[00:25:10.674139] image_bind.modality_preprocessors.text.token_embedding.weight torch.Size([49408, 1024]) False
[00:25:10.674171] image_bind.modality_preprocessors.audio.cls_token torch.Size([1, 1, 768]) False
[00:25:10.674204] image_bind.modality_preprocessors.audio.rgbt_stem.proj.weight torch.Size([768, 1, 16, 16]) False
[00:25:10.674236] image_bind.modality_preprocessors.audio.rgbt_stem.norm_layer.weight torch.Size([768]) False
[00:25:10.674267] image_bind.modality_preprocessors.audio.rgbt_stem.norm_layer.bias torch.Size([768]) False
[00:25:10.674306] image_bind.modality_preprocessors.audio.pos_embedding_helper.pos_embed torch.Size([1, 229, 768]) False
[00:25:10.674338] image_bind.modality_preprocessors.depth.cls_token torch.Size([1, 1, 384]) False
[00:25:10.674371] image_bind.modality_preprocessors.depth.depth_stem.proj.weight torch.Size([384, 1, 16, 16]) False
[00:25:10.674402] image_bind.modality_preprocessors.depth.depth_stem.norm_layer.weight torch.Size([384]) False
[00:25:10.674431] image_bind.modality_preprocessors.depth.depth_stem.norm_layer.bias torch.Size([384]) False
[00:25:10.674462] image_bind.modality_preprocessors.depth.pos_embedding_helper.pos_embed torch.Size([1, 197, 384]) False
[00:25:10.674498] image_bind.modality_preprocessors.thermal.cls_token torch.Size([1, 1, 768]) False
[00:25:10.674531] image_bind.modality_preprocessors.thermal.rgbt_stem.proj.weight torch.Size([768, 1, 16, 16]) False
[00:25:10.674562] image_bind.modality_preprocessors.thermal.rgbt_stem.norm_layer.weight torch.Size([768]) False
[00:25:10.674591] image_bind.modality_preprocessors.thermal.rgbt_stem.norm_layer.bias torch.Size([768]) False
[00:25:10.674622] image_bind.modality_preprocessors.thermal.pos_embedding_helper.pos_embed torch.Size([1, 197, 768]) False
[00:25:10.674653] image_bind.modality_preprocessors.imu.pos_embed torch.Size([1, 251, 512]) False
[00:25:10.674812] image_bind.modality_preprocessors.imu.cls_token torch.Size([1, 1, 512]) False
[00:25:10.674846] image_bind.modality_preprocessors.imu.imu_stem.proj.weight torch.Size([512, 48]) False
[00:25:10.674883] image_bind.modality_preprocessors.imu.imu_stem.norm_layer.weight torch.Size([512]) False
[00:25:10.674912] image_bind.modality_preprocessors.imu.imu_stem.norm_layer.bias torch.Size([512]) False
[00:25:10.674946] image_bind.modality_trunks.vision.pre_transformer_layer.0.weight torch.Size([1280]) False
[00:25:10.674976] image_bind.modality_trunks.vision.pre_transformer_layer.0.bias torch.Size([1280]) False
[00:25:10.675011] image_bind.modality_trunks.vision.blocks.0.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.675041] image_bind.modality_trunks.vision.blocks.0.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.675071] image_bind.modality_trunks.vision.blocks.0.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.675100] image_bind.modality_trunks.vision.blocks.0.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.675132] image_bind.modality_trunks.vision.blocks.0.norm_1.weight torch.Size([1280]) False
[00:25:10.675161] image_bind.modality_trunks.vision.blocks.0.norm_1.bias torch.Size([1280]) False
[00:25:10.675192] image_bind.modality_trunks.vision.blocks.0.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.675221] image_bind.modality_trunks.vision.blocks.0.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.675252] image_bind.modality_trunks.vision.blocks.0.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.675284] image_bind.modality_trunks.vision.blocks.0.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.675322] image_bind.modality_trunks.vision.blocks.0.norm_2.weight torch.Size([1280]) False
[00:25:10.675350] image_bind.modality_trunks.vision.blocks.0.norm_2.bias torch.Size([1280]) False
[00:25:10.675382] image_bind.modality_trunks.vision.blocks.1.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.675411] image_bind.modality_trunks.vision.blocks.1.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.675441] image_bind.modality_trunks.vision.blocks.1.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.675470] image_bind.modality_trunks.vision.blocks.1.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.675506] image_bind.modality_trunks.vision.blocks.1.norm_1.weight torch.Size([1280]) False
[00:25:10.675535] image_bind.modality_trunks.vision.blocks.1.norm_1.bias torch.Size([1280]) False
[00:25:10.675566] image_bind.modality_trunks.vision.blocks.1.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.675595] image_bind.modality_trunks.vision.blocks.1.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.675626] image_bind.modality_trunks.vision.blocks.1.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.675655] image_bind.modality_trunks.vision.blocks.1.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.675686] image_bind.modality_trunks.vision.blocks.1.norm_2.weight torch.Size([1280]) False
[00:25:10.675716] image_bind.modality_trunks.vision.blocks.1.norm_2.bias torch.Size([1280]) False
[00:25:10.675756] image_bind.modality_trunks.vision.blocks.2.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.675786] image_bind.modality_trunks.vision.blocks.2.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.675816] image_bind.modality_trunks.vision.blocks.2.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.675845] image_bind.modality_trunks.vision.blocks.2.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.675876] image_bind.modality_trunks.vision.blocks.2.norm_1.weight torch.Size([1280]) False
[00:25:10.675905] image_bind.modality_trunks.vision.blocks.2.norm_1.bias torch.Size([1280]) False
[00:25:10.675936] image_bind.modality_trunks.vision.blocks.2.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.675965] image_bind.modality_trunks.vision.blocks.2.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.675996] image_bind.modality_trunks.vision.blocks.2.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.676126] image_bind.modality_trunks.vision.blocks.2.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.676165] image_bind.modality_trunks.vision.blocks.2.norm_2.weight torch.Size([1280]) False
[00:25:10.676196] image_bind.modality_trunks.vision.blocks.2.norm_2.bias torch.Size([1280]) False
[00:25:10.676227] image_bind.modality_trunks.vision.blocks.3.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.676256] image_bind.modality_trunks.vision.blocks.3.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.676286] image_bind.modality_trunks.vision.blocks.3.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.676315] image_bind.modality_trunks.vision.blocks.3.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.676346] image_bind.modality_trunks.vision.blocks.3.norm_1.weight torch.Size([1280]) False
[00:25:10.676375] image_bind.modality_trunks.vision.blocks.3.norm_1.bias torch.Size([1280]) False
[00:25:10.676406] image_bind.modality_trunks.vision.blocks.3.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.676434] image_bind.modality_trunks.vision.blocks.3.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.676467] image_bind.modality_trunks.vision.blocks.3.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.676500] image_bind.modality_trunks.vision.blocks.3.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.676534] image_bind.modality_trunks.vision.blocks.3.norm_2.weight torch.Size([1280]) False
[00:25:10.676568] image_bind.modality_trunks.vision.blocks.3.norm_2.bias torch.Size([1280]) False
[00:25:10.676600] image_bind.modality_trunks.vision.blocks.4.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.676631] image_bind.modality_trunks.vision.blocks.4.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.676661] image_bind.modality_trunks.vision.blocks.4.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.676690] image_bind.modality_trunks.vision.blocks.4.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.676721] image_bind.modality_trunks.vision.blocks.4.norm_1.weight torch.Size([1280]) False
[00:25:10.676750] image_bind.modality_trunks.vision.blocks.4.norm_1.bias torch.Size([1280]) False
[00:25:10.676781] image_bind.modality_trunks.vision.blocks.4.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.676810] image_bind.modality_trunks.vision.blocks.4.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.676841] image_bind.modality_trunks.vision.blocks.4.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.676870] image_bind.modality_trunks.vision.blocks.4.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.676901] image_bind.modality_trunks.vision.blocks.4.norm_2.weight torch.Size([1280]) False
[00:25:10.676931] image_bind.modality_trunks.vision.blocks.4.norm_2.bias torch.Size([1280]) False
[00:25:10.676968] image_bind.modality_trunks.vision.blocks.5.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.676997] image_bind.modality_trunks.vision.blocks.5.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.677027] image_bind.modality_trunks.vision.blocks.5.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.677056] image_bind.modality_trunks.vision.blocks.5.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.677087] image_bind.modality_trunks.vision.blocks.5.norm_1.weight torch.Size([1280]) False
[00:25:10.677116] image_bind.modality_trunks.vision.blocks.5.norm_1.bias torch.Size([1280]) False
[00:25:10.677147] image_bind.modality_trunks.vision.blocks.5.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.677176] image_bind.modality_trunks.vision.blocks.5.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.677207] image_bind.modality_trunks.vision.blocks.5.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.677236] image_bind.modality_trunks.vision.blocks.5.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.677267] image_bind.modality_trunks.vision.blocks.5.norm_2.weight torch.Size([1280]) False
[00:25:10.677296] image_bind.modality_trunks.vision.blocks.5.norm_2.bias torch.Size([1280]) False
[00:25:10.677327] image_bind.modality_trunks.vision.blocks.6.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.677475] image_bind.modality_trunks.vision.blocks.6.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.677511] image_bind.modality_trunks.vision.blocks.6.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.677540] image_bind.modality_trunks.vision.blocks.6.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.677571] image_bind.modality_trunks.vision.blocks.6.norm_1.weight torch.Size([1280]) False
[00:25:10.677600] image_bind.modality_trunks.vision.blocks.6.norm_1.bias torch.Size([1280]) False
[00:25:10.677631] image_bind.modality_trunks.vision.blocks.6.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.677660] image_bind.modality_trunks.vision.blocks.6.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.677691] image_bind.modality_trunks.vision.blocks.6.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.677720] image_bind.modality_trunks.vision.blocks.6.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.677751] image_bind.modality_trunks.vision.blocks.6.norm_2.weight torch.Size([1280]) False
[00:25:10.677780] image_bind.modality_trunks.vision.blocks.6.norm_2.bias torch.Size([1280]) False
[00:25:10.677817] image_bind.modality_trunks.vision.blocks.7.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.677848] image_bind.modality_trunks.vision.blocks.7.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.677878] image_bind.modality_trunks.vision.blocks.7.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.677907] image_bind.modality_trunks.vision.blocks.7.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.677938] image_bind.modality_trunks.vision.blocks.7.norm_1.weight torch.Size([1280]) False
[00:25:10.677967] image_bind.modality_trunks.vision.blocks.7.norm_1.bias torch.Size([1280]) False
[00:25:10.677998] image_bind.modality_trunks.vision.blocks.7.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.678027] image_bind.modality_trunks.vision.blocks.7.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.678057] image_bind.modality_trunks.vision.blocks.7.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.678086] image_bind.modality_trunks.vision.blocks.7.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.678117] image_bind.modality_trunks.vision.blocks.7.norm_2.weight torch.Size([1280]) False
[00:25:10.678146] image_bind.modality_trunks.vision.blocks.7.norm_2.bias torch.Size([1280]) False
[00:25:10.678177] image_bind.modality_trunks.vision.blocks.8.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.678206] image_bind.modality_trunks.vision.blocks.8.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.678236] image_bind.modality_trunks.vision.blocks.8.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.678265] image_bind.modality_trunks.vision.blocks.8.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.678296] image_bind.modality_trunks.vision.blocks.8.norm_1.weight torch.Size([1280]) False
[00:25:10.678327] image_bind.modality_trunks.vision.blocks.8.norm_1.bias torch.Size([1280]) False
[00:25:10.678364] image_bind.modality_trunks.vision.blocks.8.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.678393] image_bind.modality_trunks.vision.blocks.8.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.678424] image_bind.modality_trunks.vision.blocks.8.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.678454] image_bind.modality_trunks.vision.blocks.8.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.678490] image_bind.modality_trunks.vision.blocks.8.norm_2.weight torch.Size([1280]) False
[00:25:10.678520] image_bind.modality_trunks.vision.blocks.8.norm_2.bias torch.Size([1280]) False
[00:25:10.678551] image_bind.modality_trunks.vision.blocks.9.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.678580] image_bind.modality_trunks.vision.blocks.9.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.678610] image_bind.modality_trunks.vision.blocks.9.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.678639] image_bind.modality_trunks.vision.blocks.9.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.678787] image_bind.modality_trunks.vision.blocks.9.norm_1.weight torch.Size([1280]) False
[00:25:10.678817] image_bind.modality_trunks.vision.blocks.9.norm_1.bias torch.Size([1280]) False
[00:25:10.678848] image_bind.modality_trunks.vision.blocks.9.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.678877] image_bind.modality_trunks.vision.blocks.9.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.678908] image_bind.modality_trunks.vision.blocks.9.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.678937] image_bind.modality_trunks.vision.blocks.9.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.678968] image_bind.modality_trunks.vision.blocks.9.norm_2.weight torch.Size([1280]) False
[00:25:10.678997] image_bind.modality_trunks.vision.blocks.9.norm_2.bias torch.Size([1280]) False
[00:25:10.679028] image_bind.modality_trunks.vision.blocks.10.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.679058] image_bind.modality_trunks.vision.blocks.10.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.679087] image_bind.modality_trunks.vision.blocks.10.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.679116] image_bind.modality_trunks.vision.blocks.10.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.679148] image_bind.modality_trunks.vision.blocks.10.norm_1.weight torch.Size([1280]) False
[00:25:10.679176] image_bind.modality_trunks.vision.blocks.10.norm_1.bias torch.Size([1280]) False
[00:25:10.679207] image_bind.modality_trunks.vision.blocks.10.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.679236] image_bind.modality_trunks.vision.blocks.10.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.679267] image_bind.modality_trunks.vision.blocks.10.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.679296] image_bind.modality_trunks.vision.blocks.10.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.679327] image_bind.modality_trunks.vision.blocks.10.norm_2.weight torch.Size([1280]) False
[00:25:10.679356] image_bind.modality_trunks.vision.blocks.10.norm_2.bias torch.Size([1280]) False
[00:25:10.679387] image_bind.modality_trunks.vision.blocks.11.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.679416] image_bind.modality_trunks.vision.blocks.11.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.679449] image_bind.modality_trunks.vision.blocks.11.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.679483] image_bind.modality_trunks.vision.blocks.11.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.679519] image_bind.modality_trunks.vision.blocks.11.norm_1.weight torch.Size([1280]) False
[00:25:10.679548] image_bind.modality_trunks.vision.blocks.11.norm_1.bias torch.Size([1280]) False
[00:25:10.679579] image_bind.modality_trunks.vision.blocks.11.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.679608] image_bind.modality_trunks.vision.blocks.11.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.679639] image_bind.modality_trunks.vision.blocks.11.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.679668] image_bind.modality_trunks.vision.blocks.11.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.679699] image_bind.modality_trunks.vision.blocks.11.norm_2.weight torch.Size([1280]) False
[00:25:10.679728] image_bind.modality_trunks.vision.blocks.11.norm_2.bias torch.Size([1280]) False
[00:25:10.679759] image_bind.modality_trunks.vision.blocks.12.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.679788] image_bind.modality_trunks.vision.blocks.12.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.679818] image_bind.modality_trunks.vision.blocks.12.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.679847] image_bind.modality_trunks.vision.blocks.12.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.679878] image_bind.modality_trunks.vision.blocks.12.norm_1.weight torch.Size([1280]) False
[00:25:10.679907] image_bind.modality_trunks.vision.blocks.12.norm_1.bias torch.Size([1280]) False
[00:25:10.679938] image_bind.modality_trunks.vision.blocks.12.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.679967] image_bind.modality_trunks.vision.blocks.12.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.680103] image_bind.modality_trunks.vision.blocks.12.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.680134] image_bind.modality_trunks.vision.blocks.12.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.680165] image_bind.modality_trunks.vision.blocks.12.norm_2.weight torch.Size([1280]) False
[00:25:10.680194] image_bind.modality_trunks.vision.blocks.12.norm_2.bias torch.Size([1280]) False
[00:25:10.680225] image_bind.modality_trunks.vision.blocks.13.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.680255] image_bind.modality_trunks.vision.blocks.13.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.680284] image_bind.modality_trunks.vision.blocks.13.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.680313] image_bind.modality_trunks.vision.blocks.13.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.680345] image_bind.modality_trunks.vision.blocks.13.norm_1.weight torch.Size([1280]) False
[00:25:10.680373] image_bind.modality_trunks.vision.blocks.13.norm_1.bias torch.Size([1280]) False
[00:25:10.680404] image_bind.modality_trunks.vision.blocks.13.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.680434] image_bind.modality_trunks.vision.blocks.13.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.680464] image_bind.modality_trunks.vision.blocks.13.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.680498] image_bind.modality_trunks.vision.blocks.13.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.680536] image_bind.modality_trunks.vision.blocks.13.norm_2.weight torch.Size([1280]) False
[00:25:10.680565] image_bind.modality_trunks.vision.blocks.13.norm_2.bias torch.Size([1280]) False
[00:25:10.680597] image_bind.modality_trunks.vision.blocks.14.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.680626] image_bind.modality_trunks.vision.blocks.14.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.680656] image_bind.modality_trunks.vision.blocks.14.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.680685] image_bind.modality_trunks.vision.blocks.14.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.680716] image_bind.modality_trunks.vision.blocks.14.norm_1.weight torch.Size([1280]) False
[00:25:10.680745] image_bind.modality_trunks.vision.blocks.14.norm_1.bias torch.Size([1280]) False
[00:25:10.680776] image_bind.modality_trunks.vision.blocks.14.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.680805] image_bind.modality_trunks.vision.blocks.14.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.680836] image_bind.modality_trunks.vision.blocks.14.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.680865] image_bind.modality_trunks.vision.blocks.14.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.680897] image_bind.modality_trunks.vision.blocks.14.norm_2.weight torch.Size([1280]) False
[00:25:10.680925] image_bind.modality_trunks.vision.blocks.14.norm_2.bias torch.Size([1280]) False
[00:25:10.680957] image_bind.modality_trunks.vision.blocks.15.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.680986] image_bind.modality_trunks.vision.blocks.15.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.681016] image_bind.modality_trunks.vision.blocks.15.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.681045] image_bind.modality_trunks.vision.blocks.15.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.681077] image_bind.modality_trunks.vision.blocks.15.norm_1.weight torch.Size([1280]) False
[00:25:10.681113] image_bind.modality_trunks.vision.blocks.15.norm_1.bias torch.Size([1280]) False
[00:25:10.681145] image_bind.modality_trunks.vision.blocks.15.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.681174] image_bind.modality_trunks.vision.blocks.15.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.681205] image_bind.modality_trunks.vision.blocks.15.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.681236] image_bind.modality_trunks.vision.blocks.15.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.681267] image_bind.modality_trunks.vision.blocks.15.norm_2.weight torch.Size([1280]) False
[00:25:10.681404] image_bind.modality_trunks.vision.blocks.15.norm_2.bias torch.Size([1280]) False
[00:25:10.681436] image_bind.modality_trunks.vision.blocks.16.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.681465] image_bind.modality_trunks.vision.blocks.16.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.681500] image_bind.modality_trunks.vision.blocks.16.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.681529] image_bind.modality_trunks.vision.blocks.16.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.681560] image_bind.modality_trunks.vision.blocks.16.norm_1.weight torch.Size([1280]) False
[00:25:10.681589] image_bind.modality_trunks.vision.blocks.16.norm_1.bias torch.Size([1280]) False
[00:25:10.681621] image_bind.modality_trunks.vision.blocks.16.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.681658] image_bind.modality_trunks.vision.blocks.16.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.681690] image_bind.modality_trunks.vision.blocks.16.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.681719] image_bind.modality_trunks.vision.blocks.16.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.681750] image_bind.modality_trunks.vision.blocks.16.norm_2.weight torch.Size([1280]) False
[00:25:10.681779] image_bind.modality_trunks.vision.blocks.16.norm_2.bias torch.Size([1280]) False
[00:25:10.681810] image_bind.modality_trunks.vision.blocks.17.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.681839] image_bind.modality_trunks.vision.blocks.17.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.681869] image_bind.modality_trunks.vision.blocks.17.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.681898] image_bind.modality_trunks.vision.blocks.17.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.681929] image_bind.modality_trunks.vision.blocks.17.norm_1.weight torch.Size([1280]) False
[00:25:10.681958] image_bind.modality_trunks.vision.blocks.17.norm_1.bias torch.Size([1280]) False
[00:25:10.681990] image_bind.modality_trunks.vision.blocks.17.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.682019] image_bind.modality_trunks.vision.blocks.17.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.682051] image_bind.modality_trunks.vision.blocks.17.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.682086] image_bind.modality_trunks.vision.blocks.17.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.682122] image_bind.modality_trunks.vision.blocks.17.norm_2.weight torch.Size([1280]) False
[00:25:10.682152] image_bind.modality_trunks.vision.blocks.17.norm_2.bias torch.Size([1280]) False
[00:25:10.682186] image_bind.modality_trunks.vision.blocks.18.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.682219] image_bind.modality_trunks.vision.blocks.18.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.682256] image_bind.modality_trunks.vision.blocks.18.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.682286] image_bind.modality_trunks.vision.blocks.18.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.682317] image_bind.modality_trunks.vision.blocks.18.norm_1.weight torch.Size([1280]) False
[00:25:10.682346] image_bind.modality_trunks.vision.blocks.18.norm_1.bias torch.Size([1280]) False
[00:25:10.682378] image_bind.modality_trunks.vision.blocks.18.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.682407] image_bind.modality_trunks.vision.blocks.18.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.682438] image_bind.modality_trunks.vision.blocks.18.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.682467] image_bind.modality_trunks.vision.blocks.18.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.682503] image_bind.modality_trunks.vision.blocks.18.norm_2.weight torch.Size([1280]) False
[00:25:10.682537] image_bind.modality_trunks.vision.blocks.18.norm_2.bias torch.Size([1280]) False
[00:25:10.682573] image_bind.modality_trunks.vision.blocks.19.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.682603] image_bind.modality_trunks.vision.blocks.19.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.682738] image_bind.modality_trunks.vision.blocks.19.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.682768] image_bind.modality_trunks.vision.blocks.19.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.682807] image_bind.modality_trunks.vision.blocks.19.norm_1.weight torch.Size([1280]) False
[00:25:10.682837] image_bind.modality_trunks.vision.blocks.19.norm_1.bias torch.Size([1280]) False
[00:25:10.682868] image_bind.modality_trunks.vision.blocks.19.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.682897] image_bind.modality_trunks.vision.blocks.19.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.682934] image_bind.modality_trunks.vision.blocks.19.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.682970] image_bind.modality_trunks.vision.blocks.19.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.683009] image_bind.modality_trunks.vision.blocks.19.norm_2.weight torch.Size([1280]) False
[00:25:10.683040] image_bind.modality_trunks.vision.blocks.19.norm_2.bias torch.Size([1280]) False
[00:25:10.683071] image_bind.modality_trunks.vision.blocks.20.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.683101] image_bind.modality_trunks.vision.blocks.20.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.683133] image_bind.modality_trunks.vision.blocks.20.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.683165] image_bind.modality_trunks.vision.blocks.20.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.683197] image_bind.modality_trunks.vision.blocks.20.norm_1.weight torch.Size([1280]) False
[00:25:10.683227] image_bind.modality_trunks.vision.blocks.20.norm_1.bias torch.Size([1280]) False
[00:25:10.683258] image_bind.modality_trunks.vision.blocks.20.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.683287] image_bind.modality_trunks.vision.blocks.20.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.683318] image_bind.modality_trunks.vision.blocks.20.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.683347] image_bind.modality_trunks.vision.blocks.20.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.683378] image_bind.modality_trunks.vision.blocks.20.norm_2.weight torch.Size([1280]) False
[00:25:10.683407] image_bind.modality_trunks.vision.blocks.20.norm_2.bias torch.Size([1280]) False
[00:25:10.683441] image_bind.modality_trunks.vision.blocks.21.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.683475] image_bind.modality_trunks.vision.blocks.21.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.683509] image_bind.modality_trunks.vision.blocks.21.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.683539] image_bind.modality_trunks.vision.blocks.21.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.683570] image_bind.modality_trunks.vision.blocks.21.norm_1.weight torch.Size([1280]) False
[00:25:10.683599] image_bind.modality_trunks.vision.blocks.21.norm_1.bias torch.Size([1280]) False
[00:25:10.683630] image_bind.modality_trunks.vision.blocks.21.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.683659] image_bind.modality_trunks.vision.blocks.21.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.683690] image_bind.modality_trunks.vision.blocks.21.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.683719] image_bind.modality_trunks.vision.blocks.21.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.683750] image_bind.modality_trunks.vision.blocks.21.norm_2.weight torch.Size([1280]) False
[00:25:10.683779] image_bind.modality_trunks.vision.blocks.21.norm_2.bias torch.Size([1280]) False
[00:25:10.683810] image_bind.modality_trunks.vision.blocks.22.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.683839] image_bind.modality_trunks.vision.blocks.22.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.683869] image_bind.modality_trunks.vision.blocks.22.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.683898] image_bind.modality_trunks.vision.blocks.22.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.683929] image_bind.modality_trunks.vision.blocks.22.norm_1.weight torch.Size([1280]) False
[00:25:10.684064] image_bind.modality_trunks.vision.blocks.22.norm_1.bias torch.Size([1280]) False
[00:25:10.684096] image_bind.modality_trunks.vision.blocks.22.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.684125] image_bind.modality_trunks.vision.blocks.22.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.684156] image_bind.modality_trunks.vision.blocks.22.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.684185] image_bind.modality_trunks.vision.blocks.22.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.684217] image_bind.modality_trunks.vision.blocks.22.norm_2.weight torch.Size([1280]) False
[00:25:10.684246] image_bind.modality_trunks.vision.blocks.22.norm_2.bias torch.Size([1280]) False
[00:25:10.684277] image_bind.modality_trunks.vision.blocks.23.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.684306] image_bind.modality_trunks.vision.blocks.23.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.684336] image_bind.modality_trunks.vision.blocks.23.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.684371] image_bind.modality_trunks.vision.blocks.23.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.684402] image_bind.modality_trunks.vision.blocks.23.norm_1.weight torch.Size([1280]) False
[00:25:10.684430] image_bind.modality_trunks.vision.blocks.23.norm_1.bias torch.Size([1280]) False
[00:25:10.684462] image_bind.modality_trunks.vision.blocks.23.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.684501] image_bind.modality_trunks.vision.blocks.23.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.684533] image_bind.modality_trunks.vision.blocks.23.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.684562] image_bind.modality_trunks.vision.blocks.23.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.684594] image_bind.modality_trunks.vision.blocks.23.norm_2.weight torch.Size([1280]) False
[00:25:10.684623] image_bind.modality_trunks.vision.blocks.23.norm_2.bias torch.Size([1280]) False
[00:25:10.684654] image_bind.modality_trunks.vision.blocks.24.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.684683] image_bind.modality_trunks.vision.blocks.24.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.684713] image_bind.modality_trunks.vision.blocks.24.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.684743] image_bind.modality_trunks.vision.blocks.24.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.684774] image_bind.modality_trunks.vision.blocks.24.norm_1.weight torch.Size([1280]) False
[00:25:10.684803] image_bind.modality_trunks.vision.blocks.24.norm_1.bias torch.Size([1280]) False
[00:25:10.684838] image_bind.modality_trunks.vision.blocks.24.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.684867] image_bind.modality_trunks.vision.blocks.24.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.684898] image_bind.modality_trunks.vision.blocks.24.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.684926] image_bind.modality_trunks.vision.blocks.24.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.684958] image_bind.modality_trunks.vision.blocks.24.norm_2.weight torch.Size([1280]) False
[00:25:10.684987] image_bind.modality_trunks.vision.blocks.24.norm_2.bias torch.Size([1280]) False
[00:25:10.685023] image_bind.modality_trunks.vision.blocks.25.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.685052] image_bind.modality_trunks.vision.blocks.25.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.685082] image_bind.modality_trunks.vision.blocks.25.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.685111] image_bind.modality_trunks.vision.blocks.25.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.685143] image_bind.modality_trunks.vision.blocks.25.norm_1.weight torch.Size([1280]) False
[00:25:10.685172] image_bind.modality_trunks.vision.blocks.25.norm_1.bias torch.Size([1280]) False
[00:25:10.685203] image_bind.modality_trunks.vision.blocks.25.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.685232] image_bind.modality_trunks.vision.blocks.25.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.685263] image_bind.modality_trunks.vision.blocks.25.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.685395] image_bind.modality_trunks.vision.blocks.25.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.685427] image_bind.modality_trunks.vision.blocks.25.norm_2.weight torch.Size([1280]) False
[00:25:10.685456] image_bind.modality_trunks.vision.blocks.25.norm_2.bias torch.Size([1280]) False
[00:25:10.685492] image_bind.modality_trunks.vision.blocks.26.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.685522] image_bind.modality_trunks.vision.blocks.26.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.685558] image_bind.modality_trunks.vision.blocks.26.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.685587] image_bind.modality_trunks.vision.blocks.26.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.685619] image_bind.modality_trunks.vision.blocks.26.norm_1.weight torch.Size([1280]) False
[00:25:10.685648] image_bind.modality_trunks.vision.blocks.26.norm_1.bias torch.Size([1280]) False
[00:25:10.685679] image_bind.modality_trunks.vision.blocks.26.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.685708] image_bind.modality_trunks.vision.blocks.26.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.685739] image_bind.modality_trunks.vision.blocks.26.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.685769] image_bind.modality_trunks.vision.blocks.26.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.685800] image_bind.modality_trunks.vision.blocks.26.norm_2.weight torch.Size([1280]) False
[00:25:10.685829] image_bind.modality_trunks.vision.blocks.26.norm_2.bias torch.Size([1280]) False
[00:25:10.685860] image_bind.modality_trunks.vision.blocks.27.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.685889] image_bind.modality_trunks.vision.blocks.27.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.685919] image_bind.modality_trunks.vision.blocks.27.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.685948] image_bind.modality_trunks.vision.blocks.27.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.685979] image_bind.modality_trunks.vision.blocks.27.norm_1.weight torch.Size([1280]) False
[00:25:10.686008] image_bind.modality_trunks.vision.blocks.27.norm_1.bias torch.Size([1280]) False
[00:25:10.686039] image_bind.modality_trunks.vision.blocks.27.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.686068] image_bind.modality_trunks.vision.blocks.27.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.686100] image_bind.modality_trunks.vision.blocks.27.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.686134] image_bind.modality_trunks.vision.blocks.27.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.686165] image_bind.modality_trunks.vision.blocks.27.norm_2.weight torch.Size([1280]) False
[00:25:10.686194] image_bind.modality_trunks.vision.blocks.27.norm_2.bias torch.Size([1280]) False
[00:25:10.686225] image_bind.modality_trunks.vision.blocks.28.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.686254] image_bind.modality_trunks.vision.blocks.28.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.686284] image_bind.modality_trunks.vision.blocks.28.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.686313] image_bind.modality_trunks.vision.blocks.28.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.686345] image_bind.modality_trunks.vision.blocks.28.norm_1.weight torch.Size([1280]) False
[00:25:10.686374] image_bind.modality_trunks.vision.blocks.28.norm_1.bias torch.Size([1280]) False
[00:25:10.686404] image_bind.modality_trunks.vision.blocks.28.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.686434] image_bind.modality_trunks.vision.blocks.28.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.686465] image_bind.modality_trunks.vision.blocks.28.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.686498] image_bind.modality_trunks.vision.blocks.28.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.686530] image_bind.modality_trunks.vision.blocks.28.norm_2.weight torch.Size([1280]) False
[00:25:10.686559] image_bind.modality_trunks.vision.blocks.28.norm_2.bias torch.Size([1280]) False
[00:25:10.686736] image_bind.modality_trunks.vision.blocks.29.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.686766] image_bind.modality_trunks.vision.blocks.29.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.686796] image_bind.modality_trunks.vision.blocks.29.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.686825] image_bind.modality_trunks.vision.blocks.29.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.686856] image_bind.modality_trunks.vision.blocks.29.norm_1.weight torch.Size([1280]) False
[00:25:10.686885] image_bind.modality_trunks.vision.blocks.29.norm_1.bias torch.Size([1280]) False
[00:25:10.686916] image_bind.modality_trunks.vision.blocks.29.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.686945] image_bind.modality_trunks.vision.blocks.29.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.686976] image_bind.modality_trunks.vision.blocks.29.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.687005] image_bind.modality_trunks.vision.blocks.29.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.687037] image_bind.modality_trunks.vision.blocks.29.norm_2.weight torch.Size([1280]) False
[00:25:10.687069] image_bind.modality_trunks.vision.blocks.29.norm_2.bias torch.Size([1280]) False
[00:25:10.687100] image_bind.modality_trunks.vision.blocks.30.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.687129] image_bind.modality_trunks.vision.blocks.30.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.687159] image_bind.modality_trunks.vision.blocks.30.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.687188] image_bind.modality_trunks.vision.blocks.30.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.687219] image_bind.modality_trunks.vision.blocks.30.norm_1.weight torch.Size([1280]) False
[00:25:10.687248] image_bind.modality_trunks.vision.blocks.30.norm_1.bias torch.Size([1280]) False
[00:25:10.687279] image_bind.modality_trunks.vision.blocks.30.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.687308] image_bind.modality_trunks.vision.blocks.30.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.687339] image_bind.modality_trunks.vision.blocks.30.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.687368] image_bind.modality_trunks.vision.blocks.30.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.687399] image_bind.modality_trunks.vision.blocks.30.norm_2.weight torch.Size([1280]) False
[00:25:10.687428] image_bind.modality_trunks.vision.blocks.30.norm_2.bias torch.Size([1280]) False
[00:25:10.687459] image_bind.modality_trunks.vision.blocks.31.attn.in_proj_weight torch.Size([3840, 1280]) False
[00:25:10.687497] image_bind.modality_trunks.vision.blocks.31.attn.in_proj_bias torch.Size([3840]) False
[00:25:10.687527] image_bind.modality_trunks.vision.blocks.31.attn.out_proj.weight torch.Size([1280, 1280]) False
[00:25:10.687556] image_bind.modality_trunks.vision.blocks.31.attn.out_proj.bias torch.Size([1280]) False
[00:25:10.687588] image_bind.modality_trunks.vision.blocks.31.norm_1.weight torch.Size([1280]) False
[00:25:10.687616] image_bind.modality_trunks.vision.blocks.31.norm_1.bias torch.Size([1280]) False
[00:25:10.687647] image_bind.modality_trunks.vision.blocks.31.mlp.fc1.weight torch.Size([5120, 1280]) False
[00:25:10.687676] image_bind.modality_trunks.vision.blocks.31.mlp.fc1.bias torch.Size([5120]) False
[00:25:10.687707] image_bind.modality_trunks.vision.blocks.31.mlp.fc2.weight torch.Size([1280, 5120]) False
[00:25:10.687736] image_bind.modality_trunks.vision.blocks.31.mlp.fc2.bias torch.Size([1280]) False
[00:25:10.687768] image_bind.modality_trunks.vision.blocks.31.norm_2.weight torch.Size([1280]) False
[00:25:10.687797] image_bind.modality_trunks.vision.blocks.31.norm_2.bias torch.Size([1280]) False
[00:25:10.687836] image_bind.modality_trunks.text.blocks.0.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.687866] image_bind.modality_trunks.text.blocks.0.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.687896] image_bind.modality_trunks.text.blocks.0.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.688036] image_bind.modality_trunks.text.blocks.0.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.688068] image_bind.modality_trunks.text.blocks.0.norm_1.weight torch.Size([1024]) False
[00:25:10.688097] image_bind.modality_trunks.text.blocks.0.norm_1.bias torch.Size([1024]) False
[00:25:10.688128] image_bind.modality_trunks.text.blocks.0.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.688157] image_bind.modality_trunks.text.blocks.0.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.688188] image_bind.modality_trunks.text.blocks.0.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.688217] image_bind.modality_trunks.text.blocks.0.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.688249] image_bind.modality_trunks.text.blocks.0.norm_2.weight torch.Size([1024]) False
[00:25:10.688277] image_bind.modality_trunks.text.blocks.0.norm_2.bias torch.Size([1024]) False
[00:25:10.688308] image_bind.modality_trunks.text.blocks.1.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.688337] image_bind.modality_trunks.text.blocks.1.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.688367] image_bind.modality_trunks.text.blocks.1.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.688396] image_bind.modality_trunks.text.blocks.1.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.688427] image_bind.modality_trunks.text.blocks.1.norm_1.weight torch.Size([1024]) False
[00:25:10.688456] image_bind.modality_trunks.text.blocks.1.norm_1.bias torch.Size([1024]) False
[00:25:10.688490] image_bind.modality_trunks.text.blocks.1.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.688520] image_bind.modality_trunks.text.blocks.1.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.688551] image_bind.modality_trunks.text.blocks.1.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.688586] image_bind.modality_trunks.text.blocks.1.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.688617] image_bind.modality_trunks.text.blocks.1.norm_2.weight torch.Size([1024]) False
[00:25:10.688646] image_bind.modality_trunks.text.blocks.1.norm_2.bias torch.Size([1024]) False
[00:25:10.688677] image_bind.modality_trunks.text.blocks.2.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.688706] image_bind.modality_trunks.text.blocks.2.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.688736] image_bind.modality_trunks.text.blocks.2.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.688765] image_bind.modality_trunks.text.blocks.2.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.688796] image_bind.modality_trunks.text.blocks.2.norm_1.weight torch.Size([1024]) False
[00:25:10.688825] image_bind.modality_trunks.text.blocks.2.norm_1.bias torch.Size([1024]) False
[00:25:10.688856] image_bind.modality_trunks.text.blocks.2.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.688885] image_bind.modality_trunks.text.blocks.2.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.688916] image_bind.modality_trunks.text.blocks.2.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.688945] image_bind.modality_trunks.text.blocks.2.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.688976] image_bind.modality_trunks.text.blocks.2.norm_2.weight torch.Size([1024]) False
[00:25:10.689005] image_bind.modality_trunks.text.blocks.2.norm_2.bias torch.Size([1024]) False
[00:25:10.689036] image_bind.modality_trunks.text.blocks.3.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.689071] image_bind.modality_trunks.text.blocks.3.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.689102] image_bind.modality_trunks.text.blocks.3.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.689131] image_bind.modality_trunks.text.blocks.3.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.689162] image_bind.modality_trunks.text.blocks.3.norm_1.weight torch.Size([1024]) False
[00:25:10.689191] image_bind.modality_trunks.text.blocks.3.norm_1.bias torch.Size([1024]) False
[00:25:10.689222] image_bind.modality_trunks.text.blocks.3.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.689361] image_bind.modality_trunks.text.blocks.3.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.689393] image_bind.modality_trunks.text.blocks.3.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.689422] image_bind.modality_trunks.text.blocks.3.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.689454] image_bind.modality_trunks.text.blocks.3.norm_2.weight torch.Size([1024]) False
[00:25:10.689482] image_bind.modality_trunks.text.blocks.3.norm_2.bias torch.Size([1024]) False
[00:25:10.689519] image_bind.modality_trunks.text.blocks.4.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.689548] image_bind.modality_trunks.text.blocks.4.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.689579] image_bind.modality_trunks.text.blocks.4.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.689612] image_bind.modality_trunks.text.blocks.4.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.689643] image_bind.modality_trunks.text.blocks.4.norm_1.weight torch.Size([1024]) False
[00:25:10.689672] image_bind.modality_trunks.text.blocks.4.norm_1.bias torch.Size([1024]) False
[00:25:10.689703] image_bind.modality_trunks.text.blocks.4.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.689732] image_bind.modality_trunks.text.blocks.4.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.689763] image_bind.modality_trunks.text.blocks.4.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.689792] image_bind.modality_trunks.text.blocks.4.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.689823] image_bind.modality_trunks.text.blocks.4.norm_2.weight torch.Size([1024]) False
[00:25:10.689852] image_bind.modality_trunks.text.blocks.4.norm_2.bias torch.Size([1024]) False
[00:25:10.689883] image_bind.modality_trunks.text.blocks.5.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.689913] image_bind.modality_trunks.text.blocks.5.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.689942] image_bind.modality_trunks.text.blocks.5.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.689971] image_bind.modality_trunks.text.blocks.5.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.690002] image_bind.modality_trunks.text.blocks.5.norm_1.weight torch.Size([1024]) False
[00:25:10.690035] image_bind.modality_trunks.text.blocks.5.norm_1.bias torch.Size([1024]) False
[00:25:10.690067] image_bind.modality_trunks.text.blocks.5.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.690096] image_bind.modality_trunks.text.blocks.5.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.690127] image_bind.modality_trunks.text.blocks.5.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.690156] image_bind.modality_trunks.text.blocks.5.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.690188] image_bind.modality_trunks.text.blocks.5.norm_2.weight torch.Size([1024]) False
[00:25:10.690216] image_bind.modality_trunks.text.blocks.5.norm_2.bias torch.Size([1024]) False
[00:25:10.690247] image_bind.modality_trunks.text.blocks.6.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.690276] image_bind.modality_trunks.text.blocks.6.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.690306] image_bind.modality_trunks.text.blocks.6.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.690335] image_bind.modality_trunks.text.blocks.6.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.690366] image_bind.modality_trunks.text.blocks.6.norm_1.weight torch.Size([1024]) False
[00:25:10.690395] image_bind.modality_trunks.text.blocks.6.norm_1.bias torch.Size([1024]) False
[00:25:10.690426] image_bind.modality_trunks.text.blocks.6.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.690455] image_bind.modality_trunks.text.blocks.6.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.690490] image_bind.modality_trunks.text.blocks.6.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.690519] image_bind.modality_trunks.text.blocks.6.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.690551] image_bind.modality_trunks.text.blocks.6.norm_2.weight torch.Size([1024]) False
[00:25:10.690580] image_bind.modality_trunks.text.blocks.6.norm_2.bias torch.Size([1024]) False
[00:25:10.690725] image_bind.modality_trunks.text.blocks.7.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.690755] image_bind.modality_trunks.text.blocks.7.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.690785] image_bind.modality_trunks.text.blocks.7.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.690814] image_bind.modality_trunks.text.blocks.7.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.690845] image_bind.modality_trunks.text.blocks.7.norm_1.weight torch.Size([1024]) False
[00:25:10.690874] image_bind.modality_trunks.text.blocks.7.norm_1.bias torch.Size([1024]) False
[00:25:10.690905] image_bind.modality_trunks.text.blocks.7.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.690934] image_bind.modality_trunks.text.blocks.7.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.690965] image_bind.modality_trunks.text.blocks.7.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.690994] image_bind.modality_trunks.text.blocks.7.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.691026] image_bind.modality_trunks.text.blocks.7.norm_2.weight torch.Size([1024]) False
[00:25:10.691054] image_bind.modality_trunks.text.blocks.7.norm_2.bias torch.Size([1024]) False
[00:25:10.691086] image_bind.modality_trunks.text.blocks.8.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.691118] image_bind.modality_trunks.text.blocks.8.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.691148] image_bind.modality_trunks.text.blocks.8.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.691177] image_bind.modality_trunks.text.blocks.8.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.691208] image_bind.modality_trunks.text.blocks.8.norm_1.weight torch.Size([1024]) False
[00:25:10.691237] image_bind.modality_trunks.text.blocks.8.norm_1.bias torch.Size([1024]) False
[00:25:10.691268] image_bind.modality_trunks.text.blocks.8.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.691297] image_bind.modality_trunks.text.blocks.8.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.691329] image_bind.modality_trunks.text.blocks.8.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.691358] image_bind.modality_trunks.text.blocks.8.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.691389] image_bind.modality_trunks.text.blocks.8.norm_2.weight torch.Size([1024]) False
[00:25:10.691418] image_bind.modality_trunks.text.blocks.8.norm_2.bias torch.Size([1024]) False
[00:25:10.691449] image_bind.modality_trunks.text.blocks.9.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.691478] image_bind.modality_trunks.text.blocks.9.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.691513] image_bind.modality_trunks.text.blocks.9.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.691542] image_bind.modality_trunks.text.blocks.9.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.691573] image_bind.modality_trunks.text.blocks.9.norm_1.weight torch.Size([1024]) False
[00:25:10.691608] image_bind.modality_trunks.text.blocks.9.norm_1.bias torch.Size([1024]) False
[00:25:10.691639] image_bind.modality_trunks.text.blocks.9.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.691668] image_bind.modality_trunks.text.blocks.9.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.691699] image_bind.modality_trunks.text.blocks.9.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.691729] image_bind.modality_trunks.text.blocks.9.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.691760] image_bind.modality_trunks.text.blocks.9.norm_2.weight torch.Size([1024]) False
[00:25:10.691788] image_bind.modality_trunks.text.blocks.9.norm_2.bias torch.Size([1024]) False
[00:25:10.691820] image_bind.modality_trunks.text.blocks.10.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.691849] image_bind.modality_trunks.text.blocks.10.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.691879] image_bind.modality_trunks.text.blocks.10.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.691908] image_bind.modality_trunks.text.blocks.10.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.692041] image_bind.modality_trunks.text.blocks.10.norm_1.weight torch.Size([1024]) False
[00:25:10.692071] image_bind.modality_trunks.text.blocks.10.norm_1.bias torch.Size([1024]) False
[00:25:10.692105] image_bind.modality_trunks.text.blocks.10.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.692134] image_bind.modality_trunks.text.blocks.10.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.692165] image_bind.modality_trunks.text.blocks.10.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.692195] image_bind.modality_trunks.text.blocks.10.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.692226] image_bind.modality_trunks.text.blocks.10.norm_2.weight torch.Size([1024]) False
[00:25:10.692255] image_bind.modality_trunks.text.blocks.10.norm_2.bias torch.Size([1024]) False
[00:25:10.692286] image_bind.modality_trunks.text.blocks.11.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.692315] image_bind.modality_trunks.text.blocks.11.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.692345] image_bind.modality_trunks.text.blocks.11.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.692374] image_bind.modality_trunks.text.blocks.11.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.692405] image_bind.modality_trunks.text.blocks.11.norm_1.weight torch.Size([1024]) False
[00:25:10.692434] image_bind.modality_trunks.text.blocks.11.norm_1.bias torch.Size([1024]) False
[00:25:10.692465] image_bind.modality_trunks.text.blocks.11.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.692499] image_bind.modality_trunks.text.blocks.11.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.692530] image_bind.modality_trunks.text.blocks.11.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.692559] image_bind.modality_trunks.text.blocks.11.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.692591] image_bind.modality_trunks.text.blocks.11.norm_2.weight torch.Size([1024]) False
[00:25:10.692619] image_bind.modality_trunks.text.blocks.11.norm_2.bias torch.Size([1024]) False
[00:25:10.692651] image_bind.modality_trunks.text.blocks.12.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.692686] image_bind.modality_trunks.text.blocks.12.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.692716] image_bind.modality_trunks.text.blocks.12.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.692746] image_bind.modality_trunks.text.blocks.12.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.692777] image_bind.modality_trunks.text.blocks.12.norm_1.weight torch.Size([1024]) False
[00:25:10.692806] image_bind.modality_trunks.text.blocks.12.norm_1.bias torch.Size([1024]) False
[00:25:10.692837] image_bind.modality_trunks.text.blocks.12.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.692866] image_bind.modality_trunks.text.blocks.12.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.692897] image_bind.modality_trunks.text.blocks.12.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.692926] image_bind.modality_trunks.text.blocks.12.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.692958] image_bind.modality_trunks.text.blocks.12.norm_2.weight torch.Size([1024]) False
[00:25:10.692986] image_bind.modality_trunks.text.blocks.12.norm_2.bias torch.Size([1024]) False
[00:25:10.693018] image_bind.modality_trunks.text.blocks.13.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.693047] image_bind.modality_trunks.text.blocks.13.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.693077] image_bind.modality_trunks.text.blocks.13.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.693106] image_bind.modality_trunks.text.blocks.13.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.693137] image_bind.modality_trunks.text.blocks.13.norm_1.weight torch.Size([1024]) False
[00:25:10.693166] image_bind.modality_trunks.text.blocks.13.norm_1.bias torch.Size([1024]) False
[00:25:10.693197] image_bind.modality_trunks.text.blocks.13.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.693226] image_bind.modality_trunks.text.blocks.13.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.693362] image_bind.modality_trunks.text.blocks.13.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.693391] image_bind.modality_trunks.text.blocks.13.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.693423] image_bind.modality_trunks.text.blocks.13.norm_2.weight torch.Size([1024]) False
[00:25:10.693454] image_bind.modality_trunks.text.blocks.13.norm_2.bias torch.Size([1024]) False
[00:25:10.693490] image_bind.modality_trunks.text.blocks.14.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.693521] image_bind.modality_trunks.text.blocks.14.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.693551] image_bind.modality_trunks.text.blocks.14.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.693580] image_bind.modality_trunks.text.blocks.14.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.693611] image_bind.modality_trunks.text.blocks.14.norm_1.weight torch.Size([1024]) False
[00:25:10.693640] image_bind.modality_trunks.text.blocks.14.norm_1.bias torch.Size([1024]) False
[00:25:10.693671] image_bind.modality_trunks.text.blocks.14.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.693700] image_bind.modality_trunks.text.blocks.14.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.693732] image_bind.modality_trunks.text.blocks.14.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.693761] image_bind.modality_trunks.text.blocks.14.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.693792] image_bind.modality_trunks.text.blocks.14.norm_2.weight torch.Size([1024]) False
[00:25:10.693821] image_bind.modality_trunks.text.blocks.14.norm_2.bias torch.Size([1024]) False
[00:25:10.693860] image_bind.modality_trunks.text.blocks.15.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.693889] image_bind.modality_trunks.text.blocks.15.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.693919] image_bind.modality_trunks.text.blocks.15.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.693948] image_bind.modality_trunks.text.blocks.15.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.693979] image_bind.modality_trunks.text.blocks.15.norm_1.weight torch.Size([1024]) False
[00:25:10.694008] image_bind.modality_trunks.text.blocks.15.norm_1.bias torch.Size([1024]) False
[00:25:10.694039] image_bind.modality_trunks.text.blocks.15.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.694068] image_bind.modality_trunks.text.blocks.15.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.694099] image_bind.modality_trunks.text.blocks.15.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.694128] image_bind.modality_trunks.text.blocks.15.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.694159] image_bind.modality_trunks.text.blocks.15.norm_2.weight torch.Size([1024]) False
[00:25:10.694188] image_bind.modality_trunks.text.blocks.15.norm_2.bias torch.Size([1024]) False
[00:25:10.694219] image_bind.modality_trunks.text.blocks.16.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.694249] image_bind.modality_trunks.text.blocks.16.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.694279] image_bind.modality_trunks.text.blocks.16.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.694308] image_bind.modality_trunks.text.blocks.16.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.694339] image_bind.modality_trunks.text.blocks.16.norm_1.weight torch.Size([1024]) False
[00:25:10.694368] image_bind.modality_trunks.text.blocks.16.norm_1.bias torch.Size([1024]) False
[00:25:10.694399] image_bind.modality_trunks.text.blocks.16.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.694429] image_bind.modality_trunks.text.blocks.16.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.694465] image_bind.modality_trunks.text.blocks.16.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.694499] image_bind.modality_trunks.text.blocks.16.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.694531] image_bind.modality_trunks.text.blocks.16.norm_2.weight torch.Size([1024]) False
[00:25:10.694560] image_bind.modality_trunks.text.blocks.16.norm_2.bias torch.Size([1024]) False
[00:25:10.694703] image_bind.modality_trunks.text.blocks.17.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.694733] image_bind.modality_trunks.text.blocks.17.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.694763] image_bind.modality_trunks.text.blocks.17.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.694792] image_bind.modality_trunks.text.blocks.17.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.694823] image_bind.modality_trunks.text.blocks.17.norm_1.weight torch.Size([1024]) False
[00:25:10.694851] image_bind.modality_trunks.text.blocks.17.norm_1.bias torch.Size([1024]) False
[00:25:10.694883] image_bind.modality_trunks.text.blocks.17.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.694913] image_bind.modality_trunks.text.blocks.17.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.694945] image_bind.modality_trunks.text.blocks.17.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.694974] image_bind.modality_trunks.text.blocks.17.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.695006] image_bind.modality_trunks.text.blocks.17.norm_2.weight torch.Size([1024]) False
[00:25:10.695035] image_bind.modality_trunks.text.blocks.17.norm_2.bias torch.Size([1024]) False
[00:25:10.695066] image_bind.modality_trunks.text.blocks.18.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.695095] image_bind.modality_trunks.text.blocks.18.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.695125] image_bind.modality_trunks.text.blocks.18.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.695154] image_bind.modality_trunks.text.blocks.18.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.695185] image_bind.modality_trunks.text.blocks.18.norm_1.weight torch.Size([1024]) False
[00:25:10.695214] image_bind.modality_trunks.text.blocks.18.norm_1.bias torch.Size([1024]) False
[00:25:10.695245] image_bind.modality_trunks.text.blocks.18.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.695273] image_bind.modality_trunks.text.blocks.18.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.695304] image_bind.modality_trunks.text.blocks.18.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.695333] image_bind.modality_trunks.text.blocks.18.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.695368] image_bind.modality_trunks.text.blocks.18.norm_2.weight torch.Size([1024]) False
[00:25:10.695397] image_bind.modality_trunks.text.blocks.18.norm_2.bias torch.Size([1024]) False
[00:25:10.695428] image_bind.modality_trunks.text.blocks.19.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.695458] image_bind.modality_trunks.text.blocks.19.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.695491] image_bind.modality_trunks.text.blocks.19.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.695521] image_bind.modality_trunks.text.blocks.19.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.695552] image_bind.modality_trunks.text.blocks.19.norm_1.weight torch.Size([1024]) False
[00:25:10.695581] image_bind.modality_trunks.text.blocks.19.norm_1.bias torch.Size([1024]) False
[00:25:10.695612] image_bind.modality_trunks.text.blocks.19.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.695641] image_bind.modality_trunks.text.blocks.19.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.695673] image_bind.modality_trunks.text.blocks.19.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.695702] image_bind.modality_trunks.text.blocks.19.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.695733] image_bind.modality_trunks.text.blocks.19.norm_2.weight torch.Size([1024]) False
[00:25:10.695762] image_bind.modality_trunks.text.blocks.19.norm_2.bias torch.Size([1024]) False
[00:25:10.695799] image_bind.modality_trunks.text.blocks.20.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.695828] image_bind.modality_trunks.text.blocks.20.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.695858] image_bind.modality_trunks.text.blocks.20.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.695887] image_bind.modality_trunks.text.blocks.20.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.696019] image_bind.modality_trunks.text.blocks.20.norm_1.weight torch.Size([1024]) False
[00:25:10.696049] image_bind.modality_trunks.text.blocks.20.norm_1.bias torch.Size([1024]) False
[00:25:10.696080] image_bind.modality_trunks.text.blocks.20.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.696109] image_bind.modality_trunks.text.blocks.20.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.696140] image_bind.modality_trunks.text.blocks.20.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.696169] image_bind.modality_trunks.text.blocks.20.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.696201] image_bind.modality_trunks.text.blocks.20.norm_2.weight torch.Size([1024]) False
[00:25:10.696229] image_bind.modality_trunks.text.blocks.20.norm_2.bias torch.Size([1024]) False
[00:25:10.696261] image_bind.modality_trunks.text.blocks.21.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.696291] image_bind.modality_trunks.text.blocks.21.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.696324] image_bind.modality_trunks.text.blocks.21.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.696353] image_bind.modality_trunks.text.blocks.21.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.696384] image_bind.modality_trunks.text.blocks.21.norm_1.weight torch.Size([1024]) False
[00:25:10.696413] image_bind.modality_trunks.text.blocks.21.norm_1.bias torch.Size([1024]) False
[00:25:10.696444] image_bind.modality_trunks.text.blocks.21.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.696473] image_bind.modality_trunks.text.blocks.21.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.696510] image_bind.modality_trunks.text.blocks.21.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.696540] image_bind.modality_trunks.text.blocks.21.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.696571] image_bind.modality_trunks.text.blocks.21.norm_2.weight torch.Size([1024]) False
[00:25:10.696600] image_bind.modality_trunks.text.blocks.21.norm_2.bias torch.Size([1024]) False
[00:25:10.696631] image_bind.modality_trunks.text.blocks.22.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.696660] image_bind.modality_trunks.text.blocks.22.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.696690] image_bind.modality_trunks.text.blocks.22.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.696719] image_bind.modality_trunks.text.blocks.22.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.696751] image_bind.modality_trunks.text.blocks.22.norm_1.weight torch.Size([1024]) False
[00:25:10.696784] image_bind.modality_trunks.text.blocks.22.norm_1.bias torch.Size([1024]) False
[00:25:10.696816] image_bind.modality_trunks.text.blocks.22.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.696845] image_bind.modality_trunks.text.blocks.22.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.696876] image_bind.modality_trunks.text.blocks.22.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.696905] image_bind.modality_trunks.text.blocks.22.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.696936] image_bind.modality_trunks.text.blocks.22.norm_2.weight torch.Size([1024]) False
[00:25:10.696965] image_bind.modality_trunks.text.blocks.22.norm_2.bias torch.Size([1024]) False
[00:25:10.696996] image_bind.modality_trunks.text.blocks.23.attn.in_proj_weight torch.Size([3072, 1024]) False
[00:25:10.697026] image_bind.modality_trunks.text.blocks.23.attn.in_proj_bias torch.Size([3072]) False
[00:25:10.697056] image_bind.modality_trunks.text.blocks.23.attn.out_proj.weight torch.Size([1024, 1024]) False
[00:25:10.697085] image_bind.modality_trunks.text.blocks.23.attn.out_proj.bias torch.Size([1024]) False
[00:25:10.697116] image_bind.modality_trunks.text.blocks.23.norm_1.weight torch.Size([1024]) False
[00:25:10.697145] image_bind.modality_trunks.text.blocks.23.norm_1.bias torch.Size([1024]) False
[00:25:10.697176] image_bind.modality_trunks.text.blocks.23.mlp.fc1.weight torch.Size([4096, 1024]) False
[00:25:10.697205] image_bind.modality_trunks.text.blocks.23.mlp.fc1.bias torch.Size([4096]) False
[00:25:10.697336] image_bind.modality_trunks.text.blocks.23.mlp.fc2.weight torch.Size([1024, 4096]) False
[00:25:10.697366] image_bind.modality_trunks.text.blocks.23.mlp.fc2.bias torch.Size([1024]) False
[00:25:10.697397] image_bind.modality_trunks.text.blocks.23.norm_2.weight torch.Size([1024]) False
[00:25:10.697426] image_bind.modality_trunks.text.blocks.23.norm_2.bias torch.Size([1024]) False
[00:25:10.697466] image_bind.modality_trunks.audio.blocks.0.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.697499] image_bind.modality_trunks.audio.blocks.0.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.697528] image_bind.modality_trunks.audio.blocks.0.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.697558] image_bind.modality_trunks.audio.blocks.0.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.697589] image_bind.modality_trunks.audio.blocks.0.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.697618] image_bind.modality_trunks.audio.blocks.0.attn.out_proj.bias torch.Size([768]) False
[00:25:10.697650] image_bind.modality_trunks.audio.blocks.0.norm_1.weight torch.Size([768]) False
[00:25:10.697679] image_bind.modality_trunks.audio.blocks.0.norm_1.bias torch.Size([768]) False
[00:25:10.697715] image_bind.modality_trunks.audio.blocks.0.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.697745] image_bind.modality_trunks.audio.blocks.0.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.697776] image_bind.modality_trunks.audio.blocks.0.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.697805] image_bind.modality_trunks.audio.blocks.0.mlp.fc2.bias torch.Size([768]) False
[00:25:10.697836] image_bind.modality_trunks.audio.blocks.0.norm_2.weight torch.Size([768]) False
[00:25:10.697865] image_bind.modality_trunks.audio.blocks.0.norm_2.bias torch.Size([768]) False
[00:25:10.697897] image_bind.modality_trunks.audio.blocks.1.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.697926] image_bind.modality_trunks.audio.blocks.1.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.697955] image_bind.modality_trunks.audio.blocks.1.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.697984] image_bind.modality_trunks.audio.blocks.1.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.698015] image_bind.modality_trunks.audio.blocks.1.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.698044] image_bind.modality_trunks.audio.blocks.1.attn.out_proj.bias torch.Size([768]) False
[00:25:10.698075] image_bind.modality_trunks.audio.blocks.1.norm_1.weight torch.Size([768]) False
[00:25:10.698107] image_bind.modality_trunks.audio.blocks.1.norm_1.bias torch.Size([768]) False
[00:25:10.698139] image_bind.modality_trunks.audio.blocks.1.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.698168] image_bind.modality_trunks.audio.blocks.1.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.698199] image_bind.modality_trunks.audio.blocks.1.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.698229] image_bind.modality_trunks.audio.blocks.1.mlp.fc2.bias torch.Size([768]) False
[00:25:10.698260] image_bind.modality_trunks.audio.blocks.1.norm_2.weight torch.Size([768]) False
[00:25:10.698289] image_bind.modality_trunks.audio.blocks.1.norm_2.bias torch.Size([768]) False
[00:25:10.698320] image_bind.modality_trunks.audio.blocks.2.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.698349] image_bind.modality_trunks.audio.blocks.2.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.698378] image_bind.modality_trunks.audio.blocks.2.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.698407] image_bind.modality_trunks.audio.blocks.2.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.698438] image_bind.modality_trunks.audio.blocks.2.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.698467] image_bind.modality_trunks.audio.blocks.2.attn.out_proj.bias torch.Size([768]) False
[00:25:10.698502] image_bind.modality_trunks.audio.blocks.2.norm_1.weight torch.Size([768]) False
[00:25:10.698535] image_bind.modality_trunks.audio.blocks.2.norm_1.bias torch.Size([768]) False
[00:25:10.698675] image_bind.modality_trunks.audio.blocks.2.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.698704] image_bind.modality_trunks.audio.blocks.2.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.698735] image_bind.modality_trunks.audio.blocks.2.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.698764] image_bind.modality_trunks.audio.blocks.2.mlp.fc2.bias torch.Size([768]) False
[00:25:10.698796] image_bind.modality_trunks.audio.blocks.2.norm_2.weight torch.Size([768]) False
[00:25:10.698824] image_bind.modality_trunks.audio.blocks.2.norm_2.bias torch.Size([768]) False
[00:25:10.698856] image_bind.modality_trunks.audio.blocks.3.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.698885] image_bind.modality_trunks.audio.blocks.3.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.698914] image_bind.modality_trunks.audio.blocks.3.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.698943] image_bind.modality_trunks.audio.blocks.3.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.698974] image_bind.modality_trunks.audio.blocks.3.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.699003] image_bind.modality_trunks.audio.blocks.3.attn.out_proj.bias torch.Size([768]) False
[00:25:10.699034] image_bind.modality_trunks.audio.blocks.3.norm_1.weight torch.Size([768]) False
[00:25:10.699063] image_bind.modality_trunks.audio.blocks.3.norm_1.bias torch.Size([768]) False
[00:25:10.699094] image_bind.modality_trunks.audio.blocks.3.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.699123] image_bind.modality_trunks.audio.blocks.3.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.699154] image_bind.modality_trunks.audio.blocks.3.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.699184] image_bind.modality_trunks.audio.blocks.3.mlp.fc2.bias torch.Size([768]) False
[00:25:10.699215] image_bind.modality_trunks.audio.blocks.3.norm_2.weight torch.Size([768]) False
[00:25:10.699244] image_bind.modality_trunks.audio.blocks.3.norm_2.bias torch.Size([768]) False
[00:25:10.699275] image_bind.modality_trunks.audio.blocks.4.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.699304] image_bind.modality_trunks.audio.blocks.4.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.699333] image_bind.modality_trunks.audio.blocks.4.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.699363] image_bind.modality_trunks.audio.blocks.4.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.699393] image_bind.modality_trunks.audio.blocks.4.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.699422] image_bind.modality_trunks.audio.blocks.4.attn.out_proj.bias torch.Size([768]) False
[00:25:10.699454] image_bind.modality_trunks.audio.blocks.4.norm_1.weight torch.Size([768]) False
[00:25:10.699483] image_bind.modality_trunks.audio.blocks.4.norm_1.bias torch.Size([768]) False
[00:25:10.699520] image_bind.modality_trunks.audio.blocks.4.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.699549] image_bind.modality_trunks.audio.blocks.4.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.699581] image_bind.modality_trunks.audio.blocks.4.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.699610] image_bind.modality_trunks.audio.blocks.4.mlp.fc2.bias torch.Size([768]) False
[00:25:10.699641] image_bind.modality_trunks.audio.blocks.4.norm_2.weight torch.Size([768]) False
[00:25:10.699676] image_bind.modality_trunks.audio.blocks.4.norm_2.bias torch.Size([768]) False
[00:25:10.699707] image_bind.modality_trunks.audio.blocks.5.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.699736] image_bind.modality_trunks.audio.blocks.5.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.699766] image_bind.modality_trunks.audio.blocks.5.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.699795] image_bind.modality_trunks.audio.blocks.5.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.699825] image_bind.modality_trunks.audio.blocks.5.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.699855] image_bind.modality_trunks.audio.blocks.5.attn.out_proj.bias torch.Size([768]) False
[00:25:10.699992] image_bind.modality_trunks.audio.blocks.5.norm_1.weight torch.Size([768]) False
[00:25:10.700022] image_bind.modality_trunks.audio.blocks.5.norm_1.bias torch.Size([768]) False
[00:25:10.700053] image_bind.modality_trunks.audio.blocks.5.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.700082] image_bind.modality_trunks.audio.blocks.5.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.700113] image_bind.modality_trunks.audio.blocks.5.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.700143] image_bind.modality_trunks.audio.blocks.5.mlp.fc2.bias torch.Size([768]) False
[00:25:10.700175] image_bind.modality_trunks.audio.blocks.5.norm_2.weight torch.Size([768]) False
[00:25:10.700207] image_bind.modality_trunks.audio.blocks.5.norm_2.bias torch.Size([768]) False
[00:25:10.700238] image_bind.modality_trunks.audio.blocks.6.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.700268] image_bind.modality_trunks.audio.blocks.6.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.700297] image_bind.modality_trunks.audio.blocks.6.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.700326] image_bind.modality_trunks.audio.blocks.6.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.700357] image_bind.modality_trunks.audio.blocks.6.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.700386] image_bind.modality_trunks.audio.blocks.6.attn.out_proj.bias torch.Size([768]) False
[00:25:10.700418] image_bind.modality_trunks.audio.blocks.6.norm_1.weight torch.Size([768]) False
[00:25:10.700446] image_bind.modality_trunks.audio.blocks.6.norm_1.bias torch.Size([768]) False
[00:25:10.700477] image_bind.modality_trunks.audio.blocks.6.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.700510] image_bind.modality_trunks.audio.blocks.6.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.700542] image_bind.modality_trunks.audio.blocks.6.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.700577] image_bind.modality_trunks.audio.blocks.6.mlp.fc2.bias torch.Size([768]) False
[00:25:10.700608] image_bind.modality_trunks.audio.blocks.6.norm_2.weight torch.Size([768]) False
[00:25:10.700637] image_bind.modality_trunks.audio.blocks.6.norm_2.bias torch.Size([768]) False
[00:25:10.700669] image_bind.modality_trunks.audio.blocks.7.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.700698] image_bind.modality_trunks.audio.blocks.7.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.700727] image_bind.modality_trunks.audio.blocks.7.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.700757] image_bind.modality_trunks.audio.blocks.7.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.700787] image_bind.modality_trunks.audio.blocks.7.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.700817] image_bind.modality_trunks.audio.blocks.7.attn.out_proj.bias torch.Size([768]) False
[00:25:10.700848] image_bind.modality_trunks.audio.blocks.7.norm_1.weight torch.Size([768]) False
[00:25:10.700877] image_bind.modality_trunks.audio.blocks.7.norm_1.bias torch.Size([768]) False
[00:25:10.700908] image_bind.modality_trunks.audio.blocks.7.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.700937] image_bind.modality_trunks.audio.blocks.7.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.700968] image_bind.modality_trunks.audio.blocks.7.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.700998] image_bind.modality_trunks.audio.blocks.7.mlp.fc2.bias torch.Size([768]) False
[00:25:10.701029] image_bind.modality_trunks.audio.blocks.7.norm_2.weight torch.Size([768]) False
[00:25:10.701062] image_bind.modality_trunks.audio.blocks.7.norm_2.bias torch.Size([768]) False
[00:25:10.701094] image_bind.modality_trunks.audio.blocks.8.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.701124] image_bind.modality_trunks.audio.blocks.8.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.701153] image_bind.modality_trunks.audio.blocks.8.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.701182] image_bind.modality_trunks.audio.blocks.8.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.701213] image_bind.modality_trunks.audio.blocks.8.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.701350] image_bind.modality_trunks.audio.blocks.8.attn.out_proj.bias torch.Size([768]) False
[00:25:10.701382] image_bind.modality_trunks.audio.blocks.8.norm_1.weight torch.Size([768]) False
[00:25:10.701411] image_bind.modality_trunks.audio.blocks.8.norm_1.bias torch.Size([768]) False
[00:25:10.701442] image_bind.modality_trunks.audio.blocks.8.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.701471] image_bind.modality_trunks.audio.blocks.8.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.701506] image_bind.modality_trunks.audio.blocks.8.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.701536] image_bind.modality_trunks.audio.blocks.8.mlp.fc2.bias torch.Size([768]) False
[00:25:10.701567] image_bind.modality_trunks.audio.blocks.8.norm_2.weight torch.Size([768]) False
[00:25:10.701600] image_bind.modality_trunks.audio.blocks.8.norm_2.bias torch.Size([768]) False
[00:25:10.701632] image_bind.modality_trunks.audio.blocks.9.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.701662] image_bind.modality_trunks.audio.blocks.9.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.701691] image_bind.modality_trunks.audio.blocks.9.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.701721] image_bind.modality_trunks.audio.blocks.9.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.701751] image_bind.modality_trunks.audio.blocks.9.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.701780] image_bind.modality_trunks.audio.blocks.9.attn.out_proj.bias torch.Size([768]) False
[00:25:10.701812] image_bind.modality_trunks.audio.blocks.9.norm_1.weight torch.Size([768]) False
[00:25:10.701840] image_bind.modality_trunks.audio.blocks.9.norm_1.bias torch.Size([768]) False
[00:25:10.701872] image_bind.modality_trunks.audio.blocks.9.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.701901] image_bind.modality_trunks.audio.blocks.9.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.701933] image_bind.modality_trunks.audio.blocks.9.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.701962] image_bind.modality_trunks.audio.blocks.9.mlp.fc2.bias torch.Size([768]) False
[00:25:10.701993] image_bind.modality_trunks.audio.blocks.9.norm_2.weight torch.Size([768]) False
[00:25:10.702022] image_bind.modality_trunks.audio.blocks.9.norm_2.bias torch.Size([768]) False
[00:25:10.702054] image_bind.modality_trunks.audio.blocks.10.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.702088] image_bind.modality_trunks.audio.blocks.10.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.702117] image_bind.modality_trunks.audio.blocks.10.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.702146] image_bind.modality_trunks.audio.blocks.10.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.702177] image_bind.modality_trunks.audio.blocks.10.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.702206] image_bind.modality_trunks.audio.blocks.10.attn.out_proj.bias torch.Size([768]) False
[00:25:10.702238] image_bind.modality_trunks.audio.blocks.10.norm_1.weight torch.Size([768]) False
[00:25:10.702266] image_bind.modality_trunks.audio.blocks.10.norm_1.bias torch.Size([768]) False
[00:25:10.702297] image_bind.modality_trunks.audio.blocks.10.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.702327] image_bind.modality_trunks.audio.blocks.10.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.702358] image_bind.modality_trunks.audio.blocks.10.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.702387] image_bind.modality_trunks.audio.blocks.10.mlp.fc2.bias torch.Size([768]) False
[00:25:10.702419] image_bind.modality_trunks.audio.blocks.10.norm_2.weight torch.Size([768]) False
[00:25:10.702448] image_bind.modality_trunks.audio.blocks.10.norm_2.bias torch.Size([768]) False
[00:25:10.702479] image_bind.modality_trunks.audio.blocks.11.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.702513] image_bind.modality_trunks.audio.blocks.11.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.702543] image_bind.modality_trunks.audio.blocks.11.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.702678] image_bind.modality_trunks.audio.blocks.11.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.702709] image_bind.modality_trunks.audio.blocks.11.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.702738] image_bind.modality_trunks.audio.blocks.11.attn.out_proj.bias torch.Size([768]) False
[00:25:10.702770] image_bind.modality_trunks.audio.blocks.11.norm_1.weight torch.Size([768]) False
[00:25:10.702799] image_bind.modality_trunks.audio.blocks.11.norm_1.bias torch.Size([768]) False
[00:25:10.702835] image_bind.modality_trunks.audio.blocks.11.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.702864] image_bind.modality_trunks.audio.blocks.11.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.702896] image_bind.modality_trunks.audio.blocks.11.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.702925] image_bind.modality_trunks.audio.blocks.11.mlp.fc2.bias torch.Size([768]) False
[00:25:10.702956] image_bind.modality_trunks.audio.blocks.11.norm_2.weight torch.Size([768]) False
[00:25:10.702985] image_bind.modality_trunks.audio.blocks.11.norm_2.bias torch.Size([768]) False
[00:25:10.703024] image_bind.modality_trunks.depth.blocks.0.attn.in_proj_weight torch.Size([1152, 384]) False
[00:25:10.703053] image_bind.modality_trunks.depth.blocks.0.attn.in_proj_bias torch.Size([1152]) False
[00:25:10.703082] image_bind.modality_trunks.depth.blocks.0.attn.bias_k torch.Size([1, 1, 384]) False
[00:25:10.703111] image_bind.modality_trunks.depth.blocks.0.attn.bias_v torch.Size([1, 1, 384]) False
[00:25:10.703142] image_bind.modality_trunks.depth.blocks.0.attn.out_proj.weight torch.Size([384, 384]) False
[00:25:10.703171] image_bind.modality_trunks.depth.blocks.0.attn.out_proj.bias torch.Size([384]) False
[00:25:10.703203] image_bind.modality_trunks.depth.blocks.0.norm_1.weight torch.Size([384]) False
[00:25:10.703232] image_bind.modality_trunks.depth.blocks.0.norm_1.bias torch.Size([384]) False
[00:25:10.703263] image_bind.modality_trunks.depth.blocks.0.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.703294] image_bind.modality_trunks.depth.blocks.0.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.703327] image_bind.modality_trunks.depth.blocks.0.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.703356] image_bind.modality_trunks.depth.blocks.0.mlp.fc2.bias torch.Size([384]) False
[00:25:10.703387] image_bind.modality_trunks.depth.blocks.0.norm_2.weight torch.Size([384]) False
[00:25:10.703416] image_bind.modality_trunks.depth.blocks.0.norm_2.bias torch.Size([384]) False
[00:25:10.703447] image_bind.modality_trunks.depth.blocks.1.attn.in_proj_weight torch.Size([1152, 384]) False
[00:25:10.703476] image_bind.modality_trunks.depth.blocks.1.attn.in_proj_bias torch.Size([1152]) False
[00:25:10.703510] image_bind.modality_trunks.depth.blocks.1.attn.bias_k torch.Size([1, 1, 384]) False
[00:25:10.703539] image_bind.modality_trunks.depth.blocks.1.attn.bias_v torch.Size([1, 1, 384]) False
[00:25:10.703570] image_bind.modality_trunks.depth.blocks.1.attn.out_proj.weight torch.Size([384, 384]) False
[00:25:10.703599] image_bind.modality_trunks.depth.blocks.1.attn.out_proj.bias torch.Size([384]) False
[00:25:10.703631] image_bind.modality_trunks.depth.blocks.1.norm_1.weight torch.Size([384]) False
[00:25:10.703660] image_bind.modality_trunks.depth.blocks.1.norm_1.bias torch.Size([384]) False
[00:25:10.703691] image_bind.modality_trunks.depth.blocks.1.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.703720] image_bind.modality_trunks.depth.blocks.1.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.703752] image_bind.modality_trunks.depth.blocks.1.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.703781] image_bind.modality_trunks.depth.blocks.1.mlp.fc2.bias torch.Size([384]) False
[00:25:10.703817] image_bind.modality_trunks.depth.blocks.1.norm_2.weight torch.Size([384]) False
[00:25:10.703847] image_bind.modality_trunks.depth.blocks.1.norm_2.bias torch.Size([384]) False
[00:25:10.703878] image_bind.modality_trunks.depth.blocks.2.attn.in_proj_weight torch.Size([1152, 384]) False
[00:25:10.704011] image_bind.modality_trunks.depth.blocks.2.attn.in_proj_bias torch.Size([1152]) False
[00:25:10.704041] image_bind.modality_trunks.depth.blocks.2.attn.bias_k torch.Size([1, 1, 384]) False
[00:25:10.704070] image_bind.modality_trunks.depth.blocks.2.attn.bias_v torch.Size([1, 1, 384]) False
[00:25:10.704101] image_bind.modality_trunks.depth.blocks.2.attn.out_proj.weight torch.Size([384, 384]) False
[00:25:10.704130] image_bind.modality_trunks.depth.blocks.2.attn.out_proj.bias torch.Size([384]) False
[00:25:10.704162] image_bind.modality_trunks.depth.blocks.2.norm_1.weight torch.Size([384]) False
[00:25:10.704191] image_bind.modality_trunks.depth.blocks.2.norm_1.bias torch.Size([384]) False
[00:25:10.704222] image_bind.modality_trunks.depth.blocks.2.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.704251] image_bind.modality_trunks.depth.blocks.2.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.704286] image_bind.modality_trunks.depth.blocks.2.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.704316] image_bind.modality_trunks.depth.blocks.2.mlp.fc2.bias torch.Size([384]) False
[00:25:10.704347] image_bind.modality_trunks.depth.blocks.2.norm_2.weight torch.Size([384]) False
[00:25:10.704376] image_bind.modality_trunks.depth.blocks.2.norm_2.bias torch.Size([384]) False
[00:25:10.704408] image_bind.modality_trunks.depth.blocks.3.attn.in_proj_weight torch.Size([1152, 384]) False
[00:25:10.704437] image_bind.modality_trunks.depth.blocks.3.attn.in_proj_bias torch.Size([1152]) False
[00:25:10.704466] image_bind.modality_trunks.depth.blocks.3.attn.bias_k torch.Size([1, 1, 384]) False
[00:25:10.704500] image_bind.modality_trunks.depth.blocks.3.attn.bias_v torch.Size([1, 1, 384]) False
[00:25:10.704531] image_bind.modality_trunks.depth.blocks.3.attn.out_proj.weight torch.Size([384, 384]) False
[00:25:10.704560] image_bind.modality_trunks.depth.blocks.3.attn.out_proj.bias torch.Size([384]) False
[00:25:10.704591] image_bind.modality_trunks.depth.blocks.3.norm_1.weight torch.Size([384]) False
[00:25:10.704620] image_bind.modality_trunks.depth.blocks.3.norm_1.bias torch.Size([384]) False
[00:25:10.704652] image_bind.modality_trunks.depth.blocks.3.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.704686] image_bind.modality_trunks.depth.blocks.3.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.704717] image_bind.modality_trunks.depth.blocks.3.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.704747] image_bind.modality_trunks.depth.blocks.3.mlp.fc2.bias torch.Size([384]) False
[00:25:10.704778] image_bind.modality_trunks.depth.blocks.3.norm_2.weight torch.Size([384]) False
[00:25:10.704807] image_bind.modality_trunks.depth.blocks.3.norm_2.bias torch.Size([384]) False
[00:25:10.704838] image_bind.modality_trunks.depth.blocks.4.attn.in_proj_weight torch.Size([1152, 384]) False
[00:25:10.704868] image_bind.modality_trunks.depth.blocks.4.attn.in_proj_bias torch.Size([1152]) False
[00:25:10.704897] image_bind.modality_trunks.depth.blocks.4.attn.bias_k torch.Size([1, 1, 384]) False
[00:25:10.704926] image_bind.modality_trunks.depth.blocks.4.attn.bias_v torch.Size([1, 1, 384]) False
[00:25:10.704956] image_bind.modality_trunks.depth.blocks.4.attn.out_proj.weight torch.Size([384, 384]) False
[00:25:10.704986] image_bind.modality_trunks.depth.blocks.4.attn.out_proj.bias torch.Size([384]) False
[00:25:10.705017] image_bind.modality_trunks.depth.blocks.4.norm_1.weight torch.Size([384]) False
[00:25:10.705046] image_bind.modality_trunks.depth.blocks.4.norm_1.bias torch.Size([384]) False
[00:25:10.705077] image_bind.modality_trunks.depth.blocks.4.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.705112] image_bind.modality_trunks.depth.blocks.4.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.705143] image_bind.modality_trunks.depth.blocks.4.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.705172] image_bind.modality_trunks.depth.blocks.4.mlp.fc2.bias torch.Size([384]) False
[00:25:10.705203] image_bind.modality_trunks.depth.blocks.4.norm_2.weight torch.Size([384]) False
[00:25:10.705345] image_bind.modality_trunks.depth.blocks.4.norm_2.bias torch.Size([384]) False
[00:25:10.705378] image_bind.modality_trunks.depth.blocks.5.attn.in_proj_weight torch.Size([1152, 384]) False
[00:25:10.705407] image_bind.modality_trunks.depth.blocks.5.attn.in_proj_bias torch.Size([1152]) False
[00:25:10.705436] image_bind.modality_trunks.depth.blocks.5.attn.bias_k torch.Size([1, 1, 384]) False
[00:25:10.705468] image_bind.modality_trunks.depth.blocks.5.attn.bias_v torch.Size([1, 1, 384]) False
[00:25:10.705504] image_bind.modality_trunks.depth.blocks.5.attn.out_proj.weight torch.Size([384, 384]) False
[00:25:10.705533] image_bind.modality_trunks.depth.blocks.5.attn.out_proj.bias torch.Size([384]) False
[00:25:10.705565] image_bind.modality_trunks.depth.blocks.5.norm_1.weight torch.Size([384]) False
[00:25:10.705593] image_bind.modality_trunks.depth.blocks.5.norm_1.bias torch.Size([384]) False
[00:25:10.705625] image_bind.modality_trunks.depth.blocks.5.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.705654] image_bind.modality_trunks.depth.blocks.5.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.705686] image_bind.modality_trunks.depth.blocks.5.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.705715] image_bind.modality_trunks.depth.blocks.5.mlp.fc2.bias torch.Size([384]) False
[00:25:10.705746] image_bind.modality_trunks.depth.blocks.5.norm_2.weight torch.Size([384]) False
[00:25:10.705775] image_bind.modality_trunks.depth.blocks.5.norm_2.bias torch.Size([384]) False
[00:25:10.705807] image_bind.modality_trunks.depth.blocks.6.attn.in_proj_weight torch.Size([1152, 384]) False
[00:25:10.705836] image_bind.modality_trunks.depth.blocks.6.attn.in_proj_bias torch.Size([1152]) False
[00:25:10.705865] image_bind.modality_trunks.depth.blocks.6.attn.bias_k torch.Size([1, 1, 384]) False
[00:25:10.705894] image_bind.modality_trunks.depth.blocks.6.attn.bias_v torch.Size([1, 1, 384]) False
[00:25:10.705926] image_bind.modality_trunks.depth.blocks.6.attn.out_proj.weight torch.Size([384, 384]) False
[00:25:10.705958] image_bind.modality_trunks.depth.blocks.6.attn.out_proj.bias torch.Size([384]) False
[00:25:10.705989] image_bind.modality_trunks.depth.blocks.6.norm_1.weight torch.Size([384]) False
[00:25:10.706018] image_bind.modality_trunks.depth.blocks.6.norm_1.bias torch.Size([384]) False
[00:25:10.706049] image_bind.modality_trunks.depth.blocks.6.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.706078] image_bind.modality_trunks.depth.blocks.6.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.706110] image_bind.modality_trunks.depth.blocks.6.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.706139] image_bind.modality_trunks.depth.blocks.6.mlp.fc2.bias torch.Size([384]) False
[00:25:10.706170] image_bind.modality_trunks.depth.blocks.6.norm_2.weight torch.Size([384]) False
[00:25:10.706199] image_bind.modality_trunks.depth.blocks.6.norm_2.bias torch.Size([384]) False
[00:25:10.706230] image_bind.modality_trunks.depth.blocks.7.attn.in_proj_weight torch.Size([1152, 384]) False
[00:25:10.706260] image_bind.modality_trunks.depth.blocks.7.attn.in_proj_bias torch.Size([1152]) False
[00:25:10.706289] image_bind.modality_trunks.depth.blocks.7.attn.bias_k torch.Size([1, 1, 384]) False
[00:25:10.706318] image_bind.modality_trunks.depth.blocks.7.attn.bias_v torch.Size([1, 1, 384]) False
[00:25:10.706349] image_bind.modality_trunks.depth.blocks.7.attn.out_proj.weight torch.Size([384, 384]) False
[00:25:10.706380] image_bind.modality_trunks.depth.blocks.7.attn.out_proj.bias torch.Size([384]) False
[00:25:10.706412] image_bind.modality_trunks.depth.blocks.7.norm_1.weight torch.Size([384]) False
[00:25:10.706441] image_bind.modality_trunks.depth.blocks.7.norm_1.bias torch.Size([384]) False
[00:25:10.706472] image_bind.modality_trunks.depth.blocks.7.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.706507] image_bind.modality_trunks.depth.blocks.7.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.706538] image_bind.modality_trunks.depth.blocks.7.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.706567] image_bind.modality_trunks.depth.blocks.7.mlp.fc2.bias torch.Size([384]) False
[00:25:10.706705] image_bind.modality_trunks.depth.blocks.7.norm_2.weight torch.Size([384]) False
[00:25:10.706735] image_bind.modality_trunks.depth.blocks.7.norm_2.bias torch.Size([384]) False
[00:25:10.706767] image_bind.modality_trunks.depth.blocks.8.attn.in_proj_weight torch.Size([1152, 384]) False
[00:25:10.706797] image_bind.modality_trunks.depth.blocks.8.attn.in_proj_bias torch.Size([1152]) False
[00:25:10.706826] image_bind.modality_trunks.depth.blocks.8.attn.bias_k torch.Size([1, 1, 384]) False
[00:25:10.706860] image_bind.modality_trunks.depth.blocks.8.attn.bias_v torch.Size([1, 1, 384]) False
[00:25:10.706892] image_bind.modality_trunks.depth.blocks.8.attn.out_proj.weight torch.Size([384, 384]) False
[00:25:10.706921] image_bind.modality_trunks.depth.blocks.8.attn.out_proj.bias torch.Size([384]) False
[00:25:10.706952] image_bind.modality_trunks.depth.blocks.8.norm_1.weight torch.Size([384]) False
[00:25:10.706981] image_bind.modality_trunks.depth.blocks.8.norm_1.bias torch.Size([384]) False
[00:25:10.707013] image_bind.modality_trunks.depth.blocks.8.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.707042] image_bind.modality_trunks.depth.blocks.8.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.707073] image_bind.modality_trunks.depth.blocks.8.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.707103] image_bind.modality_trunks.depth.blocks.8.mlp.fc2.bias torch.Size([384]) False
[00:25:10.707134] image_bind.modality_trunks.depth.blocks.8.norm_2.weight torch.Size([384]) False
[00:25:10.707163] image_bind.modality_trunks.depth.blocks.8.norm_2.bias torch.Size([384]) False
[00:25:10.707194] image_bind.modality_trunks.depth.blocks.9.attn.in_proj_weight torch.Size([1152, 384]) False
[00:25:10.707224] image_bind.modality_trunks.depth.blocks.9.attn.in_proj_bias torch.Size([1152]) False
[00:25:10.707253] image_bind.modality_trunks.depth.blocks.9.attn.bias_k torch.Size([1, 1, 384]) False
[00:25:10.707283] image_bind.modality_trunks.depth.blocks.9.attn.bias_v torch.Size([1, 1, 384]) False
[00:25:10.707313] image_bind.modality_trunks.depth.blocks.9.attn.out_proj.weight torch.Size([384, 384]) False
[00:25:10.707347] image_bind.modality_trunks.depth.blocks.9.attn.out_proj.bias torch.Size([384]) False
[00:25:10.707379] image_bind.modality_trunks.depth.blocks.9.norm_1.weight torch.Size([384]) False
[00:25:10.707408] image_bind.modality_trunks.depth.blocks.9.norm_1.bias torch.Size([384]) False
[00:25:10.707440] image_bind.modality_trunks.depth.blocks.9.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.707469] image_bind.modality_trunks.depth.blocks.9.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.707507] image_bind.modality_trunks.depth.blocks.9.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.707536] image_bind.modality_trunks.depth.blocks.9.mlp.fc2.bias torch.Size([384]) False
[00:25:10.707568] image_bind.modality_trunks.depth.blocks.9.norm_2.weight torch.Size([384]) False
[00:25:10.707597] image_bind.modality_trunks.depth.blocks.9.norm_2.bias torch.Size([384]) False
[00:25:10.707629] image_bind.modality_trunks.depth.blocks.10.attn.in_proj_weight torch.Size([1152, 384]) False
[00:25:10.707658] image_bind.modality_trunks.depth.blocks.10.attn.in_proj_bias torch.Size([1152]) False
[00:25:10.707688] image_bind.modality_trunks.depth.blocks.10.attn.bias_k torch.Size([1, 1, 384]) False
[00:25:10.707723] image_bind.modality_trunks.depth.blocks.10.attn.bias_v torch.Size([1, 1, 384]) False
[00:25:10.707753] image_bind.modality_trunks.depth.blocks.10.attn.out_proj.weight torch.Size([384, 384]) False
[00:25:10.707782] image_bind.modality_trunks.depth.blocks.10.attn.out_proj.bias torch.Size([384]) False
[00:25:10.707815] image_bind.modality_trunks.depth.blocks.10.norm_1.weight torch.Size([384]) False
[00:25:10.707845] image_bind.modality_trunks.depth.blocks.10.norm_1.bias torch.Size([384]) False
[00:25:10.707878] image_bind.modality_trunks.depth.blocks.10.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.707908] image_bind.modality_trunks.depth.blocks.10.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.708052] image_bind.modality_trunks.depth.blocks.10.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.708082] image_bind.modality_trunks.depth.blocks.10.mlp.fc2.bias torch.Size([384]) False
[00:25:10.708114] image_bind.modality_trunks.depth.blocks.10.norm_2.weight torch.Size([384]) False
[00:25:10.708144] image_bind.modality_trunks.depth.blocks.10.norm_2.bias torch.Size([384]) False
[00:25:10.708177] image_bind.modality_trunks.depth.blocks.11.attn.in_proj_weight torch.Size([1152, 384]) False
[00:25:10.708208] image_bind.modality_trunks.depth.blocks.11.attn.in_proj_bias torch.Size([1152]) False
[00:25:10.708237] image_bind.modality_trunks.depth.blocks.11.attn.bias_k torch.Size([1, 1, 384]) False
[00:25:10.708266] image_bind.modality_trunks.depth.blocks.11.attn.bias_v torch.Size([1, 1, 384]) False
[00:25:10.708297] image_bind.modality_trunks.depth.blocks.11.attn.out_proj.weight torch.Size([384, 384]) False
[00:25:10.708326] image_bind.modality_trunks.depth.blocks.11.attn.out_proj.bias torch.Size([384]) False
[00:25:10.708357] image_bind.modality_trunks.depth.blocks.11.norm_1.weight torch.Size([384]) False
[00:25:10.708387] image_bind.modality_trunks.depth.blocks.11.norm_1.bias torch.Size([384]) False
[00:25:10.708418] image_bind.modality_trunks.depth.blocks.11.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.708447] image_bind.modality_trunks.depth.blocks.11.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.708479] image_bind.modality_trunks.depth.blocks.11.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.708513] image_bind.modality_trunks.depth.blocks.11.mlp.fc2.bias torch.Size([384]) False
[00:25:10.708545] image_bind.modality_trunks.depth.blocks.11.norm_2.weight torch.Size([384]) False
[00:25:10.708573] image_bind.modality_trunks.depth.blocks.11.norm_2.bias torch.Size([384]) False
[00:25:10.708613] image_bind.modality_trunks.thermal.blocks.0.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.708644] image_bind.modality_trunks.thermal.blocks.0.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.708672] image_bind.modality_trunks.thermal.blocks.0.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.708701] image_bind.modality_trunks.thermal.blocks.0.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.708732] image_bind.modality_trunks.thermal.blocks.0.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.708762] image_bind.modality_trunks.thermal.blocks.0.attn.out_proj.bias torch.Size([768]) False
[00:25:10.708793] image_bind.modality_trunks.thermal.blocks.0.norm_1.weight torch.Size([768]) False
[00:25:10.708822] image_bind.modality_trunks.thermal.blocks.0.norm_1.bias torch.Size([768]) False
[00:25:10.708853] image_bind.modality_trunks.thermal.blocks.0.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.708882] image_bind.modality_trunks.thermal.blocks.0.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.708914] image_bind.modality_trunks.thermal.blocks.0.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.708943] image_bind.modality_trunks.thermal.blocks.0.mlp.fc2.bias torch.Size([768]) False
[00:25:10.708974] image_bind.modality_trunks.thermal.blocks.0.norm_2.weight torch.Size([768]) False
[00:25:10.709002] image_bind.modality_trunks.thermal.blocks.0.norm_2.bias torch.Size([768]) False
[00:25:10.709034] image_bind.modality_trunks.thermal.blocks.1.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.709063] image_bind.modality_trunks.thermal.blocks.1.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.709092] image_bind.modality_trunks.thermal.blocks.1.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.709124] image_bind.modality_trunks.thermal.blocks.1.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.709156] image_bind.modality_trunks.thermal.blocks.1.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.709185] image_bind.modality_trunks.thermal.blocks.1.attn.out_proj.bias torch.Size([768]) False
[00:25:10.709217] image_bind.modality_trunks.thermal.blocks.1.norm_1.weight torch.Size([768]) False
[00:25:10.709354] image_bind.modality_trunks.thermal.blocks.1.norm_1.bias torch.Size([768]) False
[00:25:10.709387] image_bind.modality_trunks.thermal.blocks.1.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.709416] image_bind.modality_trunks.thermal.blocks.1.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.709448] image_bind.modality_trunks.thermal.blocks.1.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.709477] image_bind.modality_trunks.thermal.blocks.1.mlp.fc2.bias torch.Size([768]) False
[00:25:10.709516] image_bind.modality_trunks.thermal.blocks.1.norm_2.weight torch.Size([768]) False
[00:25:10.709546] image_bind.modality_trunks.thermal.blocks.1.norm_2.bias torch.Size([768]) False
[00:25:10.709579] image_bind.modality_trunks.thermal.blocks.2.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.709608] image_bind.modality_trunks.thermal.blocks.2.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.709637] image_bind.modality_trunks.thermal.blocks.2.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.709667] image_bind.modality_trunks.thermal.blocks.2.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.709697] image_bind.modality_trunks.thermal.blocks.2.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.709727] image_bind.modality_trunks.thermal.blocks.2.attn.out_proj.bias torch.Size([768]) False
[00:25:10.709758] image_bind.modality_trunks.thermal.blocks.2.norm_1.weight torch.Size([768]) False
[00:25:10.709787] image_bind.modality_trunks.thermal.blocks.2.norm_1.bias torch.Size([768]) False
[00:25:10.709818] image_bind.modality_trunks.thermal.blocks.2.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.709847] image_bind.modality_trunks.thermal.blocks.2.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.709879] image_bind.modality_trunks.thermal.blocks.2.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.709908] image_bind.modality_trunks.thermal.blocks.2.mlp.fc2.bias torch.Size([768]) False
[00:25:10.709945] image_bind.modality_trunks.thermal.blocks.2.norm_2.weight torch.Size([768]) False
[00:25:10.709973] image_bind.modality_trunks.thermal.blocks.2.norm_2.bias torch.Size([768]) False
[00:25:10.710005] image_bind.modality_trunks.thermal.blocks.3.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.710034] image_bind.modality_trunks.thermal.blocks.3.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.710063] image_bind.modality_trunks.thermal.blocks.3.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.710093] image_bind.modality_trunks.thermal.blocks.3.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.710123] image_bind.modality_trunks.thermal.blocks.3.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.710153] image_bind.modality_trunks.thermal.blocks.3.attn.out_proj.bias torch.Size([768]) False
[00:25:10.710184] image_bind.modality_trunks.thermal.blocks.3.norm_1.weight torch.Size([768]) False
[00:25:10.710213] image_bind.modality_trunks.thermal.blocks.3.norm_1.bias torch.Size([768]) False
[00:25:10.710244] image_bind.modality_trunks.thermal.blocks.3.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.710273] image_bind.modality_trunks.thermal.blocks.3.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.710304] image_bind.modality_trunks.thermal.blocks.3.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.710339] image_bind.modality_trunks.thermal.blocks.3.mlp.fc2.bias torch.Size([768]) False
[00:25:10.710371] image_bind.modality_trunks.thermal.blocks.3.norm_2.weight torch.Size([768]) False
[00:25:10.710400] image_bind.modality_trunks.thermal.blocks.3.norm_2.bias torch.Size([768]) False
[00:25:10.710431] image_bind.modality_trunks.thermal.blocks.4.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.710460] image_bind.modality_trunks.thermal.blocks.4.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.710495] image_bind.modality_trunks.thermal.blocks.4.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.710524] image_bind.modality_trunks.thermal.blocks.4.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.710555] image_bind.modality_trunks.thermal.blocks.4.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.710718] image_bind.modality_trunks.thermal.blocks.4.attn.out_proj.bias torch.Size([768]) False
[00:25:10.710751] image_bind.modality_trunks.thermal.blocks.4.norm_1.weight torch.Size([768]) False
[00:25:10.710780] image_bind.modality_trunks.thermal.blocks.4.norm_1.bias torch.Size([768]) False
[00:25:10.710811] image_bind.modality_trunks.thermal.blocks.4.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.710841] image_bind.modality_trunks.thermal.blocks.4.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.710873] image_bind.modality_trunks.thermal.blocks.4.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.710902] image_bind.modality_trunks.thermal.blocks.4.mlp.fc2.bias torch.Size([768]) False
[00:25:10.710934] image_bind.modality_trunks.thermal.blocks.4.norm_2.weight torch.Size([768]) False
[00:25:10.710963] image_bind.modality_trunks.thermal.blocks.4.norm_2.bias torch.Size([768]) False
[00:25:10.710994] image_bind.modality_trunks.thermal.blocks.5.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.711024] image_bind.modality_trunks.thermal.blocks.5.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.711054] image_bind.modality_trunks.thermal.blocks.5.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.711083] image_bind.modality_trunks.thermal.blocks.5.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.711116] image_bind.modality_trunks.thermal.blocks.5.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.711146] image_bind.modality_trunks.thermal.blocks.5.attn.out_proj.bias torch.Size([768]) False
[00:25:10.711178] image_bind.modality_trunks.thermal.blocks.5.norm_1.weight torch.Size([768]) False
[00:25:10.711207] image_bind.modality_trunks.thermal.blocks.5.norm_1.bias torch.Size([768]) False
[00:25:10.711239] image_bind.modality_trunks.thermal.blocks.5.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.711268] image_bind.modality_trunks.thermal.blocks.5.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.711300] image_bind.modality_trunks.thermal.blocks.5.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.711330] image_bind.modality_trunks.thermal.blocks.5.mlp.fc2.bias torch.Size([768]) False
[00:25:10.711361] image_bind.modality_trunks.thermal.blocks.5.norm_2.weight torch.Size([768]) False
[00:25:10.711390] image_bind.modality_trunks.thermal.blocks.5.norm_2.bias torch.Size([768]) False
[00:25:10.711422] image_bind.modality_trunks.thermal.blocks.6.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.711452] image_bind.modality_trunks.thermal.blocks.6.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.711481] image_bind.modality_trunks.thermal.blocks.6.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.711517] image_bind.modality_trunks.thermal.blocks.6.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.711549] image_bind.modality_trunks.thermal.blocks.6.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.711584] image_bind.modality_trunks.thermal.blocks.6.attn.out_proj.bias torch.Size([768]) False
[00:25:10.711615] image_bind.modality_trunks.thermal.blocks.6.norm_1.weight torch.Size([768]) False
[00:25:10.711644] image_bind.modality_trunks.thermal.blocks.6.norm_1.bias torch.Size([768]) False
[00:25:10.711676] image_bind.modality_trunks.thermal.blocks.6.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.711706] image_bind.modality_trunks.thermal.blocks.6.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.711738] image_bind.modality_trunks.thermal.blocks.6.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.711767] image_bind.modality_trunks.thermal.blocks.6.mlp.fc2.bias torch.Size([768]) False
[00:25:10.711799] image_bind.modality_trunks.thermal.blocks.6.norm_2.weight torch.Size([768]) False
[00:25:10.711828] image_bind.modality_trunks.thermal.blocks.6.norm_2.bias torch.Size([768]) False
[00:25:10.711862] image_bind.modality_trunks.thermal.blocks.7.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.711891] image_bind.modality_trunks.thermal.blocks.7.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.711920] image_bind.modality_trunks.thermal.blocks.7.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.712091] image_bind.modality_trunks.thermal.blocks.7.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.712123] image_bind.modality_trunks.thermal.blocks.7.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.712152] image_bind.modality_trunks.thermal.blocks.7.attn.out_proj.bias torch.Size([768]) False
[00:25:10.712190] image_bind.modality_trunks.thermal.blocks.7.norm_1.weight torch.Size([768]) False
[00:25:10.712219] image_bind.modality_trunks.thermal.blocks.7.norm_1.bias torch.Size([768]) False
[00:25:10.712251] image_bind.modality_trunks.thermal.blocks.7.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.712281] image_bind.modality_trunks.thermal.blocks.7.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.712312] image_bind.modality_trunks.thermal.blocks.7.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.712342] image_bind.modality_trunks.thermal.blocks.7.mlp.fc2.bias torch.Size([768]) False
[00:25:10.712373] image_bind.modality_trunks.thermal.blocks.7.norm_2.weight torch.Size([768]) False
[00:25:10.712402] image_bind.modality_trunks.thermal.blocks.7.norm_2.bias torch.Size([768]) False
[00:25:10.712435] image_bind.modality_trunks.thermal.blocks.8.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.712464] image_bind.modality_trunks.thermal.blocks.8.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.712498] image_bind.modality_trunks.thermal.blocks.8.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.712528] image_bind.modality_trunks.thermal.blocks.8.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.712560] image_bind.modality_trunks.thermal.blocks.8.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.712593] image_bind.modality_trunks.thermal.blocks.8.attn.out_proj.bias torch.Size([768]) False
[00:25:10.712625] image_bind.modality_trunks.thermal.blocks.8.norm_1.weight torch.Size([768]) False
[00:25:10.712654] image_bind.modality_trunks.thermal.blocks.8.norm_1.bias torch.Size([768]) False
[00:25:10.712685] image_bind.modality_trunks.thermal.blocks.8.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.712715] image_bind.modality_trunks.thermal.blocks.8.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.712746] image_bind.modality_trunks.thermal.blocks.8.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.712775] image_bind.modality_trunks.thermal.blocks.8.mlp.fc2.bias torch.Size([768]) False
[00:25:10.712808] image_bind.modality_trunks.thermal.blocks.8.norm_2.weight torch.Size([768]) False
[00:25:10.712836] image_bind.modality_trunks.thermal.blocks.8.norm_2.bias torch.Size([768]) False
[00:25:10.712868] image_bind.modality_trunks.thermal.blocks.9.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.712898] image_bind.modality_trunks.thermal.blocks.9.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.712927] image_bind.modality_trunks.thermal.blocks.9.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.712957] image_bind.modality_trunks.thermal.blocks.9.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.712988] image_bind.modality_trunks.thermal.blocks.9.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.713017] image_bind.modality_trunks.thermal.blocks.9.attn.out_proj.bias torch.Size([768]) False
[00:25:10.713049] image_bind.modality_trunks.thermal.blocks.9.norm_1.weight torch.Size([768]) False
[00:25:10.713077] image_bind.modality_trunks.thermal.blocks.9.norm_1.bias torch.Size([768]) False
[00:25:10.713109] image_bind.modality_trunks.thermal.blocks.9.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.713138] image_bind.modality_trunks.thermal.blocks.9.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.713170] image_bind.modality_trunks.thermal.blocks.9.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.713199] image_bind.modality_trunks.thermal.blocks.9.mlp.fc2.bias torch.Size([768]) False
[00:25:10.713231] image_bind.modality_trunks.thermal.blocks.9.norm_2.weight torch.Size([768]) False
[00:25:10.713260] image_bind.modality_trunks.thermal.blocks.9.norm_2.bias torch.Size([768]) False
[00:25:10.713393] image_bind.modality_trunks.thermal.blocks.10.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.713423] image_bind.modality_trunks.thermal.blocks.10.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.713452] image_bind.modality_trunks.thermal.blocks.10.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.713481] image_bind.modality_trunks.thermal.blocks.10.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.713516] image_bind.modality_trunks.thermal.blocks.10.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.713546] image_bind.modality_trunks.thermal.blocks.10.attn.out_proj.bias torch.Size([768]) False
[00:25:10.713578] image_bind.modality_trunks.thermal.blocks.10.norm_1.weight torch.Size([768]) False
[00:25:10.713607] image_bind.modality_trunks.thermal.blocks.10.norm_1.bias torch.Size([768]) False
[00:25:10.713638] image_bind.modality_trunks.thermal.blocks.10.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.713668] image_bind.modality_trunks.thermal.blocks.10.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.713700] image_bind.modality_trunks.thermal.blocks.10.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.713729] image_bind.modality_trunks.thermal.blocks.10.mlp.fc2.bias torch.Size([768]) False
[00:25:10.713761] image_bind.modality_trunks.thermal.blocks.10.norm_2.weight torch.Size([768]) False
[00:25:10.713790] image_bind.modality_trunks.thermal.blocks.10.norm_2.bias torch.Size([768]) False
[00:25:10.713822] image_bind.modality_trunks.thermal.blocks.11.attn.in_proj_weight torch.Size([2304, 768]) False
[00:25:10.713851] image_bind.modality_trunks.thermal.blocks.11.attn.in_proj_bias torch.Size([2304]) False
[00:25:10.713885] image_bind.modality_trunks.thermal.blocks.11.attn.bias_k torch.Size([1, 1, 768]) False
[00:25:10.713915] image_bind.modality_trunks.thermal.blocks.11.attn.bias_v torch.Size([1, 1, 768]) False
[00:25:10.713946] image_bind.modality_trunks.thermal.blocks.11.attn.out_proj.weight torch.Size([768, 768]) False
[00:25:10.713976] image_bind.modality_trunks.thermal.blocks.11.attn.out_proj.bias torch.Size([768]) False
[00:25:10.714007] image_bind.modality_trunks.thermal.blocks.11.norm_1.weight torch.Size([768]) False
[00:25:10.714036] image_bind.modality_trunks.thermal.blocks.11.norm_1.bias torch.Size([768]) False
[00:25:10.714068] image_bind.modality_trunks.thermal.blocks.11.mlp.fc1.weight torch.Size([3072, 768]) False
[00:25:10.714097] image_bind.modality_trunks.thermal.blocks.11.mlp.fc1.bias torch.Size([3072]) False
[00:25:10.714129] image_bind.modality_trunks.thermal.blocks.11.mlp.fc2.weight torch.Size([768, 3072]) False
[00:25:10.714158] image_bind.modality_trunks.thermal.blocks.11.mlp.fc2.bias torch.Size([768]) False
[00:25:10.714190] image_bind.modality_trunks.thermal.blocks.11.norm_2.weight torch.Size([768]) False
[00:25:10.714219] image_bind.modality_trunks.thermal.blocks.11.norm_2.bias torch.Size([768]) False
[00:25:10.714260] image_bind.modality_trunks.imu.blocks.0.attn.in_proj_weight torch.Size([1536, 512]) False
[00:25:10.714290] image_bind.modality_trunks.imu.blocks.0.attn.in_proj_bias torch.Size([1536]) False
[00:25:10.714323] image_bind.modality_trunks.imu.blocks.0.attn.bias_k torch.Size([1, 1, 512]) False
[00:25:10.714353] image_bind.modality_trunks.imu.blocks.0.attn.bias_v torch.Size([1, 1, 512]) False
[00:25:10.714385] image_bind.modality_trunks.imu.blocks.0.attn.out_proj.weight torch.Size([512, 512]) False
[00:25:10.714414] image_bind.modality_trunks.imu.blocks.0.attn.out_proj.bias torch.Size([512]) False
[00:25:10.714446] image_bind.modality_trunks.imu.blocks.0.norm_1.weight torch.Size([512]) False
[00:25:10.714475] image_bind.modality_trunks.imu.blocks.0.norm_1.bias torch.Size([512]) False
[00:25:10.714512] image_bind.modality_trunks.imu.blocks.0.mlp.fc1.weight torch.Size([2048, 512]) False
[00:25:10.714542] image_bind.modality_trunks.imu.blocks.0.mlp.fc1.bias torch.Size([2048]) False
[00:25:10.714574] image_bind.modality_trunks.imu.blocks.0.mlp.fc2.weight torch.Size([512, 2048]) False
[00:25:10.714603] image_bind.modality_trunks.imu.blocks.0.mlp.fc2.bias torch.Size([512]) False
[00:25:10.714704] image_bind.modality_trunks.imu.blocks.0.norm_2.weight torch.Size([512]) False
[00:25:10.714734] image_bind.modality_trunks.imu.blocks.0.norm_2.bias torch.Size([512]) False
[00:25:10.714766] image_bind.modality_trunks.imu.blocks.1.attn.in_proj_weight torch.Size([1536, 512]) False
[00:25:10.714796] image_bind.modality_trunks.imu.blocks.1.attn.in_proj_bias torch.Size([1536]) False
[00:25:10.714826] image_bind.modality_trunks.imu.blocks.1.attn.bias_k torch.Size([1, 1, 512]) False
[00:25:10.714858] image_bind.modality_trunks.imu.blocks.1.attn.bias_v torch.Size([1, 1, 512]) False
[00:25:10.714889] image_bind.modality_trunks.imu.blocks.1.attn.out_proj.weight torch.Size([512, 512]) False
[00:25:10.714918] image_bind.modality_trunks.imu.blocks.1.attn.out_proj.bias torch.Size([512]) False
[00:25:10.714950] image_bind.modality_trunks.imu.blocks.1.norm_1.weight torch.Size([512]) False
[00:25:10.714979] image_bind.modality_trunks.imu.blocks.1.norm_1.bias torch.Size([512]) False
[00:25:10.715011] image_bind.modality_trunks.imu.blocks.1.mlp.fc1.weight torch.Size([2048, 512]) False
[00:25:10.715040] image_bind.modality_trunks.imu.blocks.1.mlp.fc1.bias torch.Size([2048]) False
[00:25:10.715072] image_bind.modality_trunks.imu.blocks.1.mlp.fc2.weight torch.Size([512, 2048]) False
[00:25:10.715133] image_bind.modality_trunks.imu.blocks.1.mlp.fc2.bias torch.Size([512]) False
[00:25:10.715166] image_bind.modality_trunks.imu.blocks.1.norm_2.weight torch.Size([512]) False
[00:25:10.715195] image_bind.modality_trunks.imu.blocks.1.norm_2.bias torch.Size([512]) False
[00:25:10.715227] image_bind.modality_trunks.imu.blocks.2.attn.in_proj_weight torch.Size([1536, 512]) False
[00:25:10.715258] image_bind.modality_trunks.imu.blocks.2.attn.in_proj_bias torch.Size([1536]) False
[00:25:10.715289] image_bind.modality_trunks.imu.blocks.2.attn.bias_k torch.Size([1, 1, 512]) False
[00:25:10.715319] image_bind.modality_trunks.imu.blocks.2.attn.bias_v torch.Size([1, 1, 512]) False
[00:25:10.715350] image_bind.modality_trunks.imu.blocks.2.attn.out_proj.weight torch.Size([512, 512]) False
[00:25:10.715380] image_bind.modality_trunks.imu.blocks.2.attn.out_proj.bias torch.Size([512]) False
[00:25:10.715412] image_bind.modality_trunks.imu.blocks.2.norm_1.weight torch.Size([512]) False
[00:25:10.715441] image_bind.modality_trunks.imu.blocks.2.norm_1.bias torch.Size([512]) False
[00:25:10.715473] image_bind.modality_trunks.imu.blocks.2.mlp.fc1.weight torch.Size([2048, 512]) False
[00:25:10.715508] image_bind.modality_trunks.imu.blocks.2.mlp.fc1.bias torch.Size([2048]) False
[00:25:10.715540] image_bind.modality_trunks.imu.blocks.2.mlp.fc2.weight torch.Size([512, 2048]) False
[00:25:10.715569] image_bind.modality_trunks.imu.blocks.2.mlp.fc2.bias torch.Size([512]) False
[00:25:10.715601] image_bind.modality_trunks.imu.blocks.2.norm_2.weight torch.Size([512]) False
[00:25:10.715630] image_bind.modality_trunks.imu.blocks.2.norm_2.bias torch.Size([512]) False
[00:25:10.715662] image_bind.modality_trunks.imu.blocks.3.attn.in_proj_weight torch.Size([1536, 512]) False
[00:25:10.715692] image_bind.modality_trunks.imu.blocks.3.attn.in_proj_bias torch.Size([1536]) False
[00:25:10.715726] image_bind.modality_trunks.imu.blocks.3.attn.bias_k torch.Size([1, 1, 512]) False
[00:25:10.715756] image_bind.modality_trunks.imu.blocks.3.attn.bias_v torch.Size([1, 1, 512]) False
[00:25:10.715787] image_bind.modality_trunks.imu.blocks.3.attn.out_proj.weight torch.Size([512, 512]) False
[00:25:10.715816] image_bind.modality_trunks.imu.blocks.3.attn.out_proj.bias torch.Size([512]) False
[00:25:10.715849] image_bind.modality_trunks.imu.blocks.3.norm_1.weight torch.Size([512]) False
[00:25:10.715878] image_bind.modality_trunks.imu.blocks.3.norm_1.bias torch.Size([512]) False
[00:25:10.715909] image_bind.modality_trunks.imu.blocks.3.mlp.fc1.weight torch.Size([2048, 512]) False
[00:25:10.715939] image_bind.modality_trunks.imu.blocks.3.mlp.fc1.bias torch.Size([2048]) False
[00:25:10.715970] image_bind.modality_trunks.imu.blocks.3.mlp.fc2.weight torch.Size([512, 2048]) False
[00:25:10.716087] image_bind.modality_trunks.imu.blocks.3.mlp.fc2.bias torch.Size([512]) False
[00:25:10.716120] image_bind.modality_trunks.imu.blocks.3.norm_2.weight torch.Size([512]) False
[00:25:10.716149] image_bind.modality_trunks.imu.blocks.3.norm_2.bias torch.Size([512]) False
[00:25:10.716181] image_bind.modality_trunks.imu.blocks.4.attn.in_proj_weight torch.Size([1536, 512]) False
[00:25:10.716211] image_bind.modality_trunks.imu.blocks.4.attn.in_proj_bias torch.Size([1536]) False
[00:25:10.716245] image_bind.modality_trunks.imu.blocks.4.attn.bias_k torch.Size([1, 1, 512]) False
[00:25:10.716274] image_bind.modality_trunks.imu.blocks.4.attn.bias_v torch.Size([1, 1, 512]) False
[00:25:10.716305] image_bind.modality_trunks.imu.blocks.4.attn.out_proj.weight torch.Size([512, 512]) False
[00:25:10.716334] image_bind.modality_trunks.imu.blocks.4.attn.out_proj.bias torch.Size([512]) False
[00:25:10.716366] image_bind.modality_trunks.imu.blocks.4.norm_1.weight torch.Size([512]) False
[00:25:10.716395] image_bind.modality_trunks.imu.blocks.4.norm_1.bias torch.Size([512]) False
[00:25:10.716426] image_bind.modality_trunks.imu.blocks.4.mlp.fc1.weight torch.Size([2048, 512]) False
[00:25:10.716455] image_bind.modality_trunks.imu.blocks.4.mlp.fc1.bias torch.Size([2048]) False
[00:25:10.716492] image_bind.modality_trunks.imu.blocks.4.mlp.fc2.weight torch.Size([512, 2048]) False
[00:25:10.716522] image_bind.modality_trunks.imu.blocks.4.mlp.fc2.bias torch.Size([512]) False
[00:25:10.716554] image_bind.modality_trunks.imu.blocks.4.norm_2.weight torch.Size([512]) False
[00:25:10.716583] image_bind.modality_trunks.imu.blocks.4.norm_2.bias torch.Size([512]) False
[00:25:10.716615] image_bind.modality_trunks.imu.blocks.5.attn.in_proj_weight torch.Size([1536, 512]) False
[00:25:10.716644] image_bind.modality_trunks.imu.blocks.5.attn.in_proj_bias torch.Size([1536]) False
[00:25:10.716673] image_bind.modality_trunks.imu.blocks.5.attn.bias_k torch.Size([1, 1, 512]) False
[00:25:10.716703] image_bind.modality_trunks.imu.blocks.5.attn.bias_v torch.Size([1, 1, 512]) False
[00:25:10.716735] image_bind.modality_trunks.imu.blocks.5.attn.out_proj.weight torch.Size([512, 512]) False
[00:25:10.716767] image_bind.modality_trunks.imu.blocks.5.attn.out_proj.bias torch.Size([512]) False
[00:25:10.716798] image_bind.modality_trunks.imu.blocks.5.norm_1.weight torch.Size([512]) False
[00:25:10.716827] image_bind.modality_trunks.imu.blocks.5.norm_1.bias torch.Size([512]) False
[00:25:10.716859] image_bind.modality_trunks.imu.blocks.5.mlp.fc1.weight torch.Size([2048, 512]) False
[00:25:10.716889] image_bind.modality_trunks.imu.blocks.5.mlp.fc1.bias torch.Size([2048]) False
[00:25:10.716920] image_bind.modality_trunks.imu.blocks.5.mlp.fc2.weight torch.Size([512, 2048]) False
[00:25:10.716949] image_bind.modality_trunks.imu.blocks.5.mlp.fc2.bias torch.Size([512]) False
[00:25:10.716981] image_bind.modality_trunks.imu.blocks.5.norm_2.weight torch.Size([512]) False
[00:25:10.717009] image_bind.modality_trunks.imu.blocks.5.norm_2.bias torch.Size([512]) False
[00:25:10.717046] image_bind.modality_heads.vision.0.weight torch.Size([1280]) False
[00:25:10.717076] image_bind.modality_heads.vision.0.bias torch.Size([1280]) False
[00:25:10.717109] image_bind.modality_heads.vision.2.weight torch.Size([1024, 1280]) False
[00:25:10.717144] image_bind.modality_heads.text.proj.0.weight torch.Size([1024]) False
[00:25:10.717173] image_bind.modality_heads.text.proj.0.bias torch.Size([1024]) False
[00:25:10.717204] image_bind.modality_heads.text.proj.1.weight torch.Size([1024, 1024]) False
[00:25:10.717237] image_bind.modality_heads.audio.0.weight torch.Size([768]) False
[00:25:10.717266] image_bind.modality_heads.audio.0.bias torch.Size([768]) False
[00:25:10.717300] image_bind.modality_heads.audio.2.weight torch.Size([1024, 768]) False
[00:25:10.717333] image_bind.modality_heads.depth.0.weight torch.Size([384]) False
[00:25:10.717362] image_bind.modality_heads.depth.0.bias torch.Size([384]) False
[00:25:10.717394] image_bind.modality_heads.depth.2.weight torch.Size([1024, 384]) False
[00:25:10.717500] image_bind.modality_heads.thermal.0.weight torch.Size([768]) False
[00:25:10.717530] image_bind.modality_heads.thermal.0.bias torch.Size([768]) False
[00:25:10.717562] image_bind.modality_heads.thermal.2.weight torch.Size([1024, 768]) False
[00:25:10.717593] image_bind.modality_heads.imu.0.weight torch.Size([512]) False
[00:25:10.717622] image_bind.modality_heads.imu.0.bias torch.Size([512]) False
[00:25:10.717656] image_bind.modality_heads.imu.3.weight torch.Size([1024, 512]) False
[00:25:10.717688] image_bind.modality_heads.point.0.weight torch.Size([512]) False
[00:25:10.717722] image_bind.modality_heads.point.0.bias torch.Size([512]) False
[00:25:10.717754] image_bind.modality_heads.point.2.weight torch.Size([1024, 512]) False
[00:25:10.717791] image_bind.modality_postprocessors.text.1.log_logit_scale torch.Size([]) False
[00:25:10.717841] image_bind.point_trunk.pc_projection torch.Size([768, 512]) False
[00:25:10.717873] image_bind.point_trunk.point_encoder.cls_token torch.Size([1, 1, 384]) False
[00:25:10.717903] image_bind.point_trunk.point_encoder.cls_pos torch.Size([1, 1, 384]) False
[00:25:10.717940] image_bind.point_trunk.point_encoder.encoder.first_conv.0.weight torch.Size([128, 3, 1]) False
[00:25:10.717969] image_bind.point_trunk.point_encoder.encoder.first_conv.0.bias torch.Size([128]) False
[00:25:10.718001] image_bind.point_trunk.point_encoder.encoder.first_conv.1.weight torch.Size([128]) False
[00:25:10.718030] image_bind.point_trunk.point_encoder.encoder.first_conv.1.bias torch.Size([128]) False
[00:25:10.718063] image_bind.point_trunk.point_encoder.encoder.first_conv.3.weight torch.Size([256, 128, 1]) False
[00:25:10.718092] image_bind.point_trunk.point_encoder.encoder.first_conv.3.bias torch.Size([256]) False
[00:25:10.718124] image_bind.point_trunk.point_encoder.encoder.second_conv.0.weight torch.Size([512, 512, 1]) False
[00:25:10.718154] image_bind.point_trunk.point_encoder.encoder.second_conv.0.bias torch.Size([512]) False
[00:25:10.718184] image_bind.point_trunk.point_encoder.encoder.second_conv.1.weight torch.Size([512]) False
[00:25:10.718215] image_bind.point_trunk.point_encoder.encoder.second_conv.1.bias torch.Size([512]) False
[00:25:10.718249] image_bind.point_trunk.point_encoder.encoder.second_conv.3.weight torch.Size([256, 512, 1]) False
[00:25:10.718278] image_bind.point_trunk.point_encoder.encoder.second_conv.3.bias torch.Size([256]) False
[00:25:10.718310] image_bind.point_trunk.point_encoder.reduce_dim.weight torch.Size([384, 256]) False
[00:25:10.718339] image_bind.point_trunk.point_encoder.reduce_dim.bias torch.Size([384]) False
[00:25:10.718371] image_bind.point_trunk.point_encoder.pos_embed.0.weight torch.Size([128, 3]) False
[00:25:10.718401] image_bind.point_trunk.point_encoder.pos_embed.0.bias torch.Size([128]) False
[00:25:10.718433] image_bind.point_trunk.point_encoder.pos_embed.2.weight torch.Size([384, 128]) False
[00:25:10.718462] image_bind.point_trunk.point_encoder.pos_embed.2.bias torch.Size([384]) False
[00:25:10.718504] image_bind.point_trunk.point_encoder.blocks.blocks.0.norm1.weight torch.Size([384]) False
[00:25:10.718534] image_bind.point_trunk.point_encoder.blocks.blocks.0.norm1.bias torch.Size([384]) False
[00:25:10.718566] image_bind.point_trunk.point_encoder.blocks.blocks.0.norm2.weight torch.Size([384]) False
[00:25:10.718595] image_bind.point_trunk.point_encoder.blocks.blocks.0.norm2.bias torch.Size([384]) False
[00:25:10.718628] image_bind.point_trunk.point_encoder.blocks.blocks.0.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.718657] image_bind.point_trunk.point_encoder.blocks.blocks.0.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.718690] image_bind.point_trunk.point_encoder.blocks.blocks.0.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.718719] image_bind.point_trunk.point_encoder.blocks.blocks.0.mlp.fc2.bias torch.Size([384]) False
[00:25:10.718753] image_bind.point_trunk.point_encoder.blocks.blocks.0.attn.qkv.weight torch.Size([1152, 384]) False
[00:25:10.718902] image_bind.point_trunk.point_encoder.blocks.blocks.0.attn.proj.weight torch.Size([384, 384]) False
[00:25:10.718932] image_bind.point_trunk.point_encoder.blocks.blocks.0.attn.proj.bias torch.Size([384]) False
[00:25:10.718966] image_bind.point_trunk.point_encoder.blocks.blocks.1.norm1.weight torch.Size([384]) False
[00:25:10.718995] image_bind.point_trunk.point_encoder.blocks.blocks.1.norm1.bias torch.Size([384]) False
[00:25:10.719027] image_bind.point_trunk.point_encoder.blocks.blocks.1.norm2.weight torch.Size([384]) False
[00:25:10.719055] image_bind.point_trunk.point_encoder.blocks.blocks.1.norm2.bias torch.Size([384]) False
[00:25:10.719088] image_bind.point_trunk.point_encoder.blocks.blocks.1.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.719117] image_bind.point_trunk.point_encoder.blocks.blocks.1.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.719149] image_bind.point_trunk.point_encoder.blocks.blocks.1.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.719178] image_bind.point_trunk.point_encoder.blocks.blocks.1.mlp.fc2.bias torch.Size([384]) False
[00:25:10.719212] image_bind.point_trunk.point_encoder.blocks.blocks.1.attn.qkv.weight torch.Size([1152, 384]) False
[00:25:10.719244] image_bind.point_trunk.point_encoder.blocks.blocks.1.attn.proj.weight torch.Size([384, 384]) False
[00:25:10.719279] image_bind.point_trunk.point_encoder.blocks.blocks.1.attn.proj.bias torch.Size([384]) False
[00:25:10.719312] image_bind.point_trunk.point_encoder.blocks.blocks.2.norm1.weight torch.Size([384]) False
[00:25:10.719341] image_bind.point_trunk.point_encoder.blocks.blocks.2.norm1.bias torch.Size([384]) False
[00:25:10.719373] image_bind.point_trunk.point_encoder.blocks.blocks.2.norm2.weight torch.Size([384]) False
[00:25:10.719402] image_bind.point_trunk.point_encoder.blocks.blocks.2.norm2.bias torch.Size([384]) False
[00:25:10.719434] image_bind.point_trunk.point_encoder.blocks.blocks.2.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.719464] image_bind.point_trunk.point_encoder.blocks.blocks.2.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.719501] image_bind.point_trunk.point_encoder.blocks.blocks.2.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.719531] image_bind.point_trunk.point_encoder.blocks.blocks.2.mlp.fc2.bias torch.Size([384]) False
[00:25:10.719564] image_bind.point_trunk.point_encoder.blocks.blocks.2.attn.qkv.weight torch.Size([1152, 384]) False
[00:25:10.719597] image_bind.point_trunk.point_encoder.blocks.blocks.2.attn.proj.weight torch.Size([384, 384]) False
[00:25:10.719626] image_bind.point_trunk.point_encoder.blocks.blocks.2.attn.proj.bias torch.Size([384]) False
[00:25:10.719660] image_bind.point_trunk.point_encoder.blocks.blocks.3.norm1.weight torch.Size([384]) False
[00:25:10.719689] image_bind.point_trunk.point_encoder.blocks.blocks.3.norm1.bias torch.Size([384]) False
[00:25:10.719721] image_bind.point_trunk.point_encoder.blocks.blocks.3.norm2.weight torch.Size([384]) False
[00:25:10.719750] image_bind.point_trunk.point_encoder.blocks.blocks.3.norm2.bias torch.Size([384]) False
[00:25:10.719783] image_bind.point_trunk.point_encoder.blocks.blocks.3.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.719812] image_bind.point_trunk.point_encoder.blocks.blocks.3.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.719844] image_bind.point_trunk.point_encoder.blocks.blocks.3.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.719873] image_bind.point_trunk.point_encoder.blocks.blocks.3.mlp.fc2.bias torch.Size([384]) False
[00:25:10.719906] image_bind.point_trunk.point_encoder.blocks.blocks.3.attn.qkv.weight torch.Size([1152, 384]) False
[00:25:10.719938] image_bind.point_trunk.point_encoder.blocks.blocks.3.attn.proj.weight torch.Size([384, 384]) False
[00:25:10.719967] image_bind.point_trunk.point_encoder.blocks.blocks.3.attn.proj.bias torch.Size([384]) False
[00:25:10.720001] image_bind.point_trunk.point_encoder.blocks.blocks.4.norm1.weight torch.Size([384]) False
[00:25:10.720035] image_bind.point_trunk.point_encoder.blocks.blocks.4.norm1.bias torch.Size([384]) False
[00:25:10.720161] image_bind.point_trunk.point_encoder.blocks.blocks.4.norm2.weight torch.Size([384]) False
[00:25:10.720191] image_bind.point_trunk.point_encoder.blocks.blocks.4.norm2.bias torch.Size([384]) False
[00:25:10.720224] image_bind.point_trunk.point_encoder.blocks.blocks.4.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.720253] image_bind.point_trunk.point_encoder.blocks.blocks.4.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.720286] image_bind.point_trunk.point_encoder.blocks.blocks.4.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.720315] image_bind.point_trunk.point_encoder.blocks.blocks.4.mlp.fc2.bias torch.Size([384]) False
[00:25:10.720348] image_bind.point_trunk.point_encoder.blocks.blocks.4.attn.qkv.weight torch.Size([1152, 384]) False
[00:25:10.720380] image_bind.point_trunk.point_encoder.blocks.blocks.4.attn.proj.weight torch.Size([384, 384]) False
[00:25:10.720410] image_bind.point_trunk.point_encoder.blocks.blocks.4.attn.proj.bias torch.Size([384]) False
[00:25:10.720443] image_bind.point_trunk.point_encoder.blocks.blocks.5.norm1.weight torch.Size([384]) False
[00:25:10.720472] image_bind.point_trunk.point_encoder.blocks.blocks.5.norm1.bias torch.Size([384]) False
[00:25:10.720508] image_bind.point_trunk.point_encoder.blocks.blocks.5.norm2.weight torch.Size([384]) False
[00:25:10.720537] image_bind.point_trunk.point_encoder.blocks.blocks.5.norm2.bias torch.Size([384]) False
[00:25:10.720570] image_bind.point_trunk.point_encoder.blocks.blocks.5.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.720604] image_bind.point_trunk.point_encoder.blocks.blocks.5.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.720636] image_bind.point_trunk.point_encoder.blocks.blocks.5.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.720666] image_bind.point_trunk.point_encoder.blocks.blocks.5.mlp.fc2.bias torch.Size([384]) False
[00:25:10.720700] image_bind.point_trunk.point_encoder.blocks.blocks.5.attn.qkv.weight torch.Size([1152, 384]) False
[00:25:10.720733] image_bind.point_trunk.point_encoder.blocks.blocks.5.attn.proj.weight torch.Size([384, 384]) False
[00:25:10.720762] image_bind.point_trunk.point_encoder.blocks.blocks.5.attn.proj.bias torch.Size([384]) False
[00:25:10.720795] image_bind.point_trunk.point_encoder.blocks.blocks.6.norm1.weight torch.Size([384]) False
[00:25:10.720825] image_bind.point_trunk.point_encoder.blocks.blocks.6.norm1.bias torch.Size([384]) False
[00:25:10.720856] image_bind.point_trunk.point_encoder.blocks.blocks.6.norm2.weight torch.Size([384]) False
[00:25:10.720885] image_bind.point_trunk.point_encoder.blocks.blocks.6.norm2.bias torch.Size([384]) False
[00:25:10.720917] image_bind.point_trunk.point_encoder.blocks.blocks.6.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.720947] image_bind.point_trunk.point_encoder.blocks.blocks.6.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.720978] image_bind.point_trunk.point_encoder.blocks.blocks.6.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.721007] image_bind.point_trunk.point_encoder.blocks.blocks.6.mlp.fc2.bias torch.Size([384]) False
[00:25:10.721040] image_bind.point_trunk.point_encoder.blocks.blocks.6.attn.qkv.weight torch.Size([1152, 384]) False
[00:25:10.721073] image_bind.point_trunk.point_encoder.blocks.blocks.6.attn.proj.weight torch.Size([384, 384]) False
[00:25:10.721102] image_bind.point_trunk.point_encoder.blocks.blocks.6.attn.proj.bias torch.Size([384]) False
[00:25:10.721135] image_bind.point_trunk.point_encoder.blocks.blocks.7.norm1.weight torch.Size([384]) False
[00:25:10.721165] image_bind.point_trunk.point_encoder.blocks.blocks.7.norm1.bias torch.Size([384]) False
[00:25:10.721201] image_bind.point_trunk.point_encoder.blocks.blocks.7.norm2.weight torch.Size([384]) False
[00:25:10.721230] image_bind.point_trunk.point_encoder.blocks.blocks.7.norm2.bias torch.Size([384]) False
[00:25:10.721262] image_bind.point_trunk.point_encoder.blocks.blocks.7.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.721291] image_bind.point_trunk.point_encoder.blocks.blocks.7.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.721398] image_bind.point_trunk.point_encoder.blocks.blocks.7.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.721428] image_bind.point_trunk.point_encoder.blocks.blocks.7.mlp.fc2.bias torch.Size([384]) False
[00:25:10.721461] image_bind.point_trunk.point_encoder.blocks.blocks.7.attn.qkv.weight torch.Size([1152, 384]) False
[00:25:10.721499] image_bind.point_trunk.point_encoder.blocks.blocks.7.attn.proj.weight torch.Size([384, 384]) False
[00:25:10.721529] image_bind.point_trunk.point_encoder.blocks.blocks.7.attn.proj.bias torch.Size([384]) False
[00:25:10.721562] image_bind.point_trunk.point_encoder.blocks.blocks.8.norm1.weight torch.Size([384]) False
[00:25:10.721591] image_bind.point_trunk.point_encoder.blocks.blocks.8.norm1.bias torch.Size([384]) False
[00:25:10.721623] image_bind.point_trunk.point_encoder.blocks.blocks.8.norm2.weight torch.Size([384]) False
[00:25:10.721655] image_bind.point_trunk.point_encoder.blocks.blocks.8.norm2.bias torch.Size([384]) False
[00:25:10.721687] image_bind.point_trunk.point_encoder.blocks.blocks.8.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.721717] image_bind.point_trunk.point_encoder.blocks.blocks.8.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.721748] image_bind.point_trunk.point_encoder.blocks.blocks.8.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.721778] image_bind.point_trunk.point_encoder.blocks.blocks.8.mlp.fc2.bias torch.Size([384]) False
[00:25:10.721811] image_bind.point_trunk.point_encoder.blocks.blocks.8.attn.qkv.weight torch.Size([1152, 384]) False
[00:25:10.721842] image_bind.point_trunk.point_encoder.blocks.blocks.8.attn.proj.weight torch.Size([384, 384]) False
[00:25:10.721872] image_bind.point_trunk.point_encoder.blocks.blocks.8.attn.proj.bias torch.Size([384]) False
[00:25:10.721904] image_bind.point_trunk.point_encoder.blocks.blocks.9.norm1.weight torch.Size([384]) False
[00:25:10.721933] image_bind.point_trunk.point_encoder.blocks.blocks.9.norm1.bias torch.Size([384]) False
[00:25:10.721965] image_bind.point_trunk.point_encoder.blocks.blocks.9.norm2.weight torch.Size([384]) False
[00:25:10.721994] image_bind.point_trunk.point_encoder.blocks.blocks.9.norm2.bias torch.Size([384]) False
[00:25:10.722025] image_bind.point_trunk.point_encoder.blocks.blocks.9.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.722054] image_bind.point_trunk.point_encoder.blocks.blocks.9.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.722086] image_bind.point_trunk.point_encoder.blocks.blocks.9.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.722115] image_bind.point_trunk.point_encoder.blocks.blocks.9.mlp.fc2.bias torch.Size([384]) False
[00:25:10.722148] image_bind.point_trunk.point_encoder.blocks.blocks.9.attn.qkv.weight torch.Size([1152, 384]) False
[00:25:10.722180] image_bind.point_trunk.point_encoder.blocks.blocks.9.attn.proj.weight torch.Size([384, 384]) False
[00:25:10.722210] image_bind.point_trunk.point_encoder.blocks.blocks.9.attn.proj.bias torch.Size([384]) False
[00:25:10.722243] image_bind.point_trunk.point_encoder.blocks.blocks.10.norm1.weight torch.Size([384]) False
[00:25:10.722272] image_bind.point_trunk.point_encoder.blocks.blocks.10.norm1.bias torch.Size([384]) False
[00:25:10.722303] image_bind.point_trunk.point_encoder.blocks.blocks.10.norm2.weight torch.Size([384]) False
[00:25:10.722332] image_bind.point_trunk.point_encoder.blocks.blocks.10.norm2.bias torch.Size([384]) False
[00:25:10.722367] image_bind.point_trunk.point_encoder.blocks.blocks.10.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.722397] image_bind.point_trunk.point_encoder.blocks.blocks.10.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.722428] image_bind.point_trunk.point_encoder.blocks.blocks.10.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.722458] image_bind.point_trunk.point_encoder.blocks.blocks.10.mlp.fc2.bias torch.Size([384]) False
[00:25:10.722494] image_bind.point_trunk.point_encoder.blocks.blocks.10.attn.qkv.weight torch.Size([1152, 384]) False
[00:25:10.722526] image_bind.point_trunk.point_encoder.blocks.blocks.10.attn.proj.weight torch.Size([384, 384]) False
[00:25:10.722630] image_bind.point_trunk.point_encoder.blocks.blocks.10.attn.proj.bias torch.Size([384]) False
[00:25:10.722664] image_bind.point_trunk.point_encoder.blocks.blocks.11.norm1.weight torch.Size([384]) False
[00:25:10.722693] image_bind.point_trunk.point_encoder.blocks.blocks.11.norm1.bias torch.Size([384]) False
[00:25:10.722725] image_bind.point_trunk.point_encoder.blocks.blocks.11.norm2.weight torch.Size([384]) False
[00:25:10.722754] image_bind.point_trunk.point_encoder.blocks.blocks.11.norm2.bias torch.Size([384]) False
[00:25:10.722786] image_bind.point_trunk.point_encoder.blocks.blocks.11.mlp.fc1.weight torch.Size([1536, 384]) False
[00:25:10.722815] image_bind.point_trunk.point_encoder.blocks.blocks.11.mlp.fc1.bias torch.Size([1536]) False
[00:25:10.722847] image_bind.point_trunk.point_encoder.blocks.blocks.11.mlp.fc2.weight torch.Size([384, 1536]) False
[00:25:10.722878] image_bind.point_trunk.point_encoder.blocks.blocks.11.mlp.fc2.bias torch.Size([384]) False
[00:25:10.722913] image_bind.point_trunk.point_encoder.blocks.blocks.11.attn.qkv.weight torch.Size([1152, 384]) False
[00:25:10.722945] image_bind.point_trunk.point_encoder.blocks.blocks.11.attn.proj.weight torch.Size([384, 384]) False
[00:25:10.722974] image_bind.point_trunk.point_encoder.blocks.blocks.11.attn.proj.bias torch.Size([384]) False
[00:25:10.723007] image_bind.point_trunk.point_encoder.norm.weight torch.Size([384]) False
[00:25:10.723036] image_bind.point_trunk.point_encoder.norm.bias torch.Size([384]) False
[00:25:10.723069] image_bind_proj.weight torch.Size([4096, 1024]) False
[00:25:10.723098] image_bind_proj.bias torch.Size([4096]) False
[00:25:10.723130] image_bind_norm_1.weight torch.Size([4096]) False
[00:25:10.723160] image_bind_f1_1.weight torch.Size([16384, 4096]) False
[00:25:10.723191] image_bind_f2_1.weight torch.Size([4096, 16384]) False
[00:25:10.723222] image_bind_f3_1.weight torch.Size([16384, 4096]) False
[00:25:10.723254] image_bind_norm_2.weight torch.Size([4096]) False
[00:25:10.723284] image_bind_f1_2.weight torch.Size([16384, 4096]) False
[00:25:10.723320] image_bind_f2_2.weight torch.Size([4096, 16384]) False
[00:25:10.723351] image_bind_f3_2.weight torch.Size([16384, 4096]) False
[00:25:10.723382] image_bind_norm_3.weight torch.Size([4096]) False
[00:25:10.723413] image_bind_f1_3.weight torch.Size([16384, 4096]) False
[00:25:10.723443] image_bind_f2_3.weight torch.Size([4096, 16384]) False
[00:25:10.723474] image_bind_f3_3.weight torch.Size([16384, 4096]) False
[00:25:10.723513] llama.tok_embeddings.weight torch.Size([32000, 4096]) False
[00:25:10.723549] llama.layers.0.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.723582] llama.layers.0.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.723612] llama.layers.0.attention.wq.bias torch.Size([4096]) True
[00:25:10.723643] llama.layers.0.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.723674] llama.layers.0.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.723705] llama.layers.0.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.723734] llama.layers.0.attention.wo.bias torch.Size([4096]) True
[00:25:10.723765] llama.layers.0.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.723801] llama.layers.0.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.723832] llama.layers.0.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.723863] llama.layers.0.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.723894] llama.layers.0.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.723925] llama.layers.0.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.723955] llama.layers.0.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.723986] llama.layers.0.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.724019] llama.layers.0.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.724048] llama.layers.0.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.724079] llama.layers.0.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.724193] llama.layers.0.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.724225] llama.layers.0.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.724259] llama.layers.0.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.724290] llama.layers.0.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.724320] llama.layers.0.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.724351] llama.layers.0.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.724381] llama.layers.0.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.724412] llama.layers.0.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.724442] llama.layers.0.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.724473] llama.layers.0.attention_norm.weight torch.Size([4096]) True
[00:25:10.724508] llama.layers.0.ffn_norm.weight torch.Size([4096]) True
[00:25:10.724542] llama.layers.1.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.724574] llama.layers.1.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.724603] llama.layers.1.attention.wq.bias torch.Size([4096]) True
[00:25:10.724634] llama.layers.1.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.724670] llama.layers.1.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.724701] llama.layers.1.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.724730] llama.layers.1.attention.wo.bias torch.Size([4096]) True
[00:25:10.724761] llama.layers.1.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.724793] llama.layers.1.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.724824] llama.layers.1.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.724854] llama.layers.1.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.724885] llama.layers.1.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.724916] llama.layers.1.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.724946] llama.layers.1.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.724977] llama.layers.1.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.725009] llama.layers.1.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.725043] llama.layers.1.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.725075] llama.layers.1.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.725104] llama.layers.1.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.725135] llama.layers.1.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.725164] llama.layers.1.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.725194] llama.layers.1.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.725225] llama.layers.1.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.725256] llama.layers.1.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.725286] llama.layers.1.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.725317] llama.layers.1.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.725348] llama.layers.1.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.725379] llama.layers.1.attention_norm.weight torch.Size([4096]) True
[00:25:10.725409] llama.layers.1.ffn_norm.weight torch.Size([4096]) True
[00:25:10.725442] llama.layers.2.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.725473] llama.layers.2.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.725513] llama.layers.2.attention.wq.bias torch.Size([4096]) True
[00:25:10.725545] llama.layers.2.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.725575] llama.layers.2.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.725606] llama.layers.2.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.725636] llama.layers.2.attention.wo.bias torch.Size([4096]) True
[00:25:10.725667] llama.layers.2.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.725787] llama.layers.2.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.725818] llama.layers.2.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.725849] llama.layers.2.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.725880] llama.layers.2.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.725910] llama.layers.2.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.725941] llama.layers.2.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.725972] llama.layers.2.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.726007] llama.layers.2.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.726036] llama.layers.2.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.726067] llama.layers.2.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.726096] llama.layers.2.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.726126] llama.layers.2.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.726155] llama.layers.2.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.726186] llama.layers.2.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.726217] llama.layers.2.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.726247] llama.layers.2.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.726278] llama.layers.2.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.726308] llama.layers.2.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.726339] llama.layers.2.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.726369] llama.layers.2.attention_norm.weight torch.Size([4096]) True
[00:25:10.726400] llama.layers.2.ffn_norm.weight torch.Size([4096]) True
[00:25:10.726432] llama.layers.3.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.726463] llama.layers.3.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.726497] llama.layers.3.attention.wq.bias torch.Size([4096]) True
[00:25:10.726529] llama.layers.3.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.726565] llama.layers.3.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.726596] llama.layers.3.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.726625] llama.layers.3.attention.wo.bias torch.Size([4096]) True
[00:25:10.726656] llama.layers.3.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.726687] llama.layers.3.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.726717] llama.layers.3.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.726748] llama.layers.3.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.726779] llama.layers.3.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.726809] llama.layers.3.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.726840] llama.layers.3.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.726871] llama.layers.3.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.726907] llama.layers.3.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.726936] llama.layers.3.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.726967] llama.layers.3.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.726996] llama.layers.3.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.727026] llama.layers.3.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.727056] llama.layers.3.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.727086] llama.layers.3.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.727117] llama.layers.3.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.727148] llama.layers.3.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.727179] llama.layers.3.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.727209] llama.layers.3.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.727326] llama.layers.3.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.727357] llama.layers.3.attention_norm.weight torch.Size([4096]) True
[00:25:10.727388] llama.layers.3.ffn_norm.weight torch.Size([4096]) True
[00:25:10.727421] llama.layers.4.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.727452] llama.layers.4.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.727481] llama.layers.4.attention.wq.bias torch.Size([4096]) True
[00:25:10.727515] llama.layers.4.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.727546] llama.layers.4.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.727578] llama.layers.4.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.727607] llama.layers.4.attention.wo.bias torch.Size([4096]) True
[00:25:10.727637] llama.layers.4.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.727669] llama.layers.4.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.727700] llama.layers.4.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.727731] llama.layers.4.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.727761] llama.layers.4.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.727792] llama.layers.4.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.727823] llama.layers.4.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.727859] llama.layers.4.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.727891] llama.layers.4.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.727920] llama.layers.4.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.727951] llama.layers.4.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.727980] llama.layers.4.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.728010] llama.layers.4.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.728040] llama.layers.4.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.728070] llama.layers.4.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.728100] llama.layers.4.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.728131] llama.layers.4.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.728161] llama.layers.4.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.728192] llama.layers.4.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.728222] llama.layers.4.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.728258] llama.layers.4.attention_norm.weight torch.Size([4096]) True
[00:25:10.728290] llama.layers.4.ffn_norm.weight torch.Size([4096]) True
[00:25:10.728322] llama.layers.5.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.728353] llama.layers.5.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.728383] llama.layers.5.attention.wq.bias torch.Size([4096]) True
[00:25:10.728413] llama.layers.5.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.728444] llama.layers.5.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.728475] llama.layers.5.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.728509] llama.layers.5.attention.wo.bias torch.Size([4096]) True
[00:25:10.728540] llama.layers.5.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.728570] llama.layers.5.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.728601] llama.layers.5.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.728632] llama.layers.5.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.728663] llama.layers.5.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.728699] llama.layers.5.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.728730] llama.layers.5.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.728761] llama.layers.5.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.728794] llama.layers.5.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.728895] llama.layers.5.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.728935] llama.layers.5.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.728964] llama.layers.5.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.728995] llama.layers.5.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.729024] llama.layers.5.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.729055] llama.layers.5.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.729086] llama.layers.5.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.729122] llama.layers.5.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.729153] llama.layers.5.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.729183] llama.layers.5.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.729214] llama.layers.5.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.729244] llama.layers.5.attention_norm.weight torch.Size([4096]) True
[00:25:10.729275] llama.layers.5.ffn_norm.weight torch.Size([4096]) True
[00:25:10.729308] llama.layers.6.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.729340] llama.layers.6.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.729369] llama.layers.6.attention.wq.bias torch.Size([4096]) True
[00:25:10.729400] llama.layers.6.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.729431] llama.layers.6.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.729462] llama.layers.6.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.729495] llama.layers.6.attention.wo.bias torch.Size([4096]) True
[00:25:10.729526] llama.layers.6.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.729557] llama.layers.6.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.729588] llama.layers.6.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.729624] llama.layers.6.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.729655] llama.layers.6.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.729685] llama.layers.6.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.729716] llama.layers.6.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.729747] llama.layers.6.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.729779] llama.layers.6.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.729809] llama.layers.6.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.729839] llama.layers.6.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.729869] llama.layers.6.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.729899] llama.layers.6.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.729929] llama.layers.6.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.729960] llama.layers.6.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.729990] llama.layers.6.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.730021] llama.layers.6.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.730057] llama.layers.6.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.730088] llama.layers.6.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.730118] llama.layers.6.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.730149] llama.layers.6.attention_norm.weight torch.Size([4096]) True
[00:25:10.730180] llama.layers.6.ffn_norm.weight torch.Size([4096]) True
[00:25:10.730212] llama.layers.7.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.730244] llama.layers.7.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.730273] llama.layers.7.attention.wq.bias torch.Size([4096]) True
[00:25:10.730304] llama.layers.7.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.730336] llama.layers.7.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.730366] llama.layers.7.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.730488] llama.layers.7.attention.wo.bias torch.Size([4096]) True
[00:25:10.730521] llama.layers.7.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.730552] llama.layers.7.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.730583] llama.layers.7.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.730614] llama.layers.7.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.730645] llama.layers.7.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.730676] llama.layers.7.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.730706] llama.layers.7.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.730737] llama.layers.7.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.730769] llama.layers.7.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.730798] llama.layers.7.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.730829] llama.layers.7.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.730859] llama.layers.7.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.730890] llama.layers.7.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.730921] llama.layers.7.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.730953] llama.layers.7.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.730984] llama.layers.7.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.731015] llama.layers.7.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.731046] llama.layers.7.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.731077] llama.layers.7.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.731107] llama.layers.7.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.731138] llama.layers.7.attention_norm.weight torch.Size([4096]) True
[00:25:10.731169] llama.layers.7.ffn_norm.weight torch.Size([4096]) True
[00:25:10.731201] llama.layers.8.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.731232] llama.layers.8.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.731261] llama.layers.8.attention.wq.bias torch.Size([4096]) True
[00:25:10.731292] llama.layers.8.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.731323] llama.layers.8.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.731353] llama.layers.8.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.731382] llama.layers.8.attention.wo.bias torch.Size([4096]) True
[00:25:10.731412] llama.layers.8.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.731447] llama.layers.8.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.731478] llama.layers.8.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.731513] llama.layers.8.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.731545] llama.layers.8.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.731576] llama.layers.8.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.731607] llama.layers.8.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.731637] llama.layers.8.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.731670] llama.layers.8.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.731699] llama.layers.8.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.731730] llama.layers.8.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.731759] llama.layers.8.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.731789] llama.layers.8.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.731818] llama.layers.8.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.731851] llama.layers.8.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.731883] llama.layers.8.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.731914] llama.layers.8.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.732066] llama.layers.8.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.732098] llama.layers.8.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.732129] llama.layers.8.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.732159] llama.layers.8.attention_norm.weight torch.Size([4096]) True
[00:25:10.732190] llama.layers.8.ffn_norm.weight torch.Size([4096]) True
[00:25:10.732227] llama.layers.9.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.732259] llama.layers.9.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.732288] llama.layers.9.attention.wq.bias torch.Size([4096]) True
[00:25:10.732319] llama.layers.9.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.732350] llama.layers.9.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.732381] llama.layers.9.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.732410] llama.layers.9.attention.wo.bias torch.Size([4096]) True
[00:25:10.732440] llama.layers.9.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.732471] llama.layers.9.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.732507] llama.layers.9.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.732538] llama.layers.9.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.732568] llama.layers.9.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.732605] llama.layers.9.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.732636] llama.layers.9.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.732667] llama.layers.9.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.732700] llama.layers.9.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.732729] llama.layers.9.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.732759] llama.layers.9.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.732789] llama.layers.9.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.732819] llama.layers.9.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.732848] llama.layers.9.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.732879] llama.layers.9.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.732909] llama.layers.9.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.732940] llama.layers.9.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.732971] llama.layers.9.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.733001] llama.layers.9.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.733032] llama.layers.9.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.733067] llama.layers.9.attention_norm.weight torch.Size([4096]) True
[00:25:10.733099] llama.layers.9.ffn_norm.weight torch.Size([4096]) True
[00:25:10.733131] llama.layers.10.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.733163] llama.layers.10.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.733192] llama.layers.10.attention.wq.bias torch.Size([4096]) True
[00:25:10.733223] llama.layers.10.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.733254] llama.layers.10.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.733285] llama.layers.10.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.733314] llama.layers.10.attention.wo.bias torch.Size([4096]) True
[00:25:10.733345] llama.layers.10.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.733376] llama.layers.10.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.733407] llama.layers.10.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.733437] llama.layers.10.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.733468] llama.layers.10.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.733504] llama.layers.10.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.733535] llama.layers.10.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.733640] llama.layers.10.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.733675] llama.layers.10.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.733705] llama.layers.10.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.733736] llama.layers.10.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.733765] llama.layers.10.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.733796] llama.layers.10.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.733825] llama.layers.10.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.733856] llama.layers.10.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.733886] llama.layers.10.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.733917] llama.layers.10.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.733947] llama.layers.10.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.733978] llama.layers.10.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.734009] llama.layers.10.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.734039] llama.layers.10.attention_norm.weight torch.Size([4096]) True
[00:25:10.734075] llama.layers.10.ffn_norm.weight torch.Size([4096]) True
[00:25:10.734108] llama.layers.11.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.734139] llama.layers.11.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.734169] llama.layers.11.attention.wq.bias torch.Size([4096]) True
[00:25:10.734200] llama.layers.11.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.734231] llama.layers.11.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.734262] llama.layers.11.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.734291] llama.layers.11.attention.wo.bias torch.Size([4096]) True
[00:25:10.734321] llama.layers.11.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.734352] llama.layers.11.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.734382] llama.layers.11.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.734413] llama.layers.11.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.734443] llama.layers.11.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.734474] llama.layers.11.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.734509] llama.layers.11.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.734540] llama.layers.11.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.734577] llama.layers.11.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.734606] llama.layers.11.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.734637] llama.layers.11.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.734667] llama.layers.11.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.734698] llama.layers.11.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.734727] llama.layers.11.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.734758] llama.layers.11.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.734789] llama.layers.11.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.734819] llama.layers.11.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.734851] llama.layers.11.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.734881] llama.layers.11.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.734913] llama.layers.11.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.734944] llama.layers.11.attention_norm.weight torch.Size([4096]) True
[00:25:10.734975] llama.layers.11.ffn_norm.weight torch.Size([4096]) True
[00:25:10.735008] llama.layers.12.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.735040] llama.layers.12.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.735074] llama.layers.12.attention.wq.bias torch.Size([4096]) True
[00:25:10.735192] llama.layers.12.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.735224] llama.layers.12.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.735256] llama.layers.12.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.735285] llama.layers.12.attention.wo.bias torch.Size([4096]) True
[00:25:10.735315] llama.layers.12.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.735346] llama.layers.12.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.735377] llama.layers.12.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.735409] llama.layers.12.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.735445] llama.layers.12.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.735475] llama.layers.12.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.735510] llama.layers.12.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.735540] llama.layers.12.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.735573] llama.layers.12.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.735602] llama.layers.12.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.735633] llama.layers.12.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.735663] llama.layers.12.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.735694] llama.layers.12.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.735724] llama.layers.12.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.735754] llama.layers.12.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.735785] llama.layers.12.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.735817] llama.layers.12.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.735847] llama.layers.12.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.735878] llama.layers.12.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.735910] llama.layers.12.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.735942] llama.layers.12.attention_norm.weight torch.Size([4096]) True
[00:25:10.735977] llama.layers.12.ffn_norm.weight torch.Size([4096]) True
[00:25:10.736010] llama.layers.13.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.736042] llama.layers.13.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.736071] llama.layers.13.attention.wq.bias torch.Size([4096]) True
[00:25:10.736102] llama.layers.13.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.736133] llama.layers.13.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.736164] llama.layers.13.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.736193] llama.layers.13.attention.wo.bias torch.Size([4096]) True
[00:25:10.736223] llama.layers.13.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.736255] llama.layers.13.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.736287] llama.layers.13.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.736318] llama.layers.13.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.736350] llama.layers.13.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.736381] llama.layers.13.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.736411] llama.layers.13.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.736442] llama.layers.13.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.736474] llama.layers.13.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.736510] llama.layers.13.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.736542] llama.layers.13.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.736571] llama.layers.13.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.736602] llama.layers.13.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.736632] llama.layers.13.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.736662] llama.layers.13.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.736786] llama.layers.13.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.736818] llama.layers.13.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.736849] llama.layers.13.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.736881] llama.layers.13.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.736915] llama.layers.13.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.736946] llama.layers.13.attention_norm.weight torch.Size([4096]) True
[00:25:10.736976] llama.layers.13.ffn_norm.weight torch.Size([4096]) True
[00:25:10.737009] llama.layers.14.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.737040] llama.layers.14.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.737069] llama.layers.14.attention.wq.bias torch.Size([4096]) True
[00:25:10.737100] llama.layers.14.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.737131] llama.layers.14.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.737161] llama.layers.14.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.737191] llama.layers.14.attention.wo.bias torch.Size([4096]) True
[00:25:10.737221] llama.layers.14.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.737252] llama.layers.14.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.737288] llama.layers.14.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.737319] llama.layers.14.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.737350] llama.layers.14.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.737381] llama.layers.14.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.737418] llama.layers.14.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.737454] llama.layers.14.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.737492] llama.layers.14.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.737522] llama.layers.14.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.737552] llama.layers.14.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.737582] llama.layers.14.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.737614] llama.layers.14.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.737645] llama.layers.14.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.737677] llama.layers.14.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.737711] llama.layers.14.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.737742] llama.layers.14.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.737773] llama.layers.14.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.737804] llama.layers.14.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.737836] llama.layers.14.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.737867] llama.layers.14.attention_norm.weight torch.Size([4096]) True
[00:25:10.737897] llama.layers.14.ffn_norm.weight torch.Size([4096]) True
[00:25:10.737933] llama.layers.15.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.737965] llama.layers.15.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.737995] llama.layers.15.attention.wq.bias torch.Size([4096]) True
[00:25:10.738026] llama.layers.15.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.738057] llama.layers.15.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.738088] llama.layers.15.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.738118] llama.layers.15.attention.wo.bias torch.Size([4096]) True
[00:25:10.738149] llama.layers.15.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.738180] llama.layers.15.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.738210] llama.layers.15.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.738241] llama.layers.15.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.738342] llama.layers.15.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.738373] llama.layers.15.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.738409] llama.layers.15.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.738440] llama.layers.15.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.738473] llama.layers.15.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.738504] llama.layers.15.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.738535] llama.layers.15.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.738565] llama.layers.15.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.738596] llama.layers.15.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.738625] llama.layers.15.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.738656] llama.layers.15.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.738686] llama.layers.15.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.738717] llama.layers.15.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.738749] llama.layers.15.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.738780] llama.layers.15.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.738811] llama.layers.15.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.738842] llama.layers.15.attention_norm.weight torch.Size([4096]) True
[00:25:10.738872] llama.layers.15.ffn_norm.weight torch.Size([4096]) True
[00:25:10.738906] llama.layers.16.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.738940] llama.layers.16.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.738970] llama.layers.16.attention.wq.bias torch.Size([4096]) True
[00:25:10.739001] llama.layers.16.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.739032] llama.layers.16.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.739063] llama.layers.16.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.739092] llama.layers.16.attention.wo.bias torch.Size([4096]) True
[00:25:10.739123] llama.layers.16.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.739154] llama.layers.16.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.739185] llama.layers.16.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.739216] llama.layers.16.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.739246] llama.layers.16.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.739277] llama.layers.16.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.739308] llama.layers.16.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.739344] llama.layers.16.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.739376] llama.layers.16.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.739405] llama.layers.16.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.739435] llama.layers.16.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.739465] llama.layers.16.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.739500] llama.layers.16.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.739529] llama.layers.16.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.739560] llama.layers.16.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.739591] llama.layers.16.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.739621] llama.layers.16.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.739652] llama.layers.16.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.739683] llama.layers.16.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.739714] llama.layers.16.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.739745] llama.layers.16.attention_norm.weight torch.Size([4096]) True
[00:25:10.739775] llama.layers.16.ffn_norm.weight torch.Size([4096]) True
[00:25:10.739904] llama.layers.17.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.739935] llama.layers.17.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.739965] llama.layers.17.attention.wq.bias torch.Size([4096]) True
[00:25:10.739996] llama.layers.17.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.740027] llama.layers.17.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.740057] llama.layers.17.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.740086] llama.layers.17.attention.wo.bias torch.Size([4096]) True
[00:25:10.740117] llama.layers.17.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.740148] llama.layers.17.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.740179] llama.layers.17.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.740211] llama.layers.17.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.740241] llama.layers.17.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.740272] llama.layers.17.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.740308] llama.layers.17.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.740339] llama.layers.17.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.740371] llama.layers.17.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.740401] llama.layers.17.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.740432] llama.layers.17.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.740461] llama.layers.17.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.740496] llama.layers.17.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.740526] llama.layers.17.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.740557] llama.layers.17.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.740588] llama.layers.17.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.740619] llama.layers.17.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.740650] llama.layers.17.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.740681] llama.layers.17.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.740712] llama.layers.17.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.740743] llama.layers.17.attention_norm.weight torch.Size([4096]) True
[00:25:10.740776] llama.layers.17.ffn_norm.weight torch.Size([4096]) True
[00:25:10.740809] llama.layers.18.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.740841] llama.layers.18.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.740870] llama.layers.18.attention.wq.bias torch.Size([4096]) True
[00:25:10.740901] llama.layers.18.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.740933] llama.layers.18.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.740963] llama.layers.18.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.740992] llama.layers.18.attention.wo.bias torch.Size([4096]) True
[00:25:10.741023] llama.layers.18.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.741054] llama.layers.18.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.741084] llama.layers.18.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.741121] llama.layers.18.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.741152] llama.layers.18.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.741183] llama.layers.18.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.741213] llama.layers.18.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.741244] llama.layers.18.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.741278] llama.layers.18.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.741307] llama.layers.18.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.741339] llama.layers.18.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.741457] llama.layers.18.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.741494] llama.layers.18.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.741524] llama.layers.18.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.741556] llama.layers.18.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.741588] llama.layers.18.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.741627] llama.layers.18.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.741659] llama.layers.18.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.741690] llama.layers.18.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.741723] llama.layers.18.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.741756] llama.layers.18.attention_norm.weight torch.Size([4096]) True
[00:25:10.741788] llama.layers.18.ffn_norm.weight torch.Size([4096]) True
[00:25:10.741822] llama.layers.19.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.741854] llama.layers.19.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.741884] llama.layers.19.attention.wq.bias torch.Size([4096]) True
[00:25:10.741915] llama.layers.19.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.741948] llama.layers.19.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.741979] llama.layers.19.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.742008] llama.layers.19.attention.wo.bias torch.Size([4096]) True
[00:25:10.742040] llama.layers.19.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.742071] llama.layers.19.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.742102] llama.layers.19.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.742138] llama.layers.19.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.742170] llama.layers.19.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.742201] llama.layers.19.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.742234] llama.layers.19.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.742265] llama.layers.19.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.742299] llama.layers.19.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.742328] llama.layers.19.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.742359] llama.layers.19.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.742389] llama.layers.19.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.742420] llama.layers.19.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.742451] llama.layers.19.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.742482] llama.layers.19.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.742518] llama.layers.19.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.742550] llama.layers.19.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.742581] llama.layers.19.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.742613] llama.layers.19.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.742645] llama.layers.19.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.742681] llama.layers.19.attention_norm.weight torch.Size([4096]) True
[00:25:10.742714] llama.layers.19.ffn_norm.weight torch.Size([4096]) True
[00:25:10.742747] llama.layers.20.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.742780] llama.layers.20.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.742811] llama.layers.20.attention.wq.bias torch.Size([4096]) True
[00:25:10.742842] llama.layers.20.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.742874] llama.layers.20.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.742906] llama.layers.20.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.742936] llama.layers.20.attention.wo.bias torch.Size([4096]) True
[00:25:10.742970] llama.layers.20.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.743083] llama.layers.20.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.743114] llama.layers.20.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.743148] llama.layers.20.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.743179] llama.layers.20.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.743210] llama.layers.20.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.743241] llama.layers.20.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.743273] llama.layers.20.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.743306] llama.layers.20.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.743336] llama.layers.20.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.743367] llama.layers.20.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.743398] llama.layers.20.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.743429] llama.layers.20.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.743459] llama.layers.20.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.743494] llama.layers.20.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.743527] llama.layers.20.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.743565] llama.layers.20.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.743597] llama.layers.20.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.743629] llama.layers.20.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.743660] llama.layers.20.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.743693] llama.layers.20.attention_norm.weight torch.Size([4096]) True
[00:25:10.743725] llama.layers.20.ffn_norm.weight torch.Size([4096]) True
[00:25:10.743758] llama.layers.21.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.743792] llama.layers.21.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.743822] llama.layers.21.attention.wq.bias torch.Size([4096]) True
[00:25:10.743854] llama.layers.21.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.743885] llama.layers.21.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.743917] llama.layers.21.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.743948] llama.layers.21.attention.wo.bias torch.Size([4096]) True
[00:25:10.743979] llama.layers.21.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.744016] llama.layers.21.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.744048] llama.layers.21.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.744080] llama.layers.21.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.744112] llama.layers.21.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.744143] llama.layers.21.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.744174] llama.layers.21.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.744205] llama.layers.21.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.744238] llama.layers.21.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.744269] llama.layers.21.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.744300] llama.layers.21.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.744329] llama.layers.21.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.744360] llama.layers.21.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.744391] llama.layers.21.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.744423] llama.layers.21.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.744457] llama.layers.21.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.744493] llama.layers.21.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.744524] llama.layers.21.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.744556] llama.layers.21.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.744674] llama.layers.21.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.744707] llama.layers.21.attention_norm.weight torch.Size([4096]) True
[00:25:10.744738] llama.layers.21.ffn_norm.weight torch.Size([4096]) True
[00:25:10.744771] llama.layers.22.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.744802] llama.layers.22.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.744831] llama.layers.22.attention.wq.bias torch.Size([4096]) True
[00:25:10.744862] llama.layers.22.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.744893] llama.layers.22.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.744924] llama.layers.22.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.744959] llama.layers.22.attention.wo.bias torch.Size([4096]) True
[00:25:10.744990] llama.layers.22.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.745021] llama.layers.22.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.745051] llama.layers.22.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.745082] llama.layers.22.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.745113] llama.layers.22.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.745144] llama.layers.22.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.745174] llama.layers.22.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.745205] llama.layers.22.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.745237] llama.layers.22.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.745266] llama.layers.22.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.745297] llama.layers.22.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.745326] llama.layers.22.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.745356] llama.layers.22.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.745385] llama.layers.22.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.745416] llama.layers.22.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.745447] llama.layers.22.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.745483] llama.layers.22.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.745519] llama.layers.22.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.745550] llama.layers.22.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.745580] llama.layers.22.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.745611] llama.layers.22.attention_norm.weight torch.Size([4096]) True
[00:25:10.745642] llama.layers.22.ffn_norm.weight torch.Size([4096]) True
[00:25:10.745674] llama.layers.23.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.745706] llama.layers.23.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.745735] llama.layers.23.attention.wq.bias torch.Size([4096]) True
[00:25:10.745766] llama.layers.23.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.745797] llama.layers.23.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.745827] llama.layers.23.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.745856] llama.layers.23.attention.wo.bias torch.Size([4096]) True
[00:25:10.745887] llama.layers.23.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.745917] llama.layers.23.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.745954] llama.layers.23.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.745985] llama.layers.23.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.746016] llama.layers.23.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.746046] llama.layers.23.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.746077] llama.layers.23.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.746108] llama.layers.23.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.746221] llama.layers.23.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.746251] llama.layers.23.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.746282] llama.layers.23.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.746311] llama.layers.23.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.746342] llama.layers.23.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.746371] llama.layers.23.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.746402] llama.layers.23.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.746433] llama.layers.23.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.746463] llama.layers.23.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.746500] llama.layers.23.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.746536] llama.layers.23.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.746567] llama.layers.23.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.746598] llama.layers.23.attention_norm.weight torch.Size([4096]) True
[00:25:10.746629] llama.layers.23.ffn_norm.weight torch.Size([4096]) True
[00:25:10.746661] llama.layers.24.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.746693] llama.layers.24.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.746723] llama.layers.24.attention.wq.bias torch.Size([4096]) True
[00:25:10.746754] llama.layers.24.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.746785] llama.layers.24.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.746816] llama.layers.24.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.746845] llama.layers.24.attention.wo.bias torch.Size([4096]) True
[00:25:10.746876] llama.layers.24.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.746907] llama.layers.24.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.746942] llama.layers.24.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.746974] llama.layers.24.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.747005] llama.layers.24.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.747036] llama.layers.24.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.747067] llama.layers.24.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.747098] llama.layers.24.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.747130] llama.layers.24.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.747159] llama.layers.24.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.747190] llama.layers.24.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.747219] llama.layers.24.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.747250] llama.layers.24.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.747279] llama.layers.24.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.747309] llama.layers.24.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.747339] llama.layers.24.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.747370] llama.layers.24.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.747401] llama.layers.24.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.747431] llama.layers.24.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.747463] llama.layers.24.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.747501] llama.layers.24.attention_norm.weight torch.Size([4096]) True
[00:25:10.747532] llama.layers.24.ffn_norm.weight torch.Size([4096]) True
[00:25:10.747566] llama.layers.25.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.747598] llama.layers.25.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.747627] llama.layers.25.attention.wq.bias torch.Size([4096]) True
[00:25:10.747658] llama.layers.25.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.747767] llama.layers.25.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.747799] llama.layers.25.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.747828] llama.layers.25.attention.wo.bias torch.Size([4096]) True
[00:25:10.747859] llama.layers.25.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.747891] llama.layers.25.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.747922] llama.layers.25.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.747957] llama.layers.25.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.747988] llama.layers.25.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.748018] llama.layers.25.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.748049] llama.layers.25.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.748080] llama.layers.25.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.748112] llama.layers.25.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.748142] llama.layers.25.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.748172] llama.layers.25.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.748201] llama.layers.25.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.748233] llama.layers.25.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.748262] llama.layers.25.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.748292] llama.layers.25.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.748323] llama.layers.25.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.748354] llama.layers.25.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.748384] llama.layers.25.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.748415] llama.layers.25.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.748446] llama.layers.25.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.748477] llama.layers.25.attention_norm.weight torch.Size([4096]) True
[00:25:10.748516] llama.layers.25.ffn_norm.weight torch.Size([4096]) True
[00:25:10.748552] llama.layers.26.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.748583] llama.layers.26.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.748613] llama.layers.26.attention.wq.bias torch.Size([4096]) True
[00:25:10.748644] llama.layers.26.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.748675] llama.layers.26.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.748706] llama.layers.26.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.748735] llama.layers.26.attention.wo.bias torch.Size([4096]) True
[00:25:10.748766] llama.layers.26.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.748797] llama.layers.26.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.748828] llama.layers.26.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.748859] llama.layers.26.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.748891] llama.layers.26.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.748922] llama.layers.26.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.748954] llama.layers.26.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.748986] llama.layers.26.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.749019] llama.layers.26.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.749048] llama.layers.26.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.749079] llama.layers.26.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.749108] llama.layers.26.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.749138] llama.layers.26.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.749167] llama.layers.26.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.749199] llama.layers.26.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.749230] llama.layers.26.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.749360] llama.layers.26.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.749397] llama.layers.26.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.749428] llama.layers.26.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.749459] llama.layers.26.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.749494] llama.layers.26.attention_norm.weight torch.Size([4096]) True
[00:25:10.749525] llama.layers.26.ffn_norm.weight torch.Size([4096]) True
[00:25:10.749558] llama.layers.27.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.749589] llama.layers.27.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.749618] llama.layers.27.attention.wq.bias torch.Size([4096]) True
[00:25:10.749649] llama.layers.27.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.749680] llama.layers.27.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.749711] llama.layers.27.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.749740] llama.layers.27.attention.wo.bias torch.Size([4096]) True
[00:25:10.749771] llama.layers.27.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.749802] llama.layers.27.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.749833] llama.layers.27.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.749864] llama.layers.27.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.749896] llama.layers.27.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.749927] llama.layers.27.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.749961] llama.layers.27.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.749992] llama.layers.27.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.750024] llama.layers.27.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.750053] llama.layers.27.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.750084] llama.layers.27.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.750113] llama.layers.27.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.750144] llama.layers.27.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.750173] llama.layers.27.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.750204] llama.layers.27.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.750235] llama.layers.27.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.750265] llama.layers.27.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.750296] llama.layers.27.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.750327] llama.layers.27.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.750357] llama.layers.27.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.750394] llama.layers.27.attention_norm.weight torch.Size([4096]) True
[00:25:10.750424] llama.layers.27.ffn_norm.weight torch.Size([4096]) True
[00:25:10.750456] llama.layers.28.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.750493] llama.layers.28.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.750523] llama.layers.28.attention.wq.bias torch.Size([4096]) True
[00:25:10.750554] llama.layers.28.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.750586] llama.layers.28.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.750617] llama.layers.28.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.750646] llama.layers.28.attention.wo.bias torch.Size([4096]) True
[00:25:10.750678] llama.layers.28.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.750709] llama.layers.28.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.750740] llama.layers.28.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.750772] llama.layers.28.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.750802] llama.layers.28.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.750931] llama.layers.28.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.750962] llama.layers.28.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.750993] llama.layers.28.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.751026] llama.layers.28.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.751055] llama.layers.28.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.751085] llama.layers.28.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.751114] llama.layers.28.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.751145] llama.layers.28.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.751174] llama.layers.28.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.751204] llama.layers.28.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.751235] llama.layers.28.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.751266] llama.layers.28.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.751297] llama.layers.28.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.751328] llama.layers.28.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.751359] llama.layers.28.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.751392] llama.layers.28.attention_norm.weight torch.Size([4096]) True
[00:25:10.751423] llama.layers.28.ffn_norm.weight torch.Size([4096]) True
[00:25:10.751456] llama.layers.29.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.751492] llama.layers.29.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.751522] llama.layers.29.attention.wq.bias torch.Size([4096]) True
[00:25:10.751553] llama.layers.29.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.751584] llama.layers.29.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.751615] llama.layers.29.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.751644] llama.layers.29.attention.wo.bias torch.Size([4096]) True
[00:25:10.751674] llama.layers.29.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.751706] llama.layers.29.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.751737] llama.layers.29.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.751768] llama.layers.29.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.751799] llama.layers.29.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.751830] llama.layers.29.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.751860] llama.layers.29.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.751892] llama.layers.29.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.751928] llama.layers.29.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.751958] llama.layers.29.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.751988] llama.layers.29.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.752018] llama.layers.29.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.752049] llama.layers.29.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.752078] llama.layers.29.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.752109] llama.layers.29.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.752140] llama.layers.29.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.752172] llama.layers.29.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.752203] llama.layers.29.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.752234] llama.layers.29.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.752265] llama.layers.29.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.752296] llama.layers.29.attention_norm.weight torch.Size([4096]) True
[00:25:10.752327] llama.layers.29.ffn_norm.weight torch.Size([4096]) True
[00:25:10.752359] llama.layers.30.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.752494] llama.layers.30.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.752524] llama.layers.30.attention.wq.bias torch.Size([4096]) True
[00:25:10.752555] llama.layers.30.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.752587] llama.layers.30.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.752618] llama.layers.30.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.752647] llama.layers.30.attention.wo.bias torch.Size([4096]) True
[00:25:10.752678] llama.layers.30.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.752709] llama.layers.30.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.752740] llama.layers.30.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.752770] llama.layers.30.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.752801] llama.layers.30.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.752832] llama.layers.30.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.752862] llama.layers.30.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.752893] llama.layers.30.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.752925] llama.layers.30.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.752955] llama.layers.30.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.752991] llama.layers.30.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.753020] llama.layers.30.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.753050] llama.layers.30.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.753080] llama.layers.30.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.753110] llama.layers.30.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.753141] llama.layers.30.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.753172] llama.layers.30.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.753202] llama.layers.30.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.753233] llama.layers.30.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.753263] llama.layers.30.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.753294] llama.layers.30.attention_norm.weight torch.Size([4096]) True
[00:25:10.753325] llama.layers.30.ffn_norm.weight torch.Size([4096]) True
[00:25:10.753357] llama.layers.31.attention.gate torch.Size([1, 32, 1, 1]) False
[00:25:10.753393] llama.layers.31.attention.wq.weight torch.Size([4096, 4096]) False
[00:25:10.753422] llama.layers.31.attention.wq.bias torch.Size([4096]) True
[00:25:10.753454] llama.layers.31.attention.wk.weight torch.Size([4096, 4096]) False
[00:25:10.753489] llama.layers.31.attention.wv.weight torch.Size([4096, 4096]) False
[00:25:10.753521] llama.layers.31.attention.wo.weight torch.Size([4096, 4096]) False
[00:25:10.753550] llama.layers.31.attention.wo.bias torch.Size([4096]) True
[00:25:10.753580] llama.layers.31.attention.lora_wq_l1.weight torch.Size([16, 4096]) True
[00:25:10.753611] llama.layers.31.attention.lora_wq_l2.weight torch.Size([4096, 16]) True
[00:25:10.753643] llama.layers.31.attention.lora_wk_l1.weight torch.Size([16, 4096]) True
[00:25:10.753673] llama.layers.31.attention.lora_wk_l2.weight torch.Size([4096, 16]) True
[00:25:10.753704] llama.layers.31.attention.lora_wv_l1.weight torch.Size([16, 4096]) True
[00:25:10.753735] llama.layers.31.attention.lora_wv_l2.weight torch.Size([4096, 16]) True
[00:25:10.753767] llama.layers.31.attention.lora_wo_l1.weight torch.Size([16, 4096]) True
[00:25:10.753800] llama.layers.31.attention.lora_wo_l2.weight torch.Size([4096, 16]) True
[00:25:10.753833] llama.layers.31.feed_forward.w1.weight torch.Size([11008, 4096]) False
[00:25:10.753863] llama.layers.31.feed_forward.w1.bias torch.Size([11008]) True
[00:25:10.753894] llama.layers.31.feed_forward.w2.weight torch.Size([4096, 11008]) False
[00:25:10.753923] llama.layers.31.feed_forward.w2.bias torch.Size([4096]) True
[00:25:10.754044] llama.layers.31.feed_forward.w3.weight torch.Size([11008, 4096]) False
[00:25:10.754074] llama.layers.31.feed_forward.w3.bias torch.Size([11008]) True
[00:25:10.754105] llama.layers.31.feed_forward.lora_w1_l1.weight torch.Size([16, 4096]) True
[00:25:10.754136] llama.layers.31.feed_forward.lora_w1_l2.weight torch.Size([11008, 16]) True
[00:25:10.754167] llama.layers.31.feed_forward.lora_w2_l1.weight torch.Size([16, 11008]) True
[00:25:10.754197] llama.layers.31.feed_forward.lora_w2_l2.weight torch.Size([4096, 16]) True
[00:25:10.754228] llama.layers.31.feed_forward.lora_w3_l1.weight torch.Size([16, 4096]) True
[00:25:10.754259] llama.layers.31.feed_forward.lora_w3_l2.weight torch.Size([11008, 16]) True
[00:25:10.754296] llama.layers.31.attention_norm.weight torch.Size([4096]) True
[00:25:10.754326] llama.layers.31.ffn_norm.weight torch.Size([4096]) True
[00:25:10.754358] llama.norm.weight torch.Size([4096]) True
[00:25:10.754388] llama.output.weight torch.Size([32000, 4096]) False
[00:25:10.754421] prefix_query.weight torch.Size([32, 4096]) False
[00:25:10.954795] base lr: 5.00e-04
[00:25:10.954854] actual lr: 6.25e-05
[00:25:10.954872] accumulate grad iterations: 4
[00:25:10.954887] effective batch size: 32
[00:25:10.960378] AdamW (
Parameter Group 0
    amsgrad: False
    betas: (0.9, 0.95)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 6.25e-05
    maximize: False
    weight_decay: 0.0

Parameter Group 1
    amsgrad: False
    betas: (0.9, 0.95)
    capturable: False
    eps: 1e-08
    foreach: None
    lr: 6.25e-05
    maximize: False
    weight_decay: 0.02
)
[00:25:22.752163] Used datasets 22 ['SpoofDetection_Asvspoof2017', 'SpeechTextMatching_LibrispeechTrainClean360', 'DialogueActClassification_DailyTalk', 'DialogueEmotionClassification_DailyTalk', 'SpokenTermDetection_Tedlium2Train', 'NoiseSNRLevelPredictionGaussian_VoxcelebMusan', 'EnhancementDetection_LibrittsTrainClean360Wham', 'SpeakerCounting_LibrittsTrainClean100', 'SpeakerVerification_Aishell1Train', 'SpoofDetection_ASVspoof2015', 'SpeakerVerification_LibrispeechTrainClean100', 'SpeakerVerification_Voxceleb1Train', 'SpokenTermDetection_LibrispeechTrainClean100', 'SpeechDetection_LibrispeechTrainClean100', 'SpeakerVerification_Tedlium2Train', 'NoiseDetectionGaussian_VoxcelebMusan', 'SpeechTextMatching_LibrispeechTrainClean100', 'SpeechDetection_Aishell1Train', 'SpeechTextMatching_Tedlium2Train', 'SpeechDetection_Tedlium2Train', 'ReverberationDetectionSmallRoom_VoxcelebRirsNoises', 'SpeechDetection_Voxceleb1Train']
[00:25:22.752257] 108014
[00:25:22.752440] All train dataset size: 108014
[00:25:22.752516] Sampler_train = <torch.utils.data.distributed.DistributedSampler object at 0x7f89d6782280>
/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/utils/data/dataloader.py:554: UserWarning: This DataLoader will create 10 worker processes in total. Our suggested max number of worker in current system is 4, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.
  warnings.warn(_create_warning_msg(
[00:25:22.756785] Start training for 5 epochs
[00:25:23.035631] log_dir: ./output
[00:25:25.127800] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 735, 314, 457, 278, 12032, 21862, 297, 278, 1023, 10348, 2407, 886, 322, 11097, 565, 896, 2041, 515, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 304, 1716, 10348, 2407, 886, 322, 408, 14082, 565, 896, 526, 19182, 491, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 304, 1716, 10348, 2407, 886, 322, 408, 14082, 565, 896, 526, 19182, 491, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 304, 1716, 10348, 2407, 886, 322, 408, 14082, 565, 896, 526, 19182, 491, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 275, 278, 10348, 15390, 310, 1641, 14831, 408, 5199, 12032, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 5816, 338, 278, 953, 8194, 310, 278, 7928, 434, 29973, 278, 1234, 1033, 367, 27343, 29892, 766, 29887, 504, 29892, 8866, 29892, 14610, 2264, 29892, 22722, 29892, 16671, 29892, 470, 694, 953, 8194, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 953, 8194, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 27902, 565, 278, 4944, 12032, 338, 263, 1121, 310, 7314, 11525, 2785, 363, 13345, 974, 292, 11976, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 598, 278, 1023, 10348, 2407, 886, 19182, 491, 278, 1021, 5375, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:25.128136] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 953, 8194, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:25.128346] torch.Size([8, 3, 1, 128, 204])
[00:25:27.675196] torch.Size([8, 1, 4096])
[W reducer.cpp:1298] Warning: find_unused_parameters=True was specified in DDP constructor, but did not find any unused parameters in the forward pass. This flag results in an extra traversal of the autograd graph every iteration,  which can adversely affect performance. If your model indeed never has any unused parameters in the forward pass, consider turning this flag off. Note that this warning may be a false positive if your model has flow control causing later iterations to have unused parameters. (function operator())
[00:25:28.522808] Epoch: [0]  [    0/13501]  eta: 20:34:30  lr: 0.000000  closs: 6.6518 (6.6518)  mloss: 6.6518 (6.6518)  time: 5.4863  data: 2.0920  max mem: 29101
[00:25:28.523153] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 12032, 7913, 2486, 2755, 278, 1426, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 29875, 29915, 29885, 13421, 591, 1818, 1925, 372, 1283, 304, 2649, 366, 278, 8760, 474, 29915, 29885, 278, 3203, 2586, 297, 278, 3186, 13421, 310, 278, 29561, 404, 474, 626, 451, 472, 599, 1497, 25352, 3547, 385, 629, 2354, 769, 18120, 364, 3096, 536, 263, 371, 670, 17803, 322, 6140, 304, 1348, 393, 393, 4383, 471, 17141, 13, 13, 2277, 29937, 13291, 29901, 3582, 2], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1693, 1598, 565, 278, 4944, 10348, 16867, 3743, 1855, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 26680, 366, 6613, 278, 3158, 310, 278, 7928, 434, 29973, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 262, 689, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 2183, 12032, 322, 1426, 5101, 526, 263, 1993, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 392, 278, 10298, 515, 322, 1647, 304, 18619, 790, 4200, 540, 471, 13461, 11687, 3153, 1048, 564, 29886, 387, 5346, 664, 322, 1663, 12652, 2501, 278, 21159, 654, 310, 1432, 4443, 322, 13382, 2745, 599, 4023, 845, 2264, 322, 12164, 2264, 310, 16225, 892, 10397, 630, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 2183, 12032, 322, 1426, 5101, 526, 263, 1993, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 29880, 1992, 1258, 474, 769, 1348, 393, 1438, 2305, 7180, 491, 263, 2833, 292, 8825, 297, 385, 594, 2212, 2827, 1002, 1489, 290, 892, 304, 367, 590, 10404, 17162, 322, 1565, 7875, 451, 871, 363, 278, 6421, 7378, 297, 393, 564, 20009, 2982, 304, 607, 591, 892, 2675, 541, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 278, 1353, 310, 7726, 414, 17809, 297, 278, 10348, 16867, 29889, 278, 1234, 1033, 367, 697, 29892, 1023, 29892, 2211, 29892, 3023, 29892, 470, 5320, 29889, 13, 13, 2277, 29937, 13291, 29901, 17823, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 16123, 680, 278, 7182, 29899, 517, 29899, 1217, 895, 11959, 310, 278, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 5225, 29892, 5320, 29892, 3006, 29892, 25020, 29892, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 28491, 9404, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 16112, 304, 1716, 10348, 2407, 886, 322, 16833, 565, 896, 526, 19182, 491, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:28.523455] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 262, 689, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17823, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28491, 9404, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:28.523535] torch.Size([8, 3, 1, 128, 204])
[00:25:28.540381] torch.Size([8, 1, 4096])
[00:25:29.144003] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 275, 278, 12032, 322, 1426, 3300, 2859, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 29875, 1348, 393, 29915, 29879, 697, 310, 278, 9590, 2020, 278, 2924, 280, 338, 577, 2107, 474, 1016, 29915, 29873, 505, 304, 4459, 763, 474, 29915, 29885, 472, 664, 304, 1303, 263, 2924, 280, 372, 29915, 29879, 6257, 304, 367, 263, 2217, 2586, 901, 6790, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1867, 278, 12032, 15038, 297, 278, 1023, 10348, 2407, 886, 2041, 515, 278, 1021, 25657, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 278, 3001, 1353, 310, 7726, 414, 17809, 297, 278, 10348, 29889, 278, 1234, 1033, 367, 697, 29892, 1023, 29892, 2211, 29892, 3023, 29892, 470, 5320, 29889, 13, 13, 2277, 29937, 13291, 29901, 10184, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 304, 278, 10348, 322, 8161, 565, 372, 3743, 738, 1147, 5521, 12084, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 5816, 338, 278, 5807, 29878, 7182, 29899, 517, 29899, 1217, 895, 11959, 363, 278, 14401, 749, 640, 9103, 630, 411, 330, 17019, 11462, 29973, 278, 1234, 1033, 367, 5225, 29892, 5320, 29892, 3006, 29892, 25020, 29892, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 28491, 9404, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 304, 278, 10348, 322, 8161, 565, 372, 3743, 738, 1147, 5521, 12084, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 311, 8204, 565, 278, 12032, 7344, 29879, 278, 13013, 310, 278, 3971, 2793, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 1552, 7101, 9488, 1048, 278, 1021, 10075, 3265, 901, 563, 18099, 393, 372, 750, 1063, 13031, 292, 1244, 472, 777, 931, 322, 5537, 2705, 2086, 471, 4318, 491, 278, 1090, 7101, 607, 471, 13725, 310, 269, 7614, 688, 29875, 408, 2898, 408, 13977, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 29883, 20440, 675, 278, 12032, 408, 2845, 13345, 974, 287, 470, 15585, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:29.144320] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10184, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28491, 9404, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:29.144394] torch.Size([8, 3, 1, 128, 204])
[00:25:29.160681] torch.Size([8, 1, 4096])
[00:25:29.762051] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 12032, 322, 12266, 3692, 278, 1734, 338, 5276, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 7892, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 14401, 749, 10371, 277, 11462, 411, 24187, 495, 362, 515, 263, 2319, 5716, 29973, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1990, 1598, 3692, 278, 2183, 14401, 749, 338, 263, 13345, 974, 287, 7314, 470, 385, 15585, 16867, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 598, 278, 1023, 10348, 2407, 886, 19182, 491, 278, 1021, 5375, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 278, 3001, 1353, 310, 7726, 414, 17809, 297, 278, 10348, 29889, 278, 1234, 1033, 367, 697, 29892, 1023, 29892, 2211, 29892, 3023, 29892, 470, 5320, 29889, 13, 13, 2277, 29937, 13291, 29901, 17536, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 3068, 591, 24809, 565, 278, 1023, 10348, 2407, 886, 526, 19182, 491, 278, 1021, 2022, 2729, 373, 1009, 20982, 15038, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 12032, 15038, 297, 278, 1023, 10348, 2407, 886, 322, 8161, 565, 896, 526, 515, 278, 1021, 25657, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 26897, 565, 278, 12032, 14401, 749, 338, 263, 544, 391, 457, 470, 694, 13344, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:29.762417] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17536, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:29.762781] torch.Size([8, 3, 1, 128, 204])
[00:25:29.779506] torch.Size([8, 1, 4096])
[00:25:30.549041] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1693, 1598, 565, 278, 1734, 508, 367, 1476, 2629, 278, 12032, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 262, 794, 292, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 304, 278, 10348, 322, 8161, 565, 372, 3743, 738, 1147, 5521, 12084, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 275, 278, 14401, 749, 1320, 28179, 491, 337, 18248, 11462, 515, 263, 2319, 29899, 29879, 1891, 5716, 29973, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24219, 403, 565, 278, 12032, 7913, 2486, 11524, 278, 1426, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 7045, 278, 11231, 12398, 2381, 279, 2168, 3661, 13936, 263, 13569, 310, 528, 2827, 3291, 322, 270, 352, 368, 27003, 11500, 282, 29379, 2038, 963, 9436, 304, 502, 2996, 1009, 10555, 699, 267, 1449, 9712, 15459, 29915, 29879, 17018, 280, 26755, 287, 697, 310, 278, 363, 331, 520, 8177, 414, 3512, 1623, 1790, 380, 25443, 975, 1075, 8379, 13, 13, 2277, 29937, 13291], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 275, 278, 1734, 5276, 297, 278, 12032, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 2543, 2247, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 26897, 565, 278, 12032, 14401, 749, 338, 263, 2821, 470, 694, 13344, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 18307, 278, 20982, 4021, 1907, 297, 278, 1023, 10348, 2407, 886, 322, 12266, 565, 896, 6852, 304, 278, 1021, 2022, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 17675, 479, 565, 278, 12032, 322, 278, 1426, 4653, 278, 1021, 7014, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 19264, 373, 8437, 1348, 1048, 1906, 23947, 8471, 2712, 373, 8437, 541, 297, 263, 6776, 13076, 18618, 445, 338, 451, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:30.549368] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:30.549555] torch.Size([8, 3, 1, 128, 204])
[00:25:30.566217] torch.Size([8, 1, 4096])
[00:25:31.251601] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 522, 565, 278, 2183, 10348, 338, 2825, 470, 11525, 7964, 491, 263, 12032, 26371, 27967, 1904, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 16123, 680, 278, 7182, 29899, 517, 29899, 1217, 895, 11959, 310, 278, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 5225, 29892, 5320, 29892, 3006, 29892, 25020, 29892, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 841, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 27902, 278, 10110, 310, 278, 25657, 297, 278, 1023, 10348, 2407, 886, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 278, 1353, 310, 7726, 414, 17809, 297, 278, 10348, 16867, 29889, 278, 1234, 1033, 367, 697, 29892, 1023, 29892, 2211, 29892, 3023, 29892, 470, 5320, 29889, 13, 13, 2277, 29937, 13291, 29901, 10184, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 278, 3001, 2302, 310, 7726, 414, 13590, 297, 278, 4944, 10348, 29889, 278, 1234, 1033, 367, 697, 29892, 1023, 29892, 2211, 29892, 3023, 29892, 470, 5320, 29889, 13, 13, 2277, 29937, 13291, 29901, 17823, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1990, 1598, 3692, 278, 2183, 12032, 338, 263, 13345, 974, 287, 7314, 470, 385, 15585, 16867, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 12032, 15038, 297, 278, 1023, 10348, 2407, 886, 322, 8161, 565, 896, 526, 515, 278, 1021, 25657, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 7928, 434, 322, 8161, 967, 3158, 29889, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 262, 689, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:31.252940] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 841, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10184, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17823, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 262, 689, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:31.253132] torch.Size([8, 3, 1, 128, 204])
[00:25:31.270315] torch.Size([8, 1, 4096])
[00:25:31.871834] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 311, 8204, 565, 278, 12032, 7344, 29879, 278, 13013, 310, 278, 3971, 2793, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 11360, 4446, 670, 3700, 1320, 18054, 411, 1153, 479, 1183, 4446, 413, 2518, 1301, 1003, 2955, 411, 29754, 728, 27343, 4446, 393, 1361, 5372, 4359, 7339, 4561, 2302, 264, 749, 29684, 964, 7955, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 12032, 322, 408, 14082, 3692, 278, 2183, 1734, 338, 5134, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 24498, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1990, 1598, 278, 14401, 749, 408, 13345, 974, 287, 470, 15585, 29892, 10816, 12789, 4746, 373, 337, 1456, 16661, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 12032, 1993, 278, 1426, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 392, 474, 2041, 1250, 304, 366, 472, 777, 1298, 2678, 373, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 275, 278, 14401, 749, 1320, 28179, 491, 337, 18248, 11462, 515, 263, 2319, 29899, 29879, 1891, 5716, 29973, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 7928, 434, 322, 12439, 967, 6590, 3158, 29889, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 2055, 790, 573, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 6151, 13946, 3692, 278, 12032, 14401, 749, 338, 263, 2821, 470, 694, 13344, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 278, 11462, 29899, 517, 29899, 25436, 11959, 363, 278, 14401, 749, 640, 9103, 630, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 5225, 29892, 5320, 29892, 3006, 29892, 25020, 29892, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 20818, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:31.872242] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2055, 790, 573, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20818, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:31.872463] torch.Size([8, 3, 1, 128, 204])
[00:25:31.889720] torch.Size([8, 1, 4096])
[00:25:32.491209] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 27902, 565, 278, 12032, 322, 1426, 1993, 1269, 916, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 29882, 5555, 1063, 6296, 701, 515, 2278, 6614, 2501, 278, 7205, 540, 750, 2360, 12399, 278, 3036, 2877, 310, 278, 11302, 297, 607, 540, 471, 1286, 17785, 541, 278, 7575, 4060, 310, 10657, 607, 471, 577, 4549, 263, 17443, 310, 670, 5469, 871, 3734, 278, 9914, 9949, 310, 263, 14225, 322, 2143, 1312, 5469, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 27902, 565, 278, 2183, 12032, 338, 263, 3234, 310, 7314, 11525, 2785, 363, 13345, 974, 292, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 27218, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 304, 278, 10348, 322, 11608, 675, 278, 3158, 29889, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 262, 689, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1990, 1598, 278, 3158, 310, 278, 7928, 434, 29889, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 2055, 790, 573, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 465, 404, 3692, 278, 1023, 10348, 2407, 886, 526, 19182, 491, 278, 1021, 2022, 2729, 373, 1009, 20982, 15038, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 2798, 278, 1353, 310, 5412, 15724, 13590, 297, 278, 10348, 20102, 29889, 278, 1234, 1033, 367, 697, 29892, 1023, 29892, 2211, 29892, 3023, 29892, 470, 5320, 29889, 13, 13, 2277, 29937, 13291, 29901, 20818, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 3068, 278, 4944, 1734, 367, 1476, 297, 278, 16867, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 12620, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 513, 9593, 278, 5807, 29878, 995, 363, 278, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 5225, 29892, 5320, 29892, 3006, 29892, 25020, 29892, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 841, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:32.491547] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 27218, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 262, 689, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2055, 790, 573, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20818, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 841, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:32.491738] torch.Size([8, 3, 1, 128, 204])
[00:25:32.508513] torch.Size([8, 1, 4096])
[00:25:33.166690] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 27902, 565, 278, 12032, 14401, 749, 338, 263, 8296, 470, 694, 13344, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 565, 278, 10348, 11524, 29120, 457, 5199, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 18307, 278, 28848, 297, 278, 1023, 10348, 2407, 886, 322, 11097, 565, 896, 6852, 304, 278, 1021, 25657, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 522, 3692, 278, 14401, 749, 756, 1063, 23116, 368, 5759, 1549, 263, 337, 1456, 5337, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 16867, 1712, 12032, 515, 5199, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 2622, 278, 3158, 7663, 393, 1900, 16612, 278, 7928, 434, 29889, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 11851, 573, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1990, 1598, 278, 14401, 749, 408, 13345, 974, 287, 470, 15585, 29892, 13858, 278, 13331, 310, 263, 337, 1456, 5337, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 1023, 10348, 2407, 886, 6852, 304, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:33.167038] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11851, 573, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:33.167232] torch.Size([8, 3, 1, 128, 204])
[00:25:33.183799] torch.Size([8, 1, 4096])
[00:25:33.783798] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 3198, 565, 278, 12032, 322, 1426, 526, 3300, 2859, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 277, 338, 1532, 451, 871, 304, 9637, 445, 2969, 297, 967, 1407, 24577, 7232, 397, 2073, 297, 4086, 541, 884, 363, 278, 16563, 310, 10230, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 465, 404, 278, 953, 8194, 310, 278, 7928, 434, 29889, 278, 1234, 1033, 367, 27343, 29892, 766, 29887, 504, 29892, 8866, 29892, 14610, 2264, 29892, 22722, 29892, 16671, 29892, 470, 694, 953, 8194, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 953, 8194, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1990, 1598, 278, 4944, 14401, 749, 408, 2845, 385, 15585, 16867, 470, 263, 337, 1456, 287, 697, 2861, 304, 263, 337, 1456, 5337, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1867, 278, 28848, 297, 278, 1023, 10348, 2407, 886, 6852, 304, 278, 1021, 2022, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 311, 8204, 565, 278, 12032, 7344, 29879, 278, 13013, 310, 278, 3971, 2793, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 392, 6060, 366, 674, 367, 2924, 3307, 304, 5967, 592, 472, 10776, 1951, 366, 2609, 2367, 592, 528, 1943, 278, 11460, 16116, 287, 3654, 714, 322, 5764, 670, 5076, 541, 540, 2355, 694, 8709, 393, 931, 363, 278, 916, 10697, 750, 6091, 670, 5828, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 12032, 14401, 749, 338, 263, 11462, 29899, 9021, 470, 694, 13344, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 27902, 565, 278, 12032, 322, 1426, 526, 378, 7108, 296, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 20313, 1492, 1286, 322, 3603, 1711, 322, 14175, 293, 20251, 881, 7246, 4771, 943, 322, 14175, 293, 270, 1617, 267, 304, 6459, 696, 13000, 270, 1617, 267, 322, 2012, 310, 9348, 413, 5495, 270, 1617, 267, 310, 1009, 1914, 701, 304, 15049, 963, 1623, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 465, 404, 3692, 278, 1023, 10348, 2407, 886, 526, 19182, 491, 278, 1021, 2022, 2729, 373, 1009, 20982, 15038, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:33.784130] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 953, 8194, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:33.784333] torch.Size([8, 3, 1, 128, 204])
[00:25:33.800659] torch.Size([8, 1, 4096])
[00:25:34.404170] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 565, 278, 12032, 322, 1426, 27769, 278, 1021, 2472, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 1552, 281, 17840, 521, 8377, 809, 294, 923, 630, 590, 10674, 1450, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1693, 1598, 565, 278, 2183, 1734, 5692, 12214, 2629, 278, 12032, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 4548, 6270, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 275, 278, 14401, 749, 15201, 491, 337, 18248, 11462, 2198, 297, 263, 2319, 5716, 29973, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 565, 278, 12032, 7595, 29879, 411, 278, 9146, 2643, 310, 278, 1426, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 277, 471, 263, 19797, 310, 394, 29885, 523, 29891, 4082, 29882, 304, 502, 322, 278, 916, 1497, 372, 338, 7088, 263, 10405, 4516, 29882, 2232, 322, 474, 674, 2367, 14904, 393, 541, 2125, 372, 304, 1316, 385, 697, 363, 540, 23870, 901, 6909, 322, 19911, 1135, 474, 577, 278, 432, 809, 3614, 372, 304, 278, 432, 809, 4539], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 1734, 1863, 297, 278, 10348, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 7099, 2618, 368, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 565, 278, 10348, 11524, 29120, 457, 5199, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 735, 314, 457, 278, 12032, 21862, 297, 278, 1023, 10348, 2407, 886, 322, 11097, 565, 896, 2041, 515, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 3068, 591, 24809, 565, 278, 1023, 10348, 2407, 886, 526, 19182, 491, 278, 1021, 2022, 2729, 373, 1009, 20982, 15038, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:34.404471] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:34.404666] torch.Size([8, 3, 1, 128, 204])
[00:25:34.421423] torch.Size([8, 1, 4096])
[00:25:35.022038] Epoch: [0]  [   10/13501]  eta: 4:04:58  lr: 0.000000  closs: 7.2689 (7.2368)  mloss: 7.2689 (7.2368)  time: 1.0895  data: 0.1904  max mem: 29574
[00:25:35.022414] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1693, 1598, 3692, 278, 2183, 10348, 756, 1063, 23116, 368, 7371, 470, 19356, 3025, 263, 12032, 26371, 27967, 1904, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1693, 1598, 3692, 278, 2183, 10348, 756, 1090, 29887, 650, 12623, 470, 9068, 3025, 263, 12032, 26371, 27967, 1904, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 27902, 565, 278, 12032, 322, 1426, 526, 378, 7108, 296, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 705, 4658, 727, 338, 1422, 3104, 15942, 2629, 1422, 5312, 1144, 322, 1197, 300, 1338, 322, 591, 864, 304, 5645, 445, 1363, 1532, 1550, 366, 29915, 276, 321, 1218, 263, 380, 1610, 16344, 470, 13748, 292, 23429, 2020, 451, 1831, 278, 697, 393, 29915, 29879, 1556, 3104, 296, 363, 5557, 292, 23900, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 10348, 5718, 310, 1855, 12032, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 565, 278, 10348, 11524, 29120, 457, 5199, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1867, 278, 28848, 297, 278, 1023, 10348, 2407, 886, 6852, 304, 278, 1021, 2022, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 735, 314, 457, 278, 10348, 4559, 322, 408, 14082, 565, 372, 3743, 5936, 13902, 5199, 12032, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 17675, 479, 565, 278, 12032, 322, 278, 1426, 4653, 278, 1021, 7014, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 2541, 451, 925, 1549, 24837, 274, 406, 1182, 284, 21531, 5829, 293, 3519, 541, 491, 22830, 4824, 1711, 8743, 411, 7014, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:35.022709] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:35.022898] torch.Size([8, 3, 1, 128, 204])
[00:25:35.039308] torch.Size([8, 1, 4096])
[00:25:35.694533] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 16467, 304, 278, 12032, 322, 8161, 565, 278, 4944, 1734, 338, 19182, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 15503, 344, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 14401, 749, 1712, 11462, 8581, 491, 24187, 495, 362, 297, 263, 2319, 2913, 29973, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 304, 1716, 10348, 2407, 886, 322, 408, 14082, 565, 896, 526, 19182, 491, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 465, 404, 3692, 278, 12032, 322, 29871, 1426, 6232, 278, 1021, 14407, 2643, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 1450, 10081, 5320, 17208, 338, 3307, 4083, 3300, 599, 1492, 4083, 278, 22707, 6661, 1244, 29915, 29879, 278, 6909, 322, 540, 18139, 372, 714, 297, 3300, 29915, 29879, 1361, 540, 4083, 825, 263, 2217, 15409, 372, 723, 367, 263, 7539, 304, 1074, 1075, 664, 373, 263, 1248, 29877, 1746, 3300, 4083, 13, 13, 2277, 29937, 13291, 29901, 3582], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 565, 278, 10348, 11524, 29120, 457, 5199, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 278, 1353, 310, 8359, 7726, 414, 297, 278, 2183, 10348, 4559, 29889, 278, 1234, 1033, 367, 697, 29892, 1023, 29892, 2211, 29892, 3023, 29892, 470, 5320, 29889, 13, 13, 2277, 29937, 13291, 29901, 17536, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 735, 314, 457, 278, 10348, 4559, 322, 408, 14082, 565, 372, 3743, 5936, 13902, 5199, 12032, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 311, 8204, 565, 278, 12032, 16467, 7087, 278, 2793, 322, 3829, 310, 278, 4944, 1426, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 25682, 519, 515, 17187, 304, 4725, 4950, 8002, 363, 9475, 12407, 288, 858, 261, 22300, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:35.694950] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17536, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:35.695160] torch.Size([8, 3, 1, 128, 204])
[00:25:35.711791] torch.Size([8, 1, 4096])
[00:25:36.313075] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 16112, 304, 1716, 10348, 2407, 886, 322, 16833, 565, 896, 526, 19182, 491, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 10348, 322, 8161, 3692, 372, 11624, 310, 1855, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 10348, 322, 8161, 3692, 372, 11624, 310, 1855, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 6151, 13946, 3692, 278, 12032, 14401, 749, 338, 263, 2821, 470, 694, 13344, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 10348, 5718, 310, 1855, 12032, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 18307, 278, 28848, 297, 278, 1023, 10348, 2407, 886, 322, 12266, 565, 896, 6852, 304, 278, 1021, 2022, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 465, 404, 565, 278, 12032, 14401, 749, 338, 263, 8296, 470, 694, 13344, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 10348, 5718, 310, 1855, 12032, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:36.313401] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:36.313575] torch.Size([8, 3, 1, 128, 204])
[00:25:36.330238] torch.Size([8, 1, 4096])
[00:25:36.929628] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 735, 314, 457, 278, 12032, 322, 12439, 565, 278, 2183, 1734, 338, 5276, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 11083, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 937, 10348, 16867, 322, 8161, 565, 278, 1473, 10348, 16867, 338, 19182, 491, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 342, 370, 1674, 3692, 278, 2183, 10348, 338, 278, 1121, 7371, 491, 263, 12032, 26371, 27967, 1904, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 5816, 338, 278, 953, 8194, 310, 278, 7928, 434, 29973, 278, 1234, 1033, 367, 27343, 29892, 766, 29887, 504, 29892, 8866, 29892, 14610, 2264, 29892, 22722, 29892, 16671, 29892, 470, 694, 953, 8194, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 953, 8194, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 2183, 10348, 20102, 3743, 1855, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 304, 278, 10348, 322, 8161, 565, 372, 3743, 738, 1147, 5521, 12084, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 27902, 565, 278, 12032, 322, 1426, 1993, 1269, 916, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 8256, 366, 526, 4249, 596, 7875, 1449, 366, 674, 2313, 824, 716, 22204, 1497, 589, 14287, 1207, 372, 263, 3414, 1286, 304, 679, 408, 1532, 322, 21732, 408, 1568, 763, 7535, 408, 366, 508, 1434, 540, 19066, 22731, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1990, 1598, 278, 14401, 749, 408, 13345, 974, 287, 470, 15585, 29892, 10816, 12789, 4746, 373, 337, 1456, 16661, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:36.929938] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 953, 8194, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:36.930101] torch.Size([8, 3, 1, 128, 204])
[00:25:36.946663] torch.Size([8, 1, 4096])
[00:25:37.548843] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 2622, 278, 953, 8194, 7663, 310, 278, 7928, 434, 29889, 278, 1234, 1033, 367, 27343, 29892, 766, 29887, 504, 29892, 8866, 29892, 14610, 2264, 29892, 22722, 29892, 16671, 29892, 470, 694, 953, 8194, 29889, 13, 13, 2277, 29937, 13291, 29901, 29882, 932, 3335, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 522, 3692, 278, 4944, 10348, 756, 1063, 7371, 773, 263, 12032, 26371, 27967, 1904, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 27902, 565, 278, 12032, 322, 1426, 1993, 1269, 916, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 3707, 565, 474, 892, 278, 871, 2022, 7291, 393, 982, 591, 723, 367, 297, 7458, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 275, 278, 10348, 15390, 310, 1641, 14831, 408, 5199, 12032, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 18307, 278, 28848, 297, 278, 1023, 10348, 2407, 886, 322, 12266, 565, 896, 6852, 304, 278, 1021, 2022, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 1023, 10348, 2407, 886, 6852, 304, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 565, 278, 10348, 11524, 29120, 457, 5199, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 17675, 479, 565, 278, 12032, 322, 278, 1426, 4653, 278, 1021, 7014, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 262, 697, 10405, 14183, 6893, 322, 25020, 372, 29915, 29879, 451, 763, 14578, 21321, 892, 7901, 1218, 263, 3287, 1048, 1009, 14175, 293, 5544, 747, 9770, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:37.565144] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 29882, 932, 3335, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:37.565381] torch.Size([8, 3, 1, 128, 204])
[00:25:37.582338] torch.Size([8, 1, 4096])
[00:25:38.237718] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 2183, 10348, 20102, 3743, 1855, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1693, 1598, 565, 278, 4944, 10348, 16867, 3743, 1855, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 278, 3001, 1353, 310, 7726, 414, 17809, 297, 278, 10348, 29889, 278, 1234, 1033, 367, 697, 29892, 1023, 29892, 2211, 29892, 3023, 29892, 470, 5320, 29889, 13, 13, 2277, 29937, 13291, 29901, 10184, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 2886, 714, 278, 3158, 310, 278, 7928, 434, 29889, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 11851, 573, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 2622, 278, 953, 8194, 7663, 310, 278, 7928, 434, 29889, 278, 1234, 1033, 367, 27343, 29892, 766, 29887, 504, 29892, 8866, 29892, 14610, 2264, 29892, 22722, 29892, 16671, 29892, 470, 694, 953, 8194, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 953, 8194, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 278, 3001, 2302, 310, 7726, 414, 13590, 297, 278, 4944, 10348, 29889, 278, 1234, 1033, 367, 697, 29892, 1023, 29892, 2211, 29892, 3023, 29892, 470, 5320, 29889, 13, 13, 2277, 29937, 13291, 29901, 10184, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 311, 8204, 565, 278, 12032, 16467, 7087, 278, 2793, 322, 3829, 310, 278, 4944, 1426, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 392, 1671, 7788, 2012, 964, 620, 261, 7869, 29879, 310, 29120, 457, 6993, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 522, 3692, 278, 4944, 10348, 756, 1063, 7371, 773, 263, 12032, 26371, 27967, 1904, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:38.238092] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10184, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11851, 573, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 953, 8194, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 10184, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:38.265147] torch.Size([8, 3, 1, 128, 204])
[00:25:38.282730] torch.Size([8, 1, 4096])
[00:25:38.884303] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 522, 3692, 278, 4944, 10348, 756, 1063, 7371, 773, 263, 12032, 26371, 27967, 1904, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 10348, 3743, 5199, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 2183, 12032, 322, 1426, 5101, 526, 263, 1993, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 4716, 471, 269, 2495, 290, 14914, 902, 411, 263, 1424, 335, 333, 316, 1659, 393, 471, 297, 17073, 14981, 12327, 5414, 304, 902, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 2798, 278, 1353, 310, 5412, 15724, 13590, 297, 278, 10348, 20102, 29889, 278, 1234, 1033, 367, 697, 29892, 1023, 29892, 2211, 29892, 3023, 29892, 470, 5320, 29889, 13, 13, 2277, 29937, 13291, 29901, 17536, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1990, 1598, 3692, 278, 2183, 14401, 749, 338, 263, 13345, 974, 287, 7314, 470, 385, 15585, 16867, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 342, 370, 1674, 3692, 278, 4944, 10348, 338, 278, 21957, 310, 23116, 12623, 773, 263, 12032, 26371, 27967, 1904, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 3198, 3692, 278, 2183, 1734, 338, 2198, 297, 278, 2183, 12032, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 7707, 682, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1990, 1598, 278, 7928, 434, 1044, 29889, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 262, 689, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:38.884606] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17536, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 262, 689, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:38.884690] torch.Size([8, 3, 1, 128, 204])
[00:25:38.901264] torch.Size([8, 1, 4096])
[00:25:39.502009] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 311, 8204, 565, 278, 12032, 322, 1426, 526, 13747, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 1552, 337, 7168, 366, 1074, 297, 278, 13722, 1244, 445, 338, 1546, 19044, 322, 697, 6893, 4508, 1450, 1131, 29879, 541, 393, 29915, 29879, 263, 15243, 310, 3081, 393, 29915, 29879, 1546, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 16112, 304, 1716, 10348, 2407, 886, 322, 16833, 565, 896, 526, 19182, 491, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 12032, 1993, 278, 1426, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 5372, 310, 366, 20000, 393, 694, 23925, 273, 8688, 368, 263, 2618, 470, 18443, 287, 278, 4023, 546, 29915, 29879, 6013, 719, 26195, 541, 1603, 1663, 391, 393, 1749, 437, 9988, 1475, 322, 28721, 12695, 3275, 304, 1316, 2582, 591, 437, 451, 4658, 372, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 14401, 749, 505, 337, 18248, 11462, 393, 620, 1590, 793, 263, 2319, 29899, 29879, 1891, 5716, 29973, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 342, 370, 1674, 565, 278, 12032, 14401, 749, 338, 263, 544, 391, 457, 470, 694, 13344, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1693, 1598, 565, 278, 4944, 10348, 16867, 3743, 1855, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 465, 404, 3692, 278, 1023, 10348, 2407, 886, 526, 19182, 491, 278, 1021, 2022, 2729, 373, 1009, 20982, 15038, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 3068, 591, 24809, 565, 278, 1023, 10348, 2407, 886, 526, 19182, 491, 278, 1021, 2022, 2729, 373, 1009, 20982, 15038, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:39.502297] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:39.502381] torch.Size([8, 3, 1, 128, 204])
[00:25:39.519114] torch.Size([8, 1, 4096])
[00:25:40.120995] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 21803, 278, 3158, 393, 1900, 16612, 278, 16867, 29889, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 12470, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 10348, 934, 322, 11097, 3692, 372, 7805, 1855, 19182, 3838, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 1734, 1863, 297, 278, 10348, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 392, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 465, 404, 278, 953, 8194, 310, 278, 7928, 434, 29889, 278, 1234, 1033, 367, 27343, 29892, 766, 29887, 504, 29892, 8866, 29892, 14610, 2264, 29892, 22722, 29892, 16671, 29892, 470, 694, 953, 8194, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 953, 8194, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1867, 278, 28848, 297, 278, 1023, 10348, 2407, 886, 6852, 304, 278, 1021, 2022, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1867, 278, 28848, 297, 278, 1023, 10348, 2407, 886, 6852, 304, 278, 1021, 2022, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 10348, 934, 322, 11097, 3692, 372, 7805, 1855, 19182, 3838, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 18307, 278, 28848, 297, 278, 1023, 10348, 2407, 886, 322, 12266, 565, 896, 6852, 304, 278, 1021, 2022, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:40.121377] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12470, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 953, 8194, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:40.121455] torch.Size([8, 3, 1, 128, 204])
[00:25:40.138392] torch.Size([8, 1, 4096])
[00:25:40.791630] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 17675, 479, 565, 278, 12032, 322, 278, 1426, 4653, 278, 1021, 7014, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 392, 746, 278, 12580, 310, 25535, 29738, 471, 577, 2215, 269, 2364, 6419, 393, 967, 12032, 5153, 2760, 7113, 278, 2791, 310, 1749, 21082, 278, 937, 2655, 393, 471, 11098, 491, 592, 471, 3856, 287, 523, 367, 12595, 288, 534, 457, 322, 697, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 465, 404, 565, 278, 12032, 14401, 749, 338, 263, 8296, 470, 694, 13344, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 552, 559, 12439, 278, 3158, 297, 278, 10348, 29889, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 262, 689, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 311, 8204, 565, 278, 12032, 322, 1426, 526, 13747, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 277, 338, 1584, 8002, 304, 22564, 278, 766, 6388, 5281, 1889, 322, 304, 6963, 1048, 263, 5119, 7168, 2354, 6728, 292, 274, 545, 278, 3151, 1230, 4221, 800, 11122, 297, 278, 7902, 2185, 1326, 886, 505, 1063, 16725, 491, 590, 1914, 7271, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 16467, 304, 278, 12032, 322, 8161, 565, 278, 4944, 1734, 338, 19182, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 29423, 1891, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 12032, 14401, 749, 338, 263, 11462, 29899, 9021, 470, 694, 13344, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24219, 403, 278, 12032, 322, 12266, 3692, 278, 2183, 1734, 338, 2198, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 29886, 1461, 7612, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 4944, 14401, 749, 338, 263, 14710, 7492, 7314, 2825, 363, 13345, 974, 292, 11976, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 27218, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:40.792061] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 262, 689, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 27218, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:40.792197] torch.Size([8, 3, 1, 128, 204])
[00:25:40.808702] torch.Size([8, 1, 4096])
[00:25:41.412569] Epoch: [0]  [   20/13501]  eta: 3:16:35  lr: 0.000000  closs: 7.6279 (7.5847)  mloss: 7.6279 (7.5847)  time: 0.6444  data: 0.0002  max mem: 29574
[00:25:41.412919] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 10348, 322, 8161, 3692, 372, 11624, 310, 1855, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 2183, 12032, 322, 1426, 5101, 526, 263, 1993, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 29875, 2665, 590, 1473, 1487, 285, 1127, 592, 1416, 261, 304, 301, 898, 265, 304, 5110, 278, 3033, 1674, 3519, 310, 17770, 278, 282, 342, 322, 304, 1053, 777, 805, 764, 292, 7672, 262, 708, 591, 1476, 304, 1749, 3438, 3138, 297, 278, 3236, 310, 931, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 278, 1353, 310, 7726, 414, 17809, 297, 278, 10348, 16867, 29889, 278, 1234, 1033, 367, 697, 29892, 1023, 29892, 2211, 29892, 3023, 29892, 470, 5320, 29889, 13, 13, 2277, 29937, 13291, 29901, 20818, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 513, 9593, 278, 5807, 29878, 995, 363, 278, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 5225, 29892, 5320, 29892, 3006, 29892, 25020, 29892, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 20818, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 5816, 338, 278, 953, 8194, 310, 278, 7928, 434, 29973, 278, 1234, 1033, 367, 27343, 29892, 766, 29887, 504, 29892, 8866, 29892, 14610, 2264, 29892, 22722, 29892, 16671, 29892, 470, 694, 953, 8194, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 953, 8194, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 275, 278, 1734, 5276, 297, 278, 12032, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 29888, 11115, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 735, 314, 457, 278, 12032, 21862, 297, 278, 1023, 10348, 2407, 886, 322, 11097, 565, 896, 2041, 515, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 465, 404, 3692, 278, 1023, 10348, 2407, 886, 526, 19182, 491, 278, 1021, 2022, 2729, 373, 1009, 20982, 15038, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:41.413472] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20818, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20818, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 953, 8194, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:41.413561] torch.Size([8, 3, 1, 128, 204])
[00:25:41.430177] torch.Size([8, 1, 4096])
[00:25:42.031585] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 10348, 322, 8161, 3692, 372, 11624, 310, 1855, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 513, 9593, 278, 5807, 29878, 995, 363, 278, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 5225, 29892, 5320, 29892, 3006, 29892, 25020, 29892, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 28491, 9404, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 465, 404, 278, 937, 10348, 16867, 322, 8161, 565, 278, 1473, 10348, 16867, 338, 19182, 491, 278, 1021, 2022, 29889, 18307, 278, 1023, 10348, 2407, 886, 322, 11097, 565, 896, 526, 19182, 491, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 522, 565, 278, 2183, 10348, 338, 2825, 470, 11525, 7964, 491, 263, 12032, 26371, 27967, 1904, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1990, 1598, 3692, 278, 2183, 14401, 749, 338, 263, 1121, 310, 7314, 13345, 974, 292, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 27902, 565, 278, 12032, 14401, 749, 338, 263, 2821, 470, 694, 13344, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 565, 278, 12032, 7595, 29879, 411, 278, 9146, 2643, 310, 278, 1426, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 277, 471, 297, 445, 2106, 310, 278, 26195, 393, 278, 10668, 886, 310, 825, 750, 10761, 7450, 282, 1308, 297, 325, 819, 1056, 408, 338, 4475, 297, 278, 1833, 16385, 540, 7389, 731, 714, 373, 670, 736, 304, 286, 14174, 340, 297, 263, 2106, 310, 1153, 479, 322, 285, 2857, 2750, 278, 15121, 1379, 13, 13, 2277, 29937], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 14401, 749, 505, 337, 18248, 11462, 393, 620, 1590, 793, 263, 2319, 29899, 29879, 1891, 5716, 29973, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:42.031918] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 28491, 9404, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:42.031994] torch.Size([8, 3, 1, 128, 204])
[00:25:42.048882] torch.Size([8, 1, 4096])
[00:25:42.648522] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 598, 278, 1023, 10348, 2407, 886, 19182, 491, 278, 1021, 5375, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 565, 278, 2183, 10348, 20102, 338, 1855, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 1023, 10348, 2407, 886, 6852, 304, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 552, 559, 12439, 278, 3158, 297, 278, 10348, 29889, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 262, 689, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 27902, 565, 278, 12032, 322, 1426, 526, 378, 7108, 296, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 392, 746, 474, 8293, 310, 366, 472, 298, 2749, 4885, 12713, 474, 1073, 393, 366, 526, 373, 596, 982, 304, 278, 916, 2712, 437, 2649, 592, 825, 2834, 338, 763, 411, 288, 2774, 2741, 322, 28008, 1026, 310, 3236, 540, 2360, 15873, 540, 338, 697, 310, 1906, 1757, 1058, 373, 20479, 292, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 14401, 749, 1712, 11462, 8581, 491, 24187, 495, 362, 297, 263, 2319, 2913, 29973, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 5816, 338, 278, 3158, 310, 278, 7928, 434, 29973, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 12470, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 735, 314, 457, 278, 10348, 4559, 322, 408, 14082, 565, 372, 3743, 5936, 13902, 5199, 12032, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:42.648860] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 262, 689, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12470, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:42.649068] torch.Size([8, 3, 1, 128, 204])
[00:25:42.665942] torch.Size([8, 1, 4096])
[00:25:43.322623] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 2793, 310, 278, 10348, 20102, 322, 8161, 278, 8210, 3158, 29889, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 11851, 573, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 278, 11462, 29899, 517, 29899, 25436, 11959, 363, 278, 14401, 749, 640, 9103, 630, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 5225, 29892, 5320, 29892, 3006, 29892, 25020, 29892, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 20818, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 16867, 1712, 12032, 515, 5199, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 27902, 565, 278, 4944, 12032, 338, 263, 1121, 310, 7314, 11525, 2785, 363, 13345, 974, 292, 11976, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 465, 404, 278, 3158, 310, 278, 7928, 434, 29889, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 12470, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24219, 403, 278, 12032, 322, 12266, 3692, 278, 2183, 1734, 338, 2198, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 4530, 29879, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 2183, 12032, 322, 1426, 5101, 526, 263, 1993, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 6098, 278, 27725, 471, 6200, 23393, 541, 278, 8760, 338, 15100, 393, 526, 18225, 472, 263, 16812, 3147, 29873, 27725, 14074, 393, 560, 273, 411, 607, 263, 1781, 7156, 508, 8681, 533, 963, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 27902, 565, 278, 12032, 14401, 749, 338, 263, 2821, 470, 694, 13344, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:43.323039] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11851, 573, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20818, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12470, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:43.323239] torch.Size([8, 3, 1, 128, 204])
[00:25:43.339978] torch.Size([8, 1, 4096])
[00:25:43.942559] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 275, 278, 12032, 322, 1426, 3300, 2859, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 8066, 1781, 1734, 674, 704, 27084, 592, 505, 366, 1063, 297, 278, 25502, 304, 2462, 1183, 3512, 373, 4441, 3262, 902, 7314, 1449, 297, 263, 21039, 756, 286, 1531, 5075, 328, 744, 1063, 2978, 278, 274, 1501, 482, 756, 3052, 2316, 4727, 1063, 714, 310, 278, 16423, 694, 526, 366, 1854, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 10348, 934, 322, 11097, 3692, 372, 7805, 1855, 19182, 3838, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 465, 404, 278, 937, 10348, 16867, 322, 8161, 565, 278, 1473, 10348, 16867, 338, 19182, 491, 278, 1021, 2022, 29889, 18307, 278, 1023, 10348, 2407, 886, 322, 11097, 565, 896, 526, 19182, 491, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1990, 1598, 278, 12032, 408, 2845, 263, 13345, 974, 287, 7314, 470, 385, 15585, 16867, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 27218, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 275, 278, 10348, 15390, 310, 1641, 14831, 408, 5199, 12032, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1867, 278, 28848, 297, 278, 1023, 10348, 2407, 886, 6852, 304, 278, 1021, 2022, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1867, 278, 12032, 15038, 297, 278, 1023, 10348, 2407, 886, 2041, 515, 278, 1021, 25657, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 275, 278, 14401, 749, 10879, 287, 491, 24187, 495, 362, 11462, 3978, 1218, 515, 263, 5716, 310, 2319, 2159, 29973, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:43.943347] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 27218, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:43.943555] torch.Size([8, 3, 1, 128, 204])
[00:25:43.960280] torch.Size([8, 1, 4096])
[00:25:44.562784] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 565, 278, 4944, 10348, 756, 1063, 14710, 300, 1711, 5759, 773, 263, 12032, 26371, 27967, 1904, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1990, 1598, 278, 12032, 408, 2845, 263, 13345, 974, 287, 7314, 470, 385, 15585, 16867, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1990, 1598, 278, 4944, 14401, 749, 408, 2845, 263, 13345, 974, 287, 7314, 470, 385, 15585, 697, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 14401, 749, 1712, 11462, 8581, 491, 24187, 495, 362, 297, 263, 2319, 2913, 29973, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 27902, 565, 278, 12032, 14401, 749, 338, 263, 2821, 470, 694, 13344, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 10348, 3743, 5199, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 278, 4944, 10348, 2407, 886, 526, 515, 1021, 2022, 2729, 373, 1009, 25657, 10110, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 278, 953, 8194, 27769, 287, 297, 278, 7928, 434, 29889, 278, 1234, 1033, 367, 27343, 29892, 766, 29887, 504, 29892, 8866, 29892, 14610, 2264, 29892, 22722, 29892, 16671, 29892, 470, 694, 953, 8194, 29889, 13, 13, 2277, 29937, 13291, 29901, 29882, 932, 3335, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:44.563109] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 29882, 932, 3335, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:44.563345] torch.Size([8, 3, 1, 128, 204])
[00:25:44.590780] torch.Size([8, 1, 4096])
[00:25:45.191099] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1693, 1598, 565, 278, 1734, 508, 367, 1476, 2629, 278, 12032, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 4287, 29880, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 522, 3692, 278, 4944, 10348, 756, 1063, 7371, 773, 263, 12032, 26371, 27967, 1904, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 565, 278, 12032, 7595, 29879, 411, 278, 9146, 2643, 310, 278, 1426, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 7045, 3006, 2440, 310, 15729, 474, 1476, 372, 723, 366, 763, 304, 1074, 372, 474, 6296, 777, 411, 592, 445, 2217, 269, 4316, 19144, 3743, 278, 14731, 13206, 29883, 1297, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 12032, 7913, 2486, 2755, 278, 1426, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 29875, 471, 7500, 411, 2498, 4575, 13716, 16241, 443, 5143, 443, 5143, 1497, 590, 2769, 11826, 491, 278, 946, 265, 5921, 20436, 14999, 964, 758, 1111, 8802, 2466, 1301, 5047, 3081, 322, 8814, 18018, 2358, 1774, 701, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 735, 314, 457, 278, 12032, 21862, 297, 278, 1023, 10348, 2407, 886, 322, 11097, 565, 896, 2041, 515, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1990, 1598, 278, 7928, 434, 1044, 29889, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 11851, 573, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 2886, 714, 278, 3158, 310, 278, 7928, 434, 29889, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 12470, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 18307, 278, 28848, 297, 278, 1023, 10348, 2407, 886, 322, 12266, 565, 896, 6852, 304, 278, 1021, 2022, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:45.191371] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 11851, 573, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12470, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:45.191532] torch.Size([8, 3, 1, 128, 204])
[00:25:45.208681] torch.Size([8, 1, 4096])
[00:25:45.865800] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 6550, 1598, 278, 11959, 1546, 278, 7182, 9324, 322, 278, 11462, 3233, 297, 278, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 5225, 29892, 5320, 29892, 3006, 29892, 25020, 29892, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 9171, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24219, 403, 278, 12032, 322, 12266, 3692, 278, 2183, 1734, 338, 2198, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 3062, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 304, 278, 10348, 322, 8161, 565, 372, 3743, 738, 1147, 5521, 12084, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 29883, 20440, 675, 278, 12032, 408, 2845, 13345, 974, 287, 470, 15585, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 565, 278, 4944, 1734, 338, 5276, 297, 278, 12032, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 29136, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1990, 1598, 278, 4944, 14401, 749, 408, 2845, 385, 15585, 16867, 470, 263, 337, 1456, 287, 697, 2861, 304, 263, 337, 1456, 5337, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 275, 278, 14401, 749, 15201, 491, 337, 18248, 11462, 2198, 297, 263, 2319, 5716, 29973, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 5816, 338, 278, 3158, 310, 278, 7928, 434, 29973, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 12470, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:45.866144] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9171, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12470, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:45.866446] torch.Size([8, 3, 1, 128, 204])
[00:25:45.882955] torch.Size([8, 1, 4096])
[00:25:46.485184] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 10348, 3743, 5199, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 12032, 322, 8161, 278, 953, 8194, 29889, 278, 1234, 1033, 367, 27343, 29892, 766, 29887, 504, 29892, 8866, 29892, 14610, 2264, 29892, 22722, 29892, 16671, 29892, 470, 694, 953, 8194, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 953, 8194, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 465, 404, 3692, 278, 1023, 10348, 2407, 886, 526, 19182, 491, 278, 1021, 2022, 2729, 373, 1009, 20982, 15038, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 17675, 479, 565, 278, 12032, 14401, 749, 338, 263, 8296, 470, 694, 13344, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 2886, 714, 565, 278, 2183, 10348, 338, 263, 3234, 310, 12623, 491, 263, 12032, 26371, 27967, 1904, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 278, 3001, 2302, 310, 7726, 414, 13590, 297, 278, 4944, 10348, 29889, 278, 1234, 1033, 367, 697, 29892, 1023, 29892, 2211, 29892, 3023, 29892, 470, 5320, 29889, 13, 13, 2277, 29937, 13291, 29901, 20818, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 275, 278, 10348, 15390, 310, 1641, 14831, 408, 5199, 12032, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 12032, 1993, 278, 1426, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 801, 1497, 278, 2030, 767, 282, 23980, 902, 373, 278, 2343, 322, 13590, 408, 22832, 2486, 408, 565, 1183, 750, 1063, 670, 15381, 568, 2278, 6460, 9425, 825, 437, 366, 1348, 310, 445, 8099, 22165, 10395, 5570, 756, 871, 3971, 304, 902, 2748, 871, 2748, 22165, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:46.485794] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 953, 8194, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20818, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:46.485976] torch.Size([8, 3, 1, 128, 204])
[00:25:46.502511] torch.Size([8, 1, 4096])
[00:25:47.105256] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 1098, 296, 3598, 304, 278, 12032, 322, 12439, 565, 278, 6790, 1734, 338, 1304, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 18732, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 26680, 366, 6613, 278, 3158, 310, 278, 7928, 434, 29973, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 262, 689, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24219, 403, 278, 10348, 322, 11097, 565, 372, 11624, 310, 1855, 12032, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 342, 370, 1674, 565, 278, 12032, 14401, 749, 338, 263, 544, 391, 457, 470, 694, 13344, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 10348, 934, 322, 11097, 3692, 372, 7805, 1855, 19182, 3838, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 735, 314, 457, 278, 12032, 304, 408, 14082, 565, 278, 2183, 1734, 338, 5276, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 771, 345, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 465, 404, 3692, 278, 1023, 10348, 2407, 886, 526, 19182, 491, 278, 1021, 2022, 2729, 373, 1009, 20982, 15038, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 3068, 278, 4944, 1734, 367, 1476, 297, 278, 16867, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 13716, 1862, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:47.105584] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 262, 689, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:47.105784] torch.Size([8, 3, 1, 128, 204])
[00:25:47.122438] torch.Size([8, 1, 4096])
[00:25:47.724906] Epoch: [0]  [   30/13501]  eta: 2:58:47  lr: 0.000000  closs: 7.8606 (7.5742)  mloss: 7.8606 (7.5742)  time: 0.6351  data: 0.0003  max mem: 29574
[00:25:47.725278] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 3198, 3692, 278, 2183, 1734, 338, 2198, 297, 278, 2183, 12032, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 547, 3707, 5485, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 12032, 322, 12266, 3692, 278, 1734, 338, 5276, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 14506, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 10348, 934, 322, 11097, 3692, 372, 7805, 1855, 19182, 3838, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 275, 278, 1734, 5276, 297, 278, 12032, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 13155, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 10348, 934, 322, 11097, 3692, 372, 7805, 1855, 19182, 3838, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 304, 278, 10348, 20102, 322, 8161, 565, 372, 3743, 1855, 12032, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24219, 403, 278, 10348, 322, 11097, 565, 372, 11624, 310, 1855, 12032, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 27902, 565, 278, 12032, 14401, 749, 338, 263, 2821, 470, 694, 13344, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:47.725517] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:47.725686] torch.Size([8, 3, 1, 128, 204])
[00:25:47.742191] torch.Size([8, 1, 4096])
[00:25:48.396210] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 304, 278, 16867, 322, 16833, 565, 372, 11624, 310, 1855, 5199, 12032, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 342, 370, 1674, 565, 278, 12032, 14401, 749, 338, 263, 544, 391, 457, 470, 694, 13344, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 2183, 10348, 20102, 3743, 1855, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 565, 278, 4944, 10348, 756, 1063, 14710, 300, 1711, 5759, 773, 263, 12032, 26371, 27967, 1904, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 12032, 15038, 297, 278, 1023, 10348, 2407, 886, 322, 8161, 565, 896, 526, 515, 278, 1021, 25657, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1693, 1598, 565, 278, 12032, 756, 1063, 11525, 7964, 304, 23332, 573, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 10348, 3743, 5199, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 3198, 3692, 278, 2183, 1734, 338, 2198, 297, 278, 2183, 12032, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 4187, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:48.396500] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:48.396700] torch.Size([8, 3, 1, 128, 204])
[00:25:48.413170] torch.Size([8, 1, 4096])
[00:25:49.013457] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 565, 278, 12032, 322, 1426, 27769, 278, 1021, 2472, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 5675, 263, 8261, 5036, 270, 820, 1196, 263, 2919, 5036, 270, 728, 411, 278, 11417, 322, 289, 1296, 2125, 2211, 29871, 1309, 778, 310, 394, 8315, 29879, 322, 282, 618, 304, 263, 11417, 788, 2211, 6131, 1129, 265, 1319, 29879, 310, 9505, 369, 1891, 26438, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 16123, 680, 278, 11462, 3233, 9401, 304, 278, 7182, 297, 278, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 5225, 29892, 5320, 29892, 3006, 29892, 25020, 29892, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 565, 278, 10348, 11524, 29120, 457, 5199, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 275, 278, 1734, 5276, 297, 278, 12032, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 1859, 14556, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 275, 278, 14401, 749, 21302, 491, 337, 18248, 11462, 9819, 515, 263, 2319, 5716, 29973, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 278, 953, 8194, 27769, 287, 297, 278, 7928, 434, 29889, 278, 1234, 1033, 367, 27343, 29892, 766, 29887, 504, 29892, 8866, 29892, 14610, 2264, 29892, 22722, 29892, 16671, 29892, 470, 694, 953, 8194, 29889, 13, 13, 2277, 29937, 13291, 29901, 29879, 328, 2264, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1693, 1598, 565, 278, 4944, 10348, 16867, 3743, 1855, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 2886, 714, 278, 3158, 310, 278, 7928, 434, 29889, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 12470, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:49.014073] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 29879, 328, 2264, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 12470, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:49.014255] torch.Size([8, 3, 1, 128, 204])
[00:25:49.030860] torch.Size([8, 1, 4096])
[00:25:49.633622] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 3692, 278, 10348, 3743, 5199, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1990, 1598, 3692, 278, 2183, 12032, 338, 263, 13345, 974, 287, 7314, 470, 385, 15585, 16867, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1693, 1598, 278, 3001, 1353, 310, 7726, 414, 297, 278, 10348, 29889, 278, 1234, 1033, 367, 697, 29892, 1023, 29892, 2211, 29892, 3023, 29892, 470, 5320, 29889, 13, 13, 2277, 29937, 13291, 29901, 17823, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 16123, 680, 278, 7182, 29899, 517, 29899, 1217, 895, 11959, 310, 278, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 5225, 29892, 5320, 29892, 3006, 29892, 25020, 29892, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 20818, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 12032, 7913, 2486, 2755, 278, 1426, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 26026, 278, 4005, 567, 29891, 5768, 297, 596, 10416, 9213, 366, 1497, 2653, 384, 6041, 474, 1348, 372, 1258, 1374, 2518, 1148, 3512, 373, 738, 3525, 2654, 28015, 300, 322, 26343, 9018, 357, 278, 916, 6940, 13273, 9087, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 465, 404, 3692, 278, 1023, 10348, 2407, 886, 526, 19182, 491, 278, 1021, 2022, 2729, 373, 1009, 20982, 15038, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 16867, 1712, 12032, 515, 5199, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 1693, 1598, 565, 278, 4944, 10348, 16867, 3743, 1855, 12032, 470, 451, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:49.633918] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 17823, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 20818, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:49.634002] torch.Size([8, 3, 1, 128, 204])
[00:25:49.650528] torch.Size([8, 1, 4096])
[00:25:50.250601] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 21803, 278, 3158, 7663, 393, 1556, 7913, 2486, 16612, 278, 7928, 434, 29889, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 262, 689, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 311, 8204, 565, 278, 12032, 322, 1426, 526, 13747, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 392, 652, 1765, 287, 278, 18363, 515, 278, 3765, 2224, 310, 9121, 322, 7631, 2834, 988, 262, 1434, 896, 892, 4527, 29894, 630, 491, 596, 21684, 14886, 896, 750, 8833, 278, 4610, 1041, 310, 278, 7242, 1237, 322, 5480, 746, 278, 2462, 4091, 27470, 607, 338, 451, 2215, 21188, 7572, 278, 1601, 29895, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 27902, 278, 10110, 310, 278, 25657, 297, 278, 1023, 10348, 2407, 886, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 465, 404, 278, 937, 10348, 16867, 322, 8161, 565, 278, 1473, 10348, 16867, 338, 19182, 491, 278, 1021, 2022, 29889, 18307, 278, 1023, 10348, 2407, 886, 322, 11097, 565, 896, 526, 19182, 491, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 29883, 20440, 675, 278, 14401, 749, 408, 13345, 974, 287, 470, 3978, 1218, 515, 385, 15585, 25657, 29892, 13858, 7037, 337, 1456, 16661, 29889, 278, 1234, 1033, 367, 13345, 974, 287, 470, 15585, 29889, 13, 13, 2277, 29937, 13291, 29901, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 311, 8204, 565, 278, 12032, 322, 1426, 1993, 1269, 916, 17503, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 29879, 1297, 25895, 9016, 1146, 2736, 471, 901, 18014, 1135, 3926, 322, 1497, 288, 13019, 366, 505, 321, 2579, 599, 278, 17803, 393, 474, 1754, 7960, 363, 599, 278, 15006, 297, 278, 3186, 322, 278, 13019, 1497, 288, 6989, 5735, 363, 3926, 541, 437, 366, 2289, 1246, 393, 263, 17803, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 4801, 837, 457, 565, 278, 12032, 322, 1426, 27769, 278, 1021, 2472, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 392, 7404, 2222, 14517, 411, 1556, 22176, 363, 599, 1492, 11643, 1189, 2879, 23382, 1749, 639, 1441, 29879, 310, 10298, 505, 443, 799, 386, 287, 27482, 297, 607, 10298, 338, 7091, 297, 2498, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 465, 404, 278, 937, 10348, 16867, 322, 8161, 565, 278, 1473, 10348, 16867, 338, 19182, 491, 278, 1021, 2022, 29889, 18307, 278, 1023, 10348, 2407, 886, 322, 11097, 565, 896, 526, 19182, 491, 278, 1021, 5375, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:50.250930] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 262, 689, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1028, 29877, 974, 287, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 3582, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:50.251007] torch.Size([8, 3, 1, 128, 204])
[00:25:50.267478] torch.Size([8, 1, 4096])
[00:25:50.926320] torch.Size([8, 128]) [[1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 12032, 15038, 297, 278, 1023, 10348, 2407, 886, 322, 8161, 565, 896, 526, 515, 278, 1021, 25657, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 14401, 749, 1712, 11462, 8581, 491, 24187, 495, 362, 297, 263, 2319, 2913, 29973, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 20631, 304, 278, 10348, 322, 11608, 675, 278, 3158, 29889, 278, 1234, 1033, 367, 1139, 29892, 1871, 29892, 17041, 29892, 470, 844, 790, 573, 29889, 13, 13, 2277, 29937, 13291, 29901, 2055, 790, 573, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29892, 3300, 2859, 411, 385, 1881, 393, 8128, 4340, 3030, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 13221, 278, 12032, 7595, 411, 278, 9146, 2643, 310, 278, 1426, 29973, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 10567, 29901, 13, 16344, 17306, 1122, 1473, 596, 5497, 10395, 314, 756, 6496, 263, 2752, 310, 14919, 21549, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 24209, 911, 278, 12032, 322, 8161, 278, 953, 8194, 29889, 278, 1234, 1033, 367, 27343, 29892, 766, 29887, 504, 29892, 8866, 29892, 14610, 2264, 29892, 22722, 29892, 16671, 29892, 470, 694, 953, 8194, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 953, 8194, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 275, 278, 14401, 749, 21302, 491, 337, 18248, 11462, 9819, 515, 263, 2319, 5716, 29973, 278, 1234, 1033, 367, 694, 13344, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 16123, 680, 278, 11462, 3233, 9401, 304, 278, 7182, 297, 278, 14401, 749, 411, 330, 17019, 11462, 29889, 278, 1234, 1033, 367, 5225, 29892, 5320, 29892, 3006, 29892, 25020, 29892, 470, 5941, 29889, 13, 13, 2277, 29937, 13291, 29901, 9171, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [1, 13866, 338, 385, 15278, 393, 16612, 263, 3414, 29889, 14350, 263, 2933, 393, 7128, 2486, 1614, 2167, 278, 2009, 29889, 13, 13, 2277, 29937, 2799, 4080, 29901, 13, 18307, 278, 20982, 4021, 1907, 297, 278, 1023, 10348, 2407, 886, 322, 12266, 565, 896, 6852, 304, 278, 1021, 2022, 29889, 278, 1234, 1033, 367, 4874, 470, 694, 29889, 13, 13, 2277, 29937, 13291, 29901, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:50.926650] torch.Size([8, 128]) [[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 13344, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 2055, 790, 573, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 953, 8194, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 14941, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 9171, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1217, 2, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]]
[00:25:50.926785] torch.Size([8, 3, 1, 128, 204])
[00:25:50.943287] torch.Size([8, 1, 4096])
WARNING:torch.distributed.elastic.agent.server.api:Received 2 death signal, shutting down workers
WARNING:torch.distributed.elastic.multiprocessing.api:Sending process 6952 closing signal SIGINT
Traceback (most recent call last):
  File "/home/u8915687/lab/big-superb/LLaMA-Adapter/imagebind_LLM/bigsuperb_finetune2.py", line 231, in <module>
    main(args)
  File "/home/u8915687/lab/big-superb/LLaMA-Adapter/imagebind_LLM/bigsuperb_finetune2.py", line 199, in main
    train_stats = train_one_epoch(
  File "/home/u8915687/lab/big-superb/LLaMA-Adapter/imagebind_LLM/engine_finetune.py", line 58, in train_one_epoch
    loss_scaler(loss, optimizer, parameters=model.parameters(),
  File "/home/u8915687/lab/big-superb/LLaMA-Adapter/imagebind_LLM/util/misc.py", line 262, in __call__
    self._scaler.scale(loss).backward(create_graph=create_graph)
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/_tensor.py", line 487, in backward
    torch.autograd.backward(
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/autograd/__init__.py", line 197, in backward
    Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass
KeyboardInterrupt
Traceback (most recent call last):
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/bin/torchrun", line 8, in <module>
    sys.exit(main())
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/errors/__init__.py", line 346, in wrapper
    return f(*args, **kwargs)
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/run.py", line 762, in main
    run(args)
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/run.py", line 753, in run
    elastic_launch(
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 132, in __call__
    return launch_agent(self._config, self._entrypoint, list(args))
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/launcher/api.py", line 237, in launch_agent
    result = agent.run()
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/elastic/metrics/api.py", line 129, in wrapper
    result = f(*args, **kwargs)
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 709, in run
    result = self._invoke_run(role)
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/elastic/agent/server/api.py", line 850, in _invoke_run
    time.sleep(monitor_interval)
  File "/home/u8915687/miniconda3/envs/imagebind_LLM/lib/python3.9/site-packages/torch/distributed/elastic/multiprocessing/api.py", line 62, in _terminate_process_handler
    raise SignalException(f"Process {os.getpid()} got signal: {sigval}", sigval=sigval)
torch.distributed.elastic.multiprocessing.api.SignalException: Process 6892 got signal: 2
